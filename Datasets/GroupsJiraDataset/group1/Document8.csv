id,love,joy,surprise,anger,sadness,fear,notes,comment N,comment N-1,comment N-2,...,comment 2,comment1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
61272,,x,,,,,,Thanks Alexey; Mark. I took the latest patch from Alexey; incorporated Marks suggestion and committed this to trunk.,I updated Sami's patch to store dataimport property file under collection directory in zk and name it after data import handler (the same way it is stored in local filesystem),Took a look at the patch and it looks good to me - only thing I might suggest is using CoreContainer#isZookeeperAware rather than comparing the zkController to null; but pretty minor stylistic thing.,Nice Sami! I was going to take the same approach. Longer term I think we want to add a write api to solrresource loader. If something came from the classpath; it would still be written to the conf area and later that would override a new read...,Here's a stab at fixing this issue. I noticed there were two places where DIH wanted to access conf dir: the config file (read) and some kind of state file (read/write) access. I added ZKPropertiesWriter that writes the contents of the state file into zk.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
18059,,x,,,,,,This was probably fixed by WODEN-86 which introduced support for the curly brace syntax in the http location template. This JIRA can now be closed.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
15084,,,x,,,,,Hellow; I have the same problem after i haved updated my libs. I'm developping a application based on struts 2.0.1 beta. It works just fine before i replace libs by 2.0.5. Original config of my application is from Struts 2 blank; so i've check all config files; and i find that web.xml in 2.0.5 doesn't have these lines : <listener> <listener-class>org.springframework.web.context.ContextLoaderListener</listener-class> </listener> so; i've deleted these lines and my app works.,Thanks for the update,Sorry for the delay; had to send in my laptop and therefore couldn't be online. Anyway; it seems that the problem is fixed; I had another; older version of struts lying in my path and that caused the conflict. Sorry to bother you!,Could you also tell us on what platform and application server you are using?,Could you provide a list of jars you were using and perhaps a stripped down version of your app? Vinny's problem was due to an old xwork 2 jar; which didn't contain the proper files; IIRC.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
29404,,,,,,x,,To be consistent with the preferred syntax in JIRA-1146; we will adopt the following syntax: <remoteAnalysisEngine remoteReplyQueueScaleout='nn1' > .... </remoteAnalysisEngine> I will start to do the work based on the above syntax if there is no objection ‰ÛÒ Tong,This change requires a change to the deployment descriptor. This change adds to the <replyQueue ...> the attribute concurrentConsumers='nnn'; and deprecates the location=[local | remote] for remote delegates. The change being done is to always use remote reply queues for remote delegates (see discussion above). Change dd2spring.xsl and also change the documentation for uima-as to correspond to this change.,Testing after the patch is done. Work properly.,For testing,Applied patches; Tong; please test.,I think Eddie is probably right that increasing the number of listeners should eliminate my need to set a prefetch > 0. A thread that's being used to execute prefetch isn't doing anything that an additional listener thread wouldn't also do; as far as I understand it. So I'm +1 to proceed with the plan as Eddie outlined it.,Thanks; Eddie. Let me clarify my statements a bit ... >>>The capability to add listeners for a remote reply queue should give equal or better performance than setting a prefetch value in most cases. Can we see if a single tuning parameter is enough before adding more complexity? Note that prefetch is not part of the JMS standard and is not available in all JMS implementations. +1 to avoiding more tweaking/tuning parameters whenever possible; in favor of something that just always works well. >>>> are there use cases where the remote delegate would be able to get requests from the remote broker; but possibly not be able to send it replies? (e.g.; due to firewall issues?) >>>Yes; when the client is behind a firewall; but the remote delegate [service] and it's broker are outside the firewall. This is one of the motivations for always allocating the reply queue on the service's broker (the other main one being to eliminate the need for a colocated broker to instantiate a local reply queue; again something not possible with many JMS implementations). Well; I meant the other way 'round. So let me try again - are there use cases where the remote broker serves the remote delegate new work OK; but for some reason can't host the reply queue? >>>>>There should only ever be one listener pulling messages off of the reply queue. >>>It is sometimes desirable to have more than one thread doing deserialization of reply messages; which is the original point of this issue. Yes; true - I meant one listener process (perhaps with mutliple threads though). So there's no need to worry about 'load balancing' due to prefetch > 0 - or is there? Not sure how these threads for multiple concurrent listeners interact with prefetch. >>>>>>>Is there a penalty for setting up the prefetch value to something high? >>>>The main problem for UIMA is memory management; as serialized XmiCas messages can be quite large. So this; together with comment above about prefetch and testing if it's needed tell me the decision to support prefetch is not yet figured out... but that we should lean toward avoiding adding this complexity if it can be shown it isn't needed. Adam - can you do a test or offer an opinion here?,The capability to add listeners for a remote reply queue should give equal or better performance than setting a prefetch value in most cases. Can we see if a single tuning parameter is enough before adding more complexity? Note that prefetch is not part of the JMS standard and is not available in all JMS implementations. >are there use cases where the remote delegate would be able to get requests from the remote broker; but possibly not be able to send it replies? (e.g.; due to firewall issues?) Yes; when the client is behind a firewall; but the remote delegate [service] and it's broker are outside the firewall. This is one of the motivations for always allocating the reply queue on the service's broker (the other main one being to eliminate the need for a colocated broker to instantiate a local reply queue; again something not possible with many JMS implementations). >There should only ever be one listener pulling messages off of the reply queue. It is sometimes desirable to have more than one thread doing deserialization of reply messages; which is the original point of this issue. >Is there a penalty for setting up the prefetch value to something high? The main problem for UIMA is memory management; as serialized XmiCas messages can be quite large.,Good points; Adam; to consider. Here are a couple of others (from reading our docs): are there use cases where the remote delegate would be able to get requests from the remote broker; but possibly not be able to send it replies? (e.g.; due to firewall issues?) Would it be possible to set the prefetch value for reply queues to be some fixed number (e.g.; 1 or 10 or ... ?) There should only ever be one listener pulling messages off of the reply queue. Is there a penalty for setting up the prefetch value to something high?,If you require the reply queues to be remote; please also allow me to set a prefetch value for them. I usually use a prefetch of 0 on my aggregate AS services; for better load balancing; but in some tests I've run; I found that local reply queues are faster; presumably because when a thread is ready to deserialize a CAS; it doesn't have to sit idle while retrieving the xmi from the broker. I'd like to be able to set a higher prefetch value (at least 1) for the reply queue. Speaking of which; prefetch needs to be settable in the DDE.,The deployment descriptor currently has: <remoteAnalysisEngine key='key name'> <!-- 0 or more --> . . . <replyQueue location='[local|remote]'/><!-- optional--> Some possibilities: a) if the location= is specified and is 'local'; give a message 'local reply queue no longer supported' b) We could force the local option to be remote - would this be a good idea? or should we just give an error message and force the user to update the descriptor? c) To support specifying tne number of concurrant consumers of the reply q; I propose adding an attribute to the replyQueue: 'concurrantConsumers' with a defualt value of 1. I'll proceed with this design / impl with the error message if the user says 'local'; unless other voices speak up,Along with this change; all reply queues for remote delegates will be deployed on the same broker as the delegate's input queue. Using remote reply queues for remote delegates will simplify message memory planning for a service; simplify the documentation and the CDE interface to the deployment descriptor.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4691,,x,,,,,,Fixed; closing,Should be fixed for win32 with revision 156722.,Looks like this applies to xsdtree as well.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3908,,x,,,,,,I fixed this in the ActionTag a while ago...,The patch as attachment.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
38439,,,,,,x,,Appled patch with some changes to compile with the new public rendering API.,Patch including the new selectors as well as its documentation.,Removed the patch for 10 minutes. Adding the selector documentation to it before uploading it again.,Fix including new selectors and skin properties,The selectors proposed looks good but I assume they're only a proposition right? Because I cannot get them to work and cannot find the reference to them inside code. However; after rethinking about it; I believe disabled should be handled differently. There should be 3 disabled hook set; one for unvisitied; one for active and one for visited stations; else the result might become strange when the user wants to make the active step disabled.,This file specifies all the skin selectors for the train component.,ADFFACES-66 is solved :),Issue 66 needs to be resolved before more skin selectors are added to processTrain,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
15698,,,,,,x,,I believe this is an issue. I have an action saveAction which I want to chain to editAction whenever there is a validation error. This is often necessary because a JSP will be displayed which has dynamic content such as a selectable list of items. However; if editAction has validation support; it will never be executed (even if it would validate successfully).,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
20061,,x,,,,,,Fixed with r1097472.,Link with WICKET-3500. Seems to be the very same problem. It has been fixed only in 1.4.x,This specific bug is fixed but stripping comments causes IE conditional comments to become broken/cut. It would be good to test WICKET-3433 with getMarkupSettings().setStripComments(true);,A patch fixing the problem. Please review.,I added a unit test demonstrating the problem: org.apache.wicket.markup.MarkupParserTest.wicket3648testCommentsWithNestedElements() Remove the prefix 'wicket3648' to run it.,_¢he problem is that there is an inner tag and the RawMarkup for the opening comment has no knowledge about the closing tag.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
70014,,,,,,x,,Marking resolved; feel free to reopen if needed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
57081,,x,,,,,,Closing as fixed.,The output from the test is below. Looks like the assertion is unrelated to the SIGHUP problem. INFO (S1) (10 lines): TEXT: COMPILER: IBM VisualAge C++; _IBMCPP_ = 900 ENVIRONMENT: powerpc/LP64 running aix-5.3 FILE: 18.setjmp.cpp COMPILED: Nov 21 2007; 16:53:28 COMMENT: header <setjmp.h> ############################################################ CLAUSE: support.runtime ASSERTION (S7) (4 lines): TEXT: macro setjmp not #defined CLAUSE: support.runtime LINE: 66 ---------------------- -------- -------- ---------+ DIAGNOSTIC ACTIVE TOTAL INACTIVE ---------------------- -------- -------- ---------+ (S1) INFO 1 1 0% (S7) ASSERTION 1 4 75% ---------------------- -------- -------- ---------+,Looks like the SIGHUP has disappeared from nightly AIX/XLC++ builds after fixing STDCXX-654 even though 18.setjmp now fails 1 assertion. Travis; can you look into it (and maybe open a new issue; if necessary)?,Now that 4.2.0 is released; set Affects Version(s) accordingly.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
20954,,,,,,x,,this setting is global for all modal windows and so tweaking it from the modalwindow class doesnt really make sense. a cleaner solution then overriding the method with an empty function is to use iheadercontributor and output a bit of js into the page 'Wicket.Window.unloadConfirmation = false;',Proposed solution: In modal.js instead of if (Wicket.Window.unloadConfirmation == true) use (this.settings.unloadConfirmation == true) In ModalWindow in getWindowOpenJavascript() method add appendAssignment(buffer; 'settings.unloadConfirmation '; getUnloadConfirmation()); getUnloadConfirmation() simple getter; true for default,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
78973,,,,,,x,,Point taken. Migration query is following in this case 'Update person set username='rave2011.myopenid.com'; openid='http://rave2011.myopenid.com/&#39; where username='http://rave2011.myopenid.com/&#39;'. We can add such migration steps in release also with some migration.txt or in change log file itself. Ideas?,The reason I asked was that there may be deployed instances of Apache Rave that use a different backend (MySQL; Oracle). Simply throwing these databases away may not be an option. As community we should start thinking about how to handle upgrades.,[~jashajoachimsthal] The column existed already but for openid URL was in username column for openid user and openid column was empty. Now we are validating openid URL with openid column. Now a user can have his openid url also to login along with his regular username.,[~raminder] is the DB change: 'ALTER TABLE person ADD COLUMN openid VARCHAR(255) default null' ?,Applied the patch. Thanks Viknes. There is a change in DB so remove the h2 database file.,Added more test cases,I am able to find a solution for this problem. If you use always-use-default-target='true' in security:openid-login then the behavior is right. Now the issue is if user dont take any action then we have a temporary authenticated user( its just in memory not in DB) in the context and if user try to type http://localhost:8080/portal/ the above exception will come. To solve this problem we can create our own openid failure handler and dont create/authenticate temporary user. here is a example i found http://stackoverflow.com/questions/12140519/spring-security-with-openid-for-google-not-working-in-production-environment,Working fine scenario: 1. Close all the open windows of a particular browser 2. Open a new one 3. Try loggin in as a new openid user and it works fine. It redirects the user to /openidregister openid user registration page. Not working scenario : 1. Close all the open windows of a particular browser 2. Open a new one 3. Login to rave as a different user/openiduser. 4. Logout the user 5. Now try loggin in as a new openid user The user instead of being redirected to /openidregister; is redirected to profile page. Since this is a new user; there would not be a home page for the particular user in the DB; we get a null pointer exception. So i would say even after logging out; something is retained in the browser cache by spring security (maybe or something else is the culprit). If anyone has a better idea of what the problem; pls share it.,This is the error stack. [INFO] [talledLocalContainer] WARN : org.openid4java.consumer.ConsumerManager - Could not create association of type: no-encryption:HMAC-SHA1:OpenID2 [INFO] [talledLocalContainer] WARN : org.openid4java.consumer.ConsumerManager - Could not create association of type: no-encryption:HMAC-SHA256:OpenID2 [INFO] [talledLocalContainer] WARN : org.springframework.security.web.authentication.session.SessionFixationProtectionStrategy - Your servlet container did not change the session ID when a new session was created. You will not be adequately protected against session-fixation attacks [WARNING] [talledLocalContainer] Sep 24; 2012 3:25:55 PM org.apache.catalina.core.StandardWrapperValve invoke [WARNING] [talledLocalContainer] SEVERE: Servlet.service() for servlet dispatcher threw exception [WARNING] [talledLocalContainer] java.lang.NullPointerException [WARNING] [talledLocalContainer] at org.apache.rave.portal.web.controller.PageController.getAllPagesForAuthenticatedUser(PageController.java:111) [WARNING] [talledLocalContainer] at org.apache.rave.portal.web.controller.PageController.viewDefault(PageController.java:69) [WARNING] [talledLocalContainer] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [WARNING] [talledLocalContainer] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) [WARNING] [talledLocalContainer] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) [WARNING] [talledLocalContainer] at java.lang.reflect.Method.invoke(Method.java:597) [WARNING] [talledLocalContainer] at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:213) [WARNING] [talledLocalContainer] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:126) [WARNING] [talledLocalContainer] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:96) [WARNING] [talledLocalContainer] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:617) [WARNING] [talledLocalContainer] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:578) [WARNING] [talledLocalContainer] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:80) [WARNING] [talledLocalContainer] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:923) [WARNING] [talledLocalContainer] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:852) [WARNING] [talledLocalContainer] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:882) [WARNING] [talledLocalContainer] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:778) [WARNING] [talledLocalContainer] at javax.servlet.http.HttpServlet.service(HttpServlet.java:617) [WARNING] [talledLocalContainer] at javax.servlet.http.HttpServlet.service(HttpServlet.java:717) [WARNING] [talledLocalContainer] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290) [WARNING] [talledLocalContainer] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [WARNING] [talledLocalContainer] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:322) [WARNING] [talledLocalContainer] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:116) [WARNING] [talledLocalContainer] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:83) [WARNING] [talledLocalContainer] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [WARNING] [talledLocalContainer] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:113) [WARNING] [talledLocalContainer] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [WARNING] [talledLocalContainer] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:103) [WARNING] [talledLocalContainer] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [WARNING] [talledLocalContainer] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:113) [WARNING] [talledLocalContainer] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [WARNING] [talledLocalContainer] at org.springframework.security.web.authentication.rememberme.RememberMeAuthenticationFilter.doFilter(RememberMeAuthenticationFilter.java:146) [WARNING] [talledLocalContainer] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [WARNING] [talledLocalContainer] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:54) [WARNING] [talledLocalContainer] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [WARNING] [talledLocalContainer] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:45) [WARNING] [talledLocalContainer] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [WARNING] [talledLocalContainer] at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilter(BasicAuthenticationFilter.java:150) [WARNING] [talledLocalContainer] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [WARNING] [talledLocalContainer] at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:182) [WARNING] [talledLocalContainer] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [WARNING] [talledLocalContainer] at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:182) [WARNING] [talledLocalContainer] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [WARNING] [talledLocalContainer] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:105) [WARNING] [talledLocalContainer] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [WARNING] [talledLocalContainer] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:87) [WARNING] [talledLocalContainer] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [WARNING] [talledLocalContainer] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:184) [WARNING] [talledLocalContainer] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:155) [WARNING] [talledLocalContainer] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346) [WARNING] [talledLocalContainer] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:259) [WARNING] [talledLocalContainer] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235) [WARNING] [talledLocalContainer] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [WARNING] [talledLocalContainer] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233) [WARNING] [talledLocalContainer] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191) [WARNING] [talledLocalContainer] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127) [WARNING] [talledLocalContainer] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102) [WARNING] [talledLocalContainer] at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:615) [WARNING] [talledLocalContainer] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109) [WARNING] [talledLocalContainer] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:293) [WARNING] [talledLocalContainer] at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:859) [WARNING] [talledLocalContainer] at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:602) [WARNING] [talledLocalContainer] at org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489) [WARNING] [talledLocalContainer] at java.lang.Thread.run(Thread.java:680),Did code cleanup and added test cases,Google; yahoo openid login works fine. openid.com login works but does not send email;name parameters when redirecting to rave from openid.com.,Attached the progress so far. Need to add unit test cases,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
61559,,,,x,,,,The other precedences are OK; as far as I can tell... not worth messing around in the code for no demonstrable benefit.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
12989,,x,,,,,,Already resolved with WW-3414,Yeah; it can be the same. Could you check with the latest snapshot ?,Issue seems similar to WW-3414. Will update if that same fix will work with me or i should change the code to not use ArrayList in action with some null values.,It looks a bit strange; did you try to ask on the User Mailing List ? XWorkConverter shouldn't be put in the Session.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8502,,,,,,x,,I tried using your testcase on Win95/IE4; using old versions of Xerces (back until 1.5.1); but I never got the crash you report. So; I am closing this bug; if you still see it; please reopen it. Alberto,Created an attachment (id=148) MFC VC6 project,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
11149,,,,,x,,,I wasn't able to reproduce the problem with the attachments. I saw appropriate error messages; line numbers; etc. However; line number information was missing for the testcase idkeyerr10; so I've committed a patch which remedies this.,Doesn't look like it to me.,Is this the same bug as #5972? That involves a different function; but it's a situation where a function refers to an object that was declared in a top-level XSLT element.,See idkeyerr10 for a test case. We put out a suitable message; just not the line number. This is probably a generic expression-evaluation issue. In the attachment; the first argument to key is always a variable; so the name of the key being searched for is set dynamically. Somehow; the value 'N400561' (which likely came from generate-id) got into that variable.,Created an attachment (id=1084) this is the xsl. run it against the XMLSchema.xsd (schema for schema) from w3c,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
18707,,x,,,,,,Ah; I can close it myself...,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
34779,,,,x,,,,fix works~,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
52597,,x,,,,,,thanks Malith for your contribution...patch committed under rev. 1326522,Attaching a patch .Please review & commit. Thanks; Malith,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
45983,,x,,,,,,No longer required; solved with THRIFT-1366. There will be no D7 support.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46218,,,,,,,,was introduced with THRIFT-1267,JavaScript testsuite with jslint; gjslint; QUnit and phantomjs might be a look worth to achieve this.,I can take this on since I wrote the original code.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
74046,,x,,,,,,Looks good; the other services had the type hinting too; so this was indeed an erroneous situation. Applied & Committed; thanks!,attached a patch for fixing this issue. I do not have a working version of the samplecontainer available; so it would be great if someone could check if it still works with the samplecontainer before commiting.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
36052,,,,x,,,,Moving these all to a 'Doc 3.x' release version.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
48885,,,,,x,,,I'm working with Liferay 5.1.2 / Tapestry 4.0.2 and that patch did not work for me. The IllegalStateException I obtain is thrown by service method of AbstractEngine: Error producing exception report: java.lang.IllegalStateException ERROR [STDERR] Session id : ERROR [STDERR] ERROR [STDERR] java.lang.IllegalStateException ERROR [STDERR] com.liferay.portlet.StateAwareResponseImpl.setRenderParameter(StateAwareResponseImpl.java:154) ... ERROR [[RP]] Servlet.service() for servlet RP threw exception [exec] java.lang.IllegalStateException Code: @InjectObject('service:tapestry.portlet.ActionResponse') public abstract javax.portlet.ActionResponse getActionResponse(); getActionResponse().sendRedirect(Portal-Login-Url); The Exception is thrown; but the redirect still works and every action done before seems to be rolled back (redirect to Portal-Login works; but Portlet-Login not) So i modified the service method of AbstractEngine to catch IllegalStateException: public void service(WebRequest request; WebResponse response) throws IOException { ... catch (PageRedirectException ex) { åÊåÊåÊåÊhandlePageRedirectException(cycle; ex); } catch (RedirectException ex) { åÊåÊåÊåÊhandleRedirectException(cycle; ex); } catch (StaleLinkException ex) { åÊåÊåÊåÊhandleStaleLinkException(cycle; ex); } catch (StaleSessionException ex) { åÊåÊåÊåÊhandleStaleSessionException(cycle; ex); } //New catch(IllegalStateException ex) { åÊåÊåÊåÊåÊhandleIllegalStateException(cycle; ex); } ... I know; thats not the ideal solution; but it works with Liferay.,Thomas; Please find attached a patch for this particular issue. It is a precise patch to allow for easy review. I have patched the Tapestry 4 I am using a bit more than just this. I am interested in your experience with T4 and portlets; in particular with respect to TAPESTRY-2548. Regards; Pieter Schoenmakers,Actually I'm facing the same Problem: trying to redirect to the Loginpage of my Portal; but I get the IllegalStateException. (getActionResponse().sendRedirect(myurl);) Could you please post your solution for me Pieter? Thanks in advance!,I've extended WebResponse to implement sendRedirect for a ServletResponse and ActionResponse; throwing for a RenderResponse. AbstractEngine.handleRedirect is fixed to invoke sendRedirect on the reponse. Works like a charm. Add a comment to this bug if you're interested in a patch.,Interestingly; redirection from within a portlet works (more or less) by doing a getActionResponse().sendRedirect('foo'). Any attempt by Tapestry to set render parameters in order to influence the next service invoked will fail. That includes the exception page triggered by the attempt to set render parameters. The only downside is the amount of litter in the log. The real solution is for AbstractEngine.handleRedirectException to be overridden for the situation in which we're handling an ActionRequest. In that case the sendRedirect of the ActionReponse should be invoked instead of the forward of the WebRequest (which does the wrong thing for absolute URLs anyway). I am becoming disappointed in Tapestry-4 and the way it is maintained. A bug like this should not remain open for 2 years (minus 3 days). I know moaning does not speed up the bug being fixed but at least the moaning may be noticed. I'll probably fix the bug myself anyway. Add a comment to this bug if you're interested in a patch.,I'm sorry; I forgot to say about environment. I've tried run portlet in pluto 1.0.1 and jetspeed-2.1-dev. But result is still the same,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
63070,,x,,,,,,Bulk close for Solr 1.4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5721,,,x,,,,,All of the components in the configuration get reset before parsing begins. This gives each component an opportunity to read features and properties from the configuration; and also to set its internals to the state it needs to be in before it is used by the configuration.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
398,,,,,,x,,+1 overall. Here are the results of testing the latest attachment http://issues.apache.org/jira/secure/attachment/12509655/patch.txt against trunk revision 1227927. +1 @author. The patch does not contain any @author tags. +1 tests included. The patch appears to include 3 new or modified tests. +1 javadoc. The javadoc tool did not generate any warning messages. +1 javac. The applied patch does not increase the total number of javac compiler warnings. +1 findbugs. The patch does not introduce any new Findbugs (version 1.3.9) warnings. +1 release audit. The applied patch does not increase the total number of release audit warnings. +1 core tests. The patch passed core unit tests. +1 contrib tests. The patch passed contrib unit tests. Test results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/882//testReport/ Findbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/882//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html Console output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/882//console This message is automatically generated.,----------------------------------------------------------- This is an automatically generated e-mail. To reply; visit: https://reviews.apache.org/r/3410/ ----------------------------------------------------------- (Updated 2012-01-06 05:02:48.623412) Review request for zookeeper. Summary ------- LearnerZooKeeperServer has no option to disable JMX registrations. Curator has a test ZK server cluster. Due to the intricacies of JMX; the registrations cannot be easily undone. In order for the Curator Test cluster to be re-usable in a testing session; JavaAssist ugliness was necessary to make LearnerZooKeeperServer.registerJMX() and LearnerZooKeeperServer.unregisterJMX() NOPs. This addresses bug ZOOKEEPER-1350. https://issues.apache.org/jira/browse/ZOOKEEPER-1350 Diffs (updated) /src/java/main/org/apache/zookeeper/server/ServerCnxnFactory.java 1227917 /src/java/main/org/apache/zookeeper/server/ZooKeeperServer.java 1227917 /src/java/main/org/apache/zookeeper/server/quorum/AuthFastLeaderElection.java 1227917 /src/java/main/org/apache/zookeeper/server/quorum/FastLeaderElection.java 1227917 /src/java/main/org/apache/zookeeper/server/quorum/LeaderElection.java 1227917 /src/java/main/org/apache/zookeeper/server/quorum/LeaderZooKeeperServer.java 1227917 /src/java/main/org/apache/zookeeper/server/quorum/LearnerZooKeeperServer.java 1227917 /src/java/main/org/apache/zookeeper/server/quorum/QuorumPeer.java 1227917 /src/java/main/org/apache/zookeeper/server/quorum/ReadOnlyZooKeeperServer.java 1227917 /src/java/test/org/apache/zookeeper/server/quorum/LearnerTest.java 1227917 Diff: https://reviews.apache.org/r/3410/diff Testing ------- Thanks; Jordan,----------------------------------------------------------- This is an automatically generated e-mail. To reply; visit: https://reviews.apache.org/r/3410/ ----------------------------------------------------------- (Updated 2012-01-06 04:59:53.911307) Review request for zookeeper. Summary (updated) ------- LearnerZooKeeperServer has no option to disable JMX registrations. Curator has a test ZK server cluster. Due to the intricacies of JMX; the registrations cannot be easily undone. In order for the Curator Test cluster to be re-usable in a testing session; JavaAssist ugliness was necessary to make LearnerZooKeeperServer.registerJMX() and LearnerZooKeeperServer.unregisterJMX() NOPs. This addresses bug ZOOKEEPER-1350. https://issues.apache.org/jira/browse/ZOOKEEPER-1350 Diffs Diff: https://reviews.apache.org/r/3410/diff Testing ------- Thanks; Jordan,More complete implementation with test,Jordan; thanks for this patch! Some course grain f/b: 1) use Boolean.getBoolean in allowJMX http://docs.oracle.com/javase/6/docs/api/java/lang/Boolean.html#getBoolean(java.lang.String) 2) can you update all the jmx registrations; rather than the single class? 3) we should have a test that verifies both the disable and default case. This should be easy given it's a system property. Also; when you resubmit would you mind creating a review on https://reviews.apache.org/dashboard/ ? This script might help: https://github.com/phunt/apache-reviewboard-zk-git Regards.,-1 overall. Here are the results of testing the latest attachment http://issues.apache.org/jira/secure/attachment/12509347/jmx_optional.diff against trunk revision 1225927. +1 @author. The patch does not contain any @author tags. -1 tests included. The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. +1 javadoc. The javadoc tool did not generate any warning messages. +1 javac. The applied patch does not increase the total number of javac compiler warnings. +1 findbugs. The patch does not introduce any new Findbugs (version 1.3.9) warnings. +1 release audit. The applied patch does not increase the total number of release audit warnings. +1 core tests. The patch passed core unit tests. +1 contrib tests. The patch passed contrib unit tests. Test results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/875//testReport/ Findbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/875//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html Console output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/875//console This message is automatically generated.,Here's a possible solution that would work for Curator.,Patch file,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
26594,,x,,,,,,Close all resolved issues for Engine 1.5 release.,Thanks for giving in; Nathan and making the patch. I agree with Henning's comment in Velocity-193 that relying on finalize is not perfect; but it should be a big improvement. Note that I added a line to set appender to null; allowing shutdown to be called multiple times with no effect.,before/just-in-case you ask... apply this and then there should be no question about resolving the bug.,Yes; and no. This bug affected both Log4JLogSystem and the deprecated SimpleLog4JLogSystem. the patch for VELOCITY-403 fixes the bug in Log4JLogChute (and thereby Log4JLogSystem) and uses Log4JLogChute in the default velocity.properties instead of SimpleLog4JLogSystem. so; the bug will be fixed for almost everyone. however; anyone outdated enough to have explicitly specified SimpleLog4JLogSystem (which has been deprecated for eternity and will now generate deprecation warnings at init-time) will not have the bug fixed for them. it would be easy to fix SimpleLog4JLogSystem; but frankly; i didn't care to. now it's just one more reason to stop using an ancient class.,Was this fix included in VELOCITY-403? It doesn't look like it. just checking.,I was just reading http://issues.apache.org/jira/browse/VELOCITY-193 and discovered that Daniel's patch also should include a call to logger.removeAppender(appender); in the shutdown() method.,Daniel's patch suggestion looks good to me. There's no reason to be closing other appenders attached to the logger. Of course; it will need to be regenerated if/after my patch for VELOCITY-403 is committed. i'll happily do that if no one beats me to it.,The SimpleLog4JLogSystem is deprecated; but should still be fixed. This problem also applies to the replacement class Log4JLogSystem. How about a patch like this?: * src/java/org/apache/velocity/runtime/log/Log4JLogSystem.java åÊåÊappender: Expose to shutdown(). åÊåÊinternalInit(String): Use this.appender. åÊåÊshutdown(): Close only our appender. Index: src/java/org/apache/velocity/runtime/log/Log4JLogSystem.java =================================================================== --- src/java/org/apache/velocity/runtime/log/Log4JLogSystem.java (revision 76173) +++ src/java/org/apache/velocity/runtime/log/Log4JLogSystem.java (working copy) @@ -55;6 +55;12 @@ åÊ åÊåÊåÊåÊåÊ/** åÊåÊåÊåÊåÊåÊ* <a href='http://jakarta.apache.org/log4j/'>Log4J</a> + * file appender for our {@link #logger}. + */ + private RollingFileAppender appender = null; + + /** + * <a href='http://jakarta.apache.org/log4j/'>Log4J</a> åÊåÊåÊåÊåÊåÊ* logging API. åÊåÊåÊåÊåÊåÊ*/ åÊåÊåÊåÊåÊpublic Log4JLogSystem() @@ -127;7 +133;7 @@ åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊ*/ åÊåÊåÊåÊåÊåÊåÊåÊåÊlogger.setLevel(Level.DEBUG); åÊ - RollingFileAppender appender = new RollingFileAppender( + appender = new RollingFileAppender( åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊnew PatternLayout( '%d - %m%n'); logfile; true); åÊåÊåÊåÊåÊåÊåÊåÊåÊ åÊåÊåÊåÊåÊåÊåÊåÊåÊappender.setMaxBackupIndex(1); @@ -177;10 +183;8 @@ åÊåÊåÊåÊåÊ/** Close all destinations*/ åÊåÊåÊåÊåÊpublic void shutdown() åÊåÊåÊåÊåÊ{ - Enumeration appenders = logger.getAllAppenders(); - while (appenders.hasMoreElements()) + if (appender != null) åÊåÊåÊåÊåÊåÊåÊåÊåÊ{ - Appender appender = (Appender)appenders.nextElement(); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊappender.close(); åÊåÊåÊåÊåÊåÊåÊåÊåÊ} åÊåÊåÊåÊåÊ},Why create own appender in internalInit method when you can Log4J do to that. I modified internalInit method and get rid of these finalize and shutdown methods and now there are no errors. Here is code snipped from internalInit method: java.util.Properties props = new java.util.Properties(); String ap = 'log4j.appender.R'; /* * Priority is set for DEBUG becouse this implementation checks * log level. */ props.put('log4j.logger.'+this.getClass().getName(); Priority.DEBUG.toString()+ ' ;R'); props.put(ap; RollingFileAppender.class.getName()); props.put(ap+'.File'; logfile); props.put(ap+'.MaxFileSize'; '100KB'); props.put(ap+'.MaxBackupIndex'; '1'); props.put(ap+'.layout'; PatternLayout.class.getName()); props.put(ap+'.layout.ConversionPattern'; '%d - %m%n'); org.apache.log4j.PropertyConfigurator.configure(props); logger = Category.getInstance(this.getClass().getName()); // logger.setAdditivity(false); /* * Priority is set for DEBUG becouse this implementation checks * log level. */ // logger.setPriority(Priority.DEBUG); // // RollingFileAppender appender = new RollingFileAppender( new PatternLayout( '%d - %m%n'); logfile; true); // // appender.setMaxBackupIndex( 1 ); // // appender.setMaximumFileSize( 100000 ); // // logger.addAppender(appender);,I agree we are doing the wrong thing and will stop. However; not sure if we want to take that strategy for shutdown - we can try.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
60912,,,,x,,,,[branch_4x commit] Mark Robert Miller http://svn.apache.org/viewvc?view=revision&revision=1384969 SOLR-3527: SolrCmdDistributor drops some of the important commit attributes (maxOptimizeSegments; softCommit; expungeDeletes) when sending a commit to replicas.,[branch_4x commit] Mark Robert Miller http://svn.apache.org/viewvc?view=revision&revision=1384969 SOLR-3527: SolrCmdDistributor drops some of the important commit attributes (maxOptimizeSegments; softCommit; expungeDeletes) when sending a commit to replicas.,I was investigating this issue and found that DistribUpdateProcessor distributes the commit commands using the SolrCommandDistributor.distribCommit(...). The method creates Actions to be distributed to other nodes like:  void addCommit(UpdateRequestExt ureq; CommitUpdateCommand cmd) {     if (cmd == null) return;     ureq.setAction(cmd.optimize ? AbstractUpdateRequest.ACTION.OPTIMIZE         : AbstractUpdateRequest.ACTION.COMMIT; false; cmd.waitSearcher);   }  In that method; the action is not considering the 'maxOptimizeSegments' parameter; that's why it's not being distributed to other nodes. However; a bigger problem may be that this method is omitting other parameters too; like 'softCommit' and 'epungeDeletes'; which means that an explicit soft commit issued like:  http://host:port/solr/update?commit=true&softCommit=true  can be distributed as a hard commit to the nodes. I'm not sure about this because I haven't write any test case yet; but it's definitely something to test.,Sounds right Andy - thanks for the report.,One additional data point: the distrib=false does not matter with current behavior. It seems if distrib=false only the local server should be optimized (to the requested value) and if distrib=true (default) all shards in the index should be optimized with N max segments.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
38950,,x,,,,,,I've re-worked my code and the problem has now 'gone away'. The original code; where the problem was found; was ported from a solution that worked fine using ADF controls. The same code resulted in this problem. I moved some controls on the page around and altered some of the attributes and the tree table now collapses and expands as expected. Quite why the re-work has now eliminated the problem I do not know but as I need to progress with other things I've decided to close this issue rather than waste anymore of anybody's time. Thanks for all your help anyway.,I think we need a testcase. I've tried reproducing this without luck in the trinidad-demo bundle; so there must be something about your configuration. For example; what are your state saving settings?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
63697,,,x,,,,,Ah; fantastic - that works very well. Thanks!,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
28338,,x,,,,,,added fixVersion,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
58473,,,,,,,,rules/,engines/refactor,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33144,,x,,,,,,Closing because this has been in RESOLVED state for over one year; if it turns out to not be fixed please reopen.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
78329,,x,,,,,,Issue fixed.,New certificate generation code in jtreg tests utilising bouncy castle provider,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
29161,,x,,,,,,Already fixed in UIMA-1379.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
154,,,,x,,,,Marshall; I'm wondering if the bug has something to do with the following: when you create a client; the second parameter to the constructor determines the random seed used by the client. That second parameter I think is supposed to be the client's id; but what is passed is clients.size(). I might be wrong here but I don't see where this vector of clients is cleared in between tests; so is it true that at some point the set size is fixed and all the seeds are the same ?,In the equivalent Java client test; the essential idea is to use a known seed of 1; but instead of using the random numbers directly from that; it passes the numbers generated into the client's invidiaul random number generators to be the seeds.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
13658,,,,,,x,,> Would it have an impact to remove this 'name' attribute from the generated 'form' tag ? YES! If you need XHTML strict compliance; just drop a new copy of form-common.ftl into template/simple; you can easily take out the section that generates the name=... It would probably cause us major problems; but you might be able to code around it for a single app. You can reopen as a feature request; but I think it is sufficient that you can change the templates yourself.,Ok; so maybe I should set the type to feature ! The thing is; from the test I made; most of the generated HTML code is XHTML strict compliant; so it would be very nice if all the generated HTML code was XHTML strict compliant. Would it have an impact to remove this 'name' attribute from the generated 'form' tag ?,I don't think strict XHTML compliance has ever been a goal.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
61118,,,x,,,,,I do have some interest in working on this; but it's not currently on my radar. Implementing SOLR-4241 would illustrate the issues that need fixing ... although if this is tackled first; writing SOLR-4241 would be much easier.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4758,,x,,,,,,See comments above; closing,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
20729,,,,,x,,,Sorry; I've reread the IOC code; and you're right. This is indeed not an issue. My apologies..,I'm not sure that I understand you. org.apache.wicket.injection.Injector#cache caches all fields per class; not the fields' values. This caching saves some CPU cycles to introspect the class again and again. The field's value comes from the IFieldValueFactory; so it is up to its implementation to lookup it properly. Please re-open if I'm not correct.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
35420,,,,,x,,,put backdoor cleanup v3.3 target,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
58767,,,x,,,,,Unfortunately no: - looking at ServerSession.userAuth where it sets the state to Running: åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊbuffer = createBuffer(SshConstants.Message.SSH_MSG_USERAUTH_SUCCESS; 0); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊwritePacket(buffer); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊsetState(State.Running); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊthis.authed = true; åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊthis.username = username; åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊunscheduleAuthTimer(); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊscheduleIdleTimer(); the event is triggered before this.username is updated so the observer doesn't have access to that value. If the set is moved to later than I can eliminate two hacks (I suspect this.username should be updated far earlier when userauth_request arrives; but that would be a change in getUsername's semantics); however ... - as I mentioned above; instead of overloading ServerSession I should be defining my own service type and adding that; I've created SSHD-211 and attached a patch to illustrate the basic idea,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
56598,,,x,,,,,Each instance in SQL Server gets its own port number. As long as the port number for the SQLExpress instance is accurate it should work okay.,org.wso2.stocktrader.mssql.MSSQLDAOFactory.host=localhost org.wso2.stocktrader.mssql.MSSQLDAOFactory.port=1433 should work for SQLExpress as well. If you have SQLServer and SQLExpress together; then SQLExpress might listen on a different port? Can you try it and let me know? (It worked for me; but I am using SQLExpress 2005). If it is not working; we'll add it. Will you be able to provide a patch in that case?,From my initial testing I think the following lines need to be added to (trunk\stocktrader\wsas\common\src\org\wso2\stocktrader\mssql\MSSQLDAOFactory.java) (43) public static final String PROP_MSSQL_DB_INSTANCE = 'org.wso2.stocktrader.mssql.MSSQLDAOFactory.instance'; (145) if (prop.getProperty(PROP_MSSQL_DB_INSTANCE) != null) { åÊåÊ// I'm rusty with java so != null or != '' whatever getProperty would return åÊåÊbuf.append(';Instance=' + prop.getProperty(PROP_MSSQL_DB_INSTANCE)); } And the respective property should be added to the mssql-db.properties,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
27656,,,,,,x,,We'll look at the issue for 1.1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
45250,,,,,,x,,Resolving as fixed. We can do better positioning of the comments once someone has a concrete use case for that.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
57170,,x,,,,,,Fixed thus: http://svn.apache.org/viewvc?rev=574613&view=rev,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
26551,,,,x,,,,used struts for 2 years now - no clue whether it has been fixed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8640,,,x,,,,,I think you want the XMLBEANS project; the xml to object mapping; rather than XBEAN; reusable server components,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
47248,,,,,x,,,In r681863,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
13977,,,x,,,,,Assigning this to future until the dependent XWork enhancement is made.,Waiting for http://jira.opensymphony.com/browse/XW-554 so we don't have to duplicate all the interceptor configuration.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
36205,,,x,,,,,as for V2.1.4 and later; we do not seen any reproduce; so mark this issue as fixed,Moving this to 2.3 as clustering hasn't been used in production for many years so unless someone who wants to deploy it wants to take on hardening it right now; it isn't urgent.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
31191,,,,,x,,,Fixed. Sorry folks; the 2 contributions ASM_8001_Java and ASM_12011 did not get committed from my local machine since the projects somehow were not part of my Eclipse workspace when I did the commits of these changes,Here are the changes that get the assembly otests building cleanly for me.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
36048,,,x,,,,,Right now ET_CALL; ET_NET and ET_TASK are the same unless task_threads is set > 0 So; ET_DEFAULT_THREAD_TYPE could just be ET_TASK if you want and it would accomplish the same thing.,Proposed changes to the SDK. See ts.h.in for the interface changes.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5784,,,,x,,,,This bug is 3 years old. Anybody looking to fix it?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46997,,x,,,,,,Ah; great; things are running now. Thanks guys.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
61898,,x,,,,,,bulk close for 3.4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
60817,,,,x,,,,removing fixVersion=4.0 since there is no evidence that anyone is currently working on this issue. (this can certainly be revisited if volunteers step forward),rmuir20120906-bulk-40-change,I don't mind if it's an option if you find it a useful feature. But we should be careful to doc it as not working with cloud at least. never rollback (default?) +1,What if it was configurable so that users had 3 options: rollback on failure (current option) execute user-defined delete query on failure never rollback (default?),Should the rollback feature be removed in favor of something more cloud-friendly? No. Some people do want it (same with the prepare). The uses are pretty special though; when you bave complete control of all updates going to Solr and you know exactly when commits happen; etc. In general; one should use something like deleteByQuery to remove a bunch of added updates (however that only works if the documents added are new and did not overwrite any older ones). Real transaction isolation is not a target feature for Solr.,rollback doesn't (and probably never will) have first-class cloud/distributed support Should the rollback feature be removed in favor of something more cloud-friendly?,+1 rollback doesn't (and probably never will) have first-class cloud/distributed support; and it's also not nice to roll back other people's updates that were unrelated to DIH.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
47855,,x,,,,,,Great! I'm glad you found it helpful.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33117,,,x,,,,,I've just made some observations on the tuscany-user mailing list which should appear in the mailing list archives shortly; under the thread that contains http://www.mail-archive.com/tuscany-user@ws.apache.org/msg02162.html,Kelvin; apparently there is no public maven repo that hosts these artifacts. We added the eclipse artifacts to our own repo using (something almost identical to) the maven eclipse plugin ( http://maven.apache.org/plugins/maven-eclipse-plugin/to-maven-mojo.html ),Kris; åÊåÊI downloaded and manually installed the eclipse core and osgi dependencies at the appropriate level into my maven repository. Currently I'm getting more eclipse missing classes such as IExtension; which I guess is because the eclipse artifacts have transitive dependencies which would be known if maven had installed the artifacts itself. I'm guessing you have a repository in your settings.xml file for maven that can resolve these artifacts automatically. I can continue to dig out jars and manually install them into my repo until all requirements are resolved; but if you happen to be able to point me at a maven repo to do the job automatically that would be great; thanks.,Kris; thanks for this. It's going to be a couple of days before I can get to looking at it; but I look forward to doing so.,The attachement agfasdo.tar.gz contains the full source code of our custom sdo implementation; including our data mapping extension. The included maven pom file might need some tweaking to get it to build.,I've added as much as I can to my sandbox in commit http://svn.apache.org/viewvc?rev=581184&view=rev I've not added anything from the hibernate integration archive due to the licensing issues alluded to earlier. Two of the files with header issues are part of the generic snapshot code; so they are missing from what I have committed (see the commit comment in http://svn.apache.org/viewvc?rev=581184&view=rev),I've been going through the files in preparation for putting them into the code base somewhere; and have been adding apache license headers to the files that have no headers; on the basis of the license you granted when attaching the zip files. There are about 10 files in the archives which have Agfa copyright headers in them (e.g. ExtendablePropertyAccessBuilder.java); saying that . ... // THIS IS UNPUBLISHED PROPRIETARY SOURCE CODE OF // Agfa-Gevaert Group åÊI don't feel it's right for me to remove those headers; although I guess that would be in the spirit of the submission. Could you please search for files with similar headers to that file; fix the headers as you see fit; and resubmit any files you wish to be included in the submission.,Hi; Thanks for the code. Sorry to take a while to get back to you. I have revisited this a few times to make sure I have a reasonably good feel for it before commenting. I'd love to be able to execute a test program to answer some of the question I have about the code; or at least to see some code that exercises it. Looking at the SnapshotSerializer code I think I'm OK to make the inference that the Type and Property classes used in there are your implementation classes of the SDO concepts; although of course that implementation code is not available. So; given that assumption; I understand that the implementation of your opaque snapshot representation is based on SDOs. It would be interesting to understand the issues you have encountered in using the code; for example; if there are any lossy round-trip transformations that cause problems. It would be great to work towards getting some code running inside the Tuscany code base; it would also be helpful if you could put some more words around any key design concepts and the issues you have encountered and solved; or have yet to solve. How should we proceed? Clearly the code is broken at the moment; given the missing aspects; so it's not suitable for including in the nightly build. I can put it in my sandbox; or I could set up another project under the SDO project; but not include it in the main build.,Bogdan; it's not in the code base yet. I'm looking at it now.,Are there any updates on this issue? Is this feature included in the nightly builds? Is it documented somewhere?,I didn't know about the license stuff and Hibernate. I'm sorry about that. I'll post some more stuff in the next days; so I should wait before committing this somewhere.,This seems pretty cool; in fact just yesterday on the user list another user was asking for exactly this functionality. There is an issue with the hibernate code unfortunately; it uses the LGPL license and we're not able to uses any code under that license in an Apache project (for the legal details see: http://www.apache.org/legal/3party.html). We can use the framework; just the code that directly references hiberbnate classes needs to be kept separate. Whats going to be easiest way to progress this; you say you're going to be adding more to it over the next days; should we wait for that before committing this somewhere or would it be easier to have it committed somewhere?,First attachment contains the main interfaces and implementation classes for snapshots; and mappers. Second attachment contains the hibernate integration.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
20748,,x,,,,,,Integrated in Apache Wicket 1.4.x #58 (See [http://hudson.zones.apache.org/hudson/job/Apache%20Wicket%201.4.x/58/]) åÊåÊåÊåÊ,Integrated in Apache Wicket 1.5.x #168 (See [http://hudson.zones.apache.org/hudson/job/Apache%20Wicket%201.5.x/168/]) åÊåÊåÊåÊ,Fixed with r978909 in trunk and r978910 in 1.4.x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
58727,,,,x,,,,Example RequestDocumentor output for the StatelessEngineTest,I have committed a prototype using a different approach in revision 1068442; where integration tests are enhanced with some metatada to generate RESTful API documentation. Will discuss on the dev list.,I think this should be given high priority (creating REST API documentation) for the whole system. It is at present impossible to get an overview of what IKS/Stanbol can do for you. As a result; it's difficult to work out what things are needed for a full IKS stack; let alone communicate the capabilities of IKS/Stanbol to others. So a definite +1 for anything that gets us to this documentation!,Jersey has builtin support to generate a WADL description of the HTTP service. I did not manage to get it working in fise but it should be possible. Would be good to generate the HTML documentation automatically though.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2557,,,,,,x,,I like MemoryResourceCalculator (or MemoryBasedResourceCalculator) better as well; that was my first choice; and is what the attached patch uses. Arun went with that on YARN-2 but people objected; if people are OK with it now then let's go with it. I don't think proliferation of many class names will be an issue.,"'""Single' is equally confusing ('which one is it?'). How about MemoryBasedResourceCalculator? Anything more (like MemoryCPUResrouceCalculator); we should religiously invent new names (like we did for schedulers).""",+1 on the SingleResourceCalculator idea.,+1 overall. Here are the results of testing the latest attachment http://issues.apache.org/jira/secure/attachment/12564795/yarn-340.txt against trunk revision . +1 @author. The patch does not contain any @author tags. +1 tests included. The patch appears to include 4 new or modified test files. +1 javac. The applied patch does not increase the total number of javac compiler warnings. +1 javadoc. The javadoc tool did not generate any warning messages. +1 eclipse:eclipse. The patch built with eclipse:eclipse. +1 findbugs. The patch does not introduce any new Findbugs (version 1.3.9) warnings. +1 release audit. The applied patch does not increase the total number of release audit warnings. +1 core tests. The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager. +1 contrib tests. The patch passed contrib unit tests. Test results: https://builds.apache.org/job/PreCommit-YARN-Build/349//testReport/ Console output: https://builds.apache.org/job/PreCommit-YARN-Build/349//console This message is automatically generated.,Yea; that's why I suggested SingleResourceCalculator as well; what do you think of using it? I actually think your original name was better (and don't think we'll end up with that many permutations in practice which is why I went with MemoryResourceCalculator) but if people are concerned with that at least SingleResourceCalculator means we won't proliferate as many but we'll still be able to change the default in the future without renaming classes or having the DefaultResourceCalculator not actually be the default.,Eli - I was specifically asked to not call it MemoryResourceCalculator during reviews in YARN-2 (the fear was that we'd proliferate MemoryCalculator MemoryCPUCalculator etc.).,Release audit warnings are unrelated (YARN-341),-1 overall. Here are the results of testing the latest attachment http://issues.apache.org/jira/secure/attachment/12564795/yarn-340.txt against trunk revision . +1 @author. The patch does not contain any @author tags. +1 tests included. The patch appears to include 4 new or modified test files. +1 javac. The applied patch does not increase the total number of javac compiler warnings. +1 javadoc. The javadoc tool did not generate any warning messages. +1 eclipse:eclipse. The patch built with eclipse:eclipse. +1 findbugs. The patch does not introduce any new Findbugs (version 1.3.9) warnings. -1 release audit. The applied patch generated 2 release audit warnings. +1 core tests. The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager. +1 contrib tests. The patch passed contrib unit tests. Test results: https://builds.apache.org/job/PreCommit-YARN-Build/348//testReport/ Release audit warnings: https://builds.apache.org/job/PreCommit-YARN-Build/348//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt Console output: https://builds.apache.org/job/PreCommit-YARN-Build/348//console This message is automatically generated.,Looks like svn diff after doing a mv and edit didn't generate a diff that test-patch could apply; this one should work.,-1 overall. Here are the results of testing the latest attachment http://issues.apache.org/jira/secure/attachment/12564791/yarn-340.txt against trunk revision . -1 patch. The patch command could not apply the patch. Console output: https://builds.apache.org/job/PreCommit-YARN-Build/347//console This message is automatically generated.,Patch attached. (Used svn mv for DefaultResourceCalculator to maintain history; so this patch shouldn't be checked in verbatim),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
20625,,x,,,,,,Integrated in Apache Wicket 1.4.x #200 (See [https://hudson.apache.org/hudson/job/Apache%20Wicket%201.4.x/200/]) åÊåÊåÊåÊ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
34486,,,,x,,,,Odd that you can't get the attached to build as it builds fine for me with the current latest code; never mind because I've tried it for you and yes this has fixed the problems and it now works. Thanks Jim! (Side note; I agree 100% about moving all the non-Java container specific tests out of the java container project),I think I fixed the issue but I can't get the attached to build on my machine so I am not sure if the web services binding will work. I have checked in unit tests that rely on the foo binding in container-java that exercise this core feature: org.apache.tuscany.container.java.integration.binding.EPtoExternalServiceTestCase org.apache.tuscany.container.java.integration.binding.ExternalServiceProxyInvokeTestCase Ideally; I would like the unit tests to be in core but pending what we decide on integration testing; I did not want to duplicate the test binding in two places (test classes can't be shared between projects). If this doesn't fix the problem; can you send a testcase demonstrating the issue so I can help address it? Thanks; Jim,This is not a problem with the SCA Tomcat integration. This is a problem with the core runtime; similar to the bug reported in TUSCANY-123. Jim; could you please look into this one as well as part of your investigation of TUSCANY-123? Thanks.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
918,,,,x,,,,You should also consider using Avro for the marshalling/unmarshal of the records. http://avro.apache.org/ Lots of benefits - in particular it's cross-language. Re writing to disk - perhaps just re-use the ZK WAL code and write to a disk that's not storing the transactional log.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
20237,,,,x,,,,See my comment in WICKET-3093.,I am using AjaxFormComponentUpdatingBehavior on autocompletetext field. below is the code snippet. åÊautocomplete.add(new AjaxFormComponentUpdatingBehavior('onchange'){ åÊåÊåÊåÊåÊåÊåÊåÊ private static final long serialVersionUID = 1L; åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊprotected void onUpdate(AjaxRequestTarget target) { åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊtarget.addComponent(getFormComponent()); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊ} åÊåÊåÊåÊåÊåÊåÊåÊåÊ}); please try it an the defect is recreatable.,Mark this as duplicate of WICKET-3093.,tried; could not reproduce. closing until quickstart is provided.,wicket-examples (latest 1.4.x) > ajax > autocompleter works without any problems on my IE6 here. Please provide a quickstart that reproduces the problem or give more details about the setup.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
13391,,,x,,,,,I am also having the same issue with a java.sql.Timestamp based attribute. The date I entered into the field was 'not a date'. Of course; XWorkBasicConverter fails to convert successfully and throws an XWorkException; then it is downhill from there on. When attempting to find the method to call in OgnlRuntime it appears to look for a String parameter; when it should be looking for the java.sql.Timestamp parameter.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
74301,,x,,,,,,Applied in r648154. Thanks!,The OAuth parameters are always urlencoded. The question is; where do they go. The OAuth spec specifies three potential places: the Authorization: header; the URI query part; or the POST body. The latter location only works; however; if the POST body is already of the right type (x-www-form-urlencoded). The code currently gets this wrong (attempting to add urlencoded OAuth parameters to any kind of POST body); and generally doesn't let you specify which of the three places you want your parameters to go. After the patch; they will go by default into the Authorization: header; which will work both with GETs and with POSTs of any MIME type.,I seem to recall Brian mentioning that OAuth only supported urlencoded (using their strict urlencoding definiton) requests. Is this not the case? Maybe I should just read the spec; eh?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
62999,,,x,,,,,@Noble Paul I cooked something resembling a backport here SOLR-3079,Yes; we can; can u post a patch @jason ?,Can we look at backporting this one to 3.x; given 4.x is a little ways off?,I have committed it to trunk. We may need more iterations to clean it up,This time use a factory to create shardHandler  <requestHandler name='standard' class='solr.SearchHandler' default='true'>     <!-- other params go here -->        <shardHandlerFactory class='HttpShardHandlerFactory'>          <int name='socketTimeOut'>1000</int>         <int name='connTimeOut'>5000</int>       </shardHandler>   </requestHandler>,Noble; the Jira issue is HBASE-3529 where much of the code is offline on Git because of the different pieces involved. That being said; I've linked the various Lucene and Solr Jira issues that are required to implement Solr in HBase; eg LUCENE-2919 and SOLR-2563.,Got a 3 day weekend; so I won't likely look at nobles patch more till next week - I def will still take a peek and weigh in; but this is simple enough that I don't mind if we just commit and iterate on trunk if necessary in further issues.,Jason. Open an issue and I will be glad to pitch in,@Noble I agree; I don't think committing this patch should hold things up. That was just a little note. I've been looking at implementing Solr into HBase and am worried [somewhat] about the ZK libaries. HBase + Solr can help with massive scale near realtime systems you've described; eg; HBase implements splitting; partitioning; a fast write ahead log; etc. Facebook has implemented the index directly into HBase; which probably offers degraded indexing and search performance. We badly need the cloud features now Right; many users are going with Elastic Search for the reasons mentioned.,Jason; Yeah ; it would be ideal. But we need to get things moving fast enough so that users can get the benefit ASAP. We badly need the cloud features now. I'm sure there are others too. We have clusters with 1000's of Solr hosts which are managed w/ ad-hoc tools.,I think it could conflict with other uses of Zookeeper when the library versions are different. Yeah - always a problem with dependencies like this. It's hard to say what direction we go right now though - some have argued even non zookeeper mode should be single install zookeeper mode instead. Has it's advantages and disadvantages I think. For me; I can really only take it an issue at a team; and while I hope to drive some more things around SolrCloud soon; it's obviously been a while. Others have some issues open; but more ideas are always good. I certainly agree that CoreContainer could be modularized better - would help for testing too. I have an issue to do this for the persistence code (baby steps ); but feel free to open further issues. I somewhat took the easy route in integrating zookeeper - there are certainly lots of improvements that could be made overall. And TODO's to finish - I think a couple guys have done a few from the wiki in various issues; and I know loggly has privately impl'd a couple from their talk at revolution (would be cool to see that come back; but I know they are busy guys). I love TODO's - minimal effort; but when you put one at a future pain point; your code doesn't look so stupid even when it's not perfect yet We should discuss in other issues though.,Seems to be fine. It'd be great to modularize Zookeeper references into a separate abstract interface (like what's done here); and not tie it to CoreContainer. I think it could conflict with other uses of Zookeeper when the library versions are different.,I can look at this latest patch soon Noble. We should also give Jason a fair amount of time to weigh in.,This might need some more cleanup; but I think it is close to a state where it can be checked in.,Even the checkDistributed() method is abstracted out to ShardHandler. The current HttpShardHandler (this is default) takes care of zookeeper also,What are the concerns with the latest patch? I can work on them. I guess this is the optimal way to resolve SOLR-2592,Same as the previous patch w/ standard configuration,Jason; the configuration which I have specified lets you do ShardHandler specific configuration. It goes well with the general Solr configuration.  <requestHandler name='standard' class='solr.SearchHandler' default='true'>     <!-- other params go here -->        <shardHandler class='HttpShardHandler'>         <!-- To be implemented-->         <int name='httpReadTimeOut'>1000</int>         <int name='httpConnTimeOut'>5000</int>       </shardHandler> </requestHandler>  Creating a new instance per request is not wise.,Does this patch incorporate any of Nobles feedback/patches? Any reason we want to create a new ShardHandler every request?,Hang - might have gotten bit by JIRA's new patch sorting bs - used to just do it right and I prob had it sorting wrong or something. Just gave it one last go and the patch applied cleanly.,Can you update your patch to apply without the hunk failures? Tests will not pass for me locally with the current patch.,I just downloaded http://svn.apache.org/repos/asf/lucene/dev/trunk and applied the patch; and test-core passed. However the patch command mentioned specific hunks; though there was no .rej file.,So my bad - looks like this patch is for 3.x - need to do it for 4 and port back.,I've got to look a little closer here - there was a conflict on trunk - naively just fixed it to compile and now I'm getting errors that are perhaps ip6 related? Need to investigate. java.lang.IllegalArgumentException: Invalid uri 'http://[::1]:33332/solr|localhost:53574/solr/select': escaped absolute path not valid,I think this patch looks good; mark I think we should commit this soon. simon,No worries mate!,I'm guessing Noble doesn't have a lot of free time for Solr these days based on how much he has popped up recently. I'm headed to Germany for a while; but I'd be happy to look at this issue as soon as I get a chance. Might even be able to start later today if my final buzzwords slides start coming together.,Methods moved up into abstract class ShardHandler. All tests pass.,Here's a patch updated to trunk.,What's the status of this one?,Bulk updating 240 Solr issues to set the Fix Version to 'next' per the process outlined in this email... http://mail-archives.apache.org/mod_mbox/lucene-dev/201005.mbox/%3Calpine.DEB.1.10.1005251052040.24672@radix.cryptio.net%3E Selection criteria was 'Unresolved' with a Fix Version of 1.5; 1.6; 3.1; or 4.0. email notifications were suppressed. A unique token for finding these 240 issues in the future: hossversioncleanup20100527,Still needs to eliminate the ResponseBuildr#shards field. We have no means of knowing the no:of of shards available in the prepare phase.The ShardHandler decides just in time the no:of shards available at any given point in time.,Search component is agnostic of the actual shards now. Some more work to be done to remove dependency on the ResponseBuilder#shards field by components.,sample of setting up a new ShardHandler   <requestHandler name='standard' class='solr.SearchHandler' default='true'>     <!-- other params go here -->        <shardHandler class='HttpShardHandler'>         <!-- To be implemented-->         <int name='httpReadTimeOut'>1000</int>         <int name='httpConnTimeOut'>5000</int>       </shardHandler>   </requestHandler>,The MultiShardHandler interface should automatically handle the shards and the search handler should be agnostic of the shard names . The MultiShardHandler interface can be simplified to this  public interface ShardHandler {     public List<Callable<ShardResponse>> submit(ShardRequest sreq; ModifiableSolrParams params);    },Same as the previous,Changed SearchHandler.getCommComponent to getMultiSearchHandler,should we have a separate plugin in solrconfig.xml like  <shardHandler class='ZkHadoopRpcHandler' name='zk'>         <str name='zkServer'>http://foo</str> </shardHandler>  and in the SearchHandler configuration it may have a reference to this  <str name='shardHandler'>zk</str>  This will help the Handler to have its own configuration,Changed the class names to the MultiShardHandler theme Added Apache license headers,Well; it's not always used in distributed mode (see MultiEmbeddedSearchHandler where we're querying multiple local cores); so DistributedCommComponent wouldn't work either. Maybe MultiShardHandler?,is it the best name ?. It somehow does not suggest that it is used for distributed search .,All tests pass (except the unrelated DirectUpdateHandlerTest),This code was originally created when integrating Katta.
75082,,x,,,,,,I intend to close this issue as fixed in a week's time. Please post your comments if you're able to test by then.,Ported to J5 branch and completed TODOs from r620242.,Thanks for your fix. I will try to test for it.,Please try building from trunk; and if possible; let us know how things go (see changes in r620242: http://svn.apache.org/viewvc?rev=620242&view=rev ). Leaving issue open for now.,Thanks for the test case and the proposed fix. Looks good; except that the else clause might need to be an else if. I am traveling till end of this month; and largely offline; but I will try to find time to get the fix in soon.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33755,,x,,,,,,Closing the issue now that it has been resolved.,Checked in a small fix for this.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9989,,x,,,,,,Xalan-Java appears to be operating correctly.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
59616,,x,,,,,,Closing this since it was committed in 1.4.0. Fixing tests is covered in SQOOP-397.,Integrated in Sqoop-jdk-1.6 #62 (See https://builds.apache.org/job/Sqoop-jdk-1.6/62/) SQOOP-354 SQOOP needs to be made compatible with Hadoop .23 release blee : http://svn.apache.org/viewvc/?view=rev&rev=1199149 Files : /incubator/sqoop/trunk/src/test/com/cloudera/sqoop/lib/TestLargeObjectLoader.java /incubator/sqoop/trunk/src/test/com/cloudera/sqoop/mapreduce/db/TestDataDrivenDBInputFormat.java /incubator/sqoop/trunk/src/test/com/cloudera/sqoop/testutil/MockObjectFactory.java,Here's an update to the latest patch that Tom posted. This makes Sqoop build. If you want to keep up with the latest versions of this patch check it out from Bigtop.,Apply SQOOP-354-0.23.0-SNAPSHOT.patch in addition to SQOOP-354.patch if you want to run against 0.23. (Not for commit.),Reviewboard: https://reviews.apache.org/r/2758/,It turns out that Mockito isn't needed; since MockObjectFactory was only being used by TestLargeObjectLoader; and then only to configure the output committer. I've simplified the test so that it doesn't use an output committer (since that isn't a part of the behaviour being tested); and now MockObjectFactory is no longer needed. Also; HadoopTestCase wasn't really being used; so I've removed that dependency too. The tests that I've changed work on both 0.20 and 0.23; so I think this change can be committed. Please review. Having a switch to build on either 0.20 or 0.23 should be tackled in another issue.,More precisely; the Hadoop test JARs are being published; but the HadoopTestCase class has not been moved to the Maven part of the build; so is missing from the test JARs. See HADOOP-7590.,Here's a patch to demonstrate the problem. Changing the Hadoop dependency to 0.23 necessitates an incompatible change to MockObjectFactory. This is similar to the changes covered in BIGTOP-162; and which are handled either via shims (an interface whose implementation is conditionally compiled according to the Hadoop target version) or via mock object libraries. Since the changes to Sqoop are only in the tests; using a mock object library is probably most appropriate. Are folks open to adding Mockito (say) as a Sqoop dependency? The other problem; not fixed in the patch; is that the Hadoop test classes (in particular HadoopTestCase) are not yet published to a Maven repository; so it's not possible to compile TestDataDrivenDBInputFormat.,Roman: have you tried excluding the extra transitive dependencies?,This is .23 related. The root cause as far as I can see is the Mavenization of Hadoop. Ivy gets confused because of extra transitive dependencies that it fetches from the .23 pom files.,Is this for 0.23 or 0.22?,A dep. problem? [ivy:resolve] 	==== maven2: tried [ivy:resolve] 	  http://repo1.maven.org/maven2/org/apache/velocity/velocity/1.7/velocity-1.7.pom [ivy:resolve] 		:::::::::::::::::::::::::::::::::::::::::::::: [ivy:resolve] 		::          UNRESOLVED DEPENDENCIES         :: [ivy:resolve] 		:::::::::::::::::::::::::::::::::::::::::::::: [ivy:resolve] 		:: org.apache.velocity#velocity;1.7: not found [ivy:resolve] 		::::::::::::::::::::::::::::::::::::::::::::::,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8053,,,,x,,,,Robert; åÊåÊåÊåÊYour patch is in; please help verify; thanks. Rgds; PeiYong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
77769,,,,x,,,,Closing resolved but not fixed (i.e.; duplicate; invalid; cannot reproduce; etc.) issues.,That last comment (about formatters listed multiple times) could be the source of the other problems. This may be a JRoller specific configuration problem; not a general Roller prolem.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
61104,,,,,x,,,I hope someone can fix this; but I know that at this time it's not something I can tackle without generous hand-holding. If there are no takers soon; I'll go ahead and close the issue. This is part of an effort to close old issues that I have reported. Search tag: elyograg2013springclean,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
44952,,x,,,,,,As suggested above; I moved the detector classes from o.a.t.detect to o.a.t.parser subpackages in revision 1159985. That should complete the last remaining open issue with this feature; so resolving as fixed.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
12834,,x,,,,,,Integrated in Struts2 #551 (See https://builds.apache.org/job/Struts2/551/) WW-3914 solves problem with returning always system implementation of FileManager (Revision 1405930) Result = SUCCESS lukaszlenart : Files : /struts/struts2/trunk/xwork-core/src/main/java/com/opensymphony/xwork2/util/fs/DefaultFileManagerFactory.java /struts/struts2/trunk/xwork-core/src/test/java/com/opensymphony/xwork2/util/fs/DefaultFileManagerFactoryTest.java,Done,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
57772,,,,,x,,,forgott to reslove: Actually this was fixed with http://svn.apache.org/r1459344 (21.March.2013),Looks like that updating the ContextClassloader results in a SecurityException under Ubuntu. Mac and Debian do now seam to cause this. Exception taken from Jenkins build 1324 java.security.AccessControlException: access denied (java.lang.RuntimePermission getClassLoader) at java.security.AccessControlContext.checkPermission(AccessControlContext.java:374) at java.security.AccessController.checkPermission(AccessController.java:546) at java.lang.SecurityManager.checkPermission(SecurityManager.java:532) at java.lang.Thread.getContextClassLoader(Thread.java:1364) at org.apache.stanbol.enhancer.engines.tika.TikaEngine.updateContextClassLoader(TikaEngine.java:402) at org.apache.stanbol.enhancer.engines.tika.TikaEngine.computeEnhancements(TikaEngine.java:270) at org.apache.stanbol.enhancer.jobmanager.event.impl.EnhancementJobHandler.processEvent(EnhancementJobHandler.java:271) at org.apache.stanbol.enhancer.jobmanager.event.impl.EnhancementJobHandler.handleEvent(EnhancementJobHandler.java:189) at org.apache.felix.eventadmin.impl.tasks.HandlerTaskImpl.execute(HandlerTaskImpl.java:88) at org.apache.felix.eventadmin.impl.tasks.SyncDeliverTasks.execute(SyncDeliverTasks.java:221) at org.apache.felix.eventadmin.impl.tasks.AsyncDeliverTasks$TaskExecuter.run(AsyncDeliverTasks.java:110) at EDU.oswego.cs.dl.util.concurrent.PooledExecutor$Worker.run(Unknown Source) at java.lang.Thread.run(Thread.java:662) moving the updating of the ContextClassloader into the doPrivileged(..) Block should solve this,starting with http://svn.apache.org/r1451480 the TikaEngine resets the context ClassLoader to the Bundle ClassLoader,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
45050,,,,,,x,,Actually I think I already applied similar changes when doing the POI 3.6 upgrade in TIKA-353. Resolving as fixed.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
36911,,,,,,x,,This is on top of http://svn.apache.org/repos/asf/myfaces/trinidad/branches/2.0.0.1-branch,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
79349,,x,,,,,,Closing old resolved issues,Thanks William to report this. I updated the page and I will verify later today that other instructions are correct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
56783,,,,x,,,,This test is not appearing in the nightly build results. When it does (and is passing); I'll close this issue.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1101,,,,,x,,,Please consider contributing your ruby binding; we'd love to include it in the release along with python; perl; etc...,Epilogue: I spoke too soon; I guess I had been staring at the data for too long. Some parts of the Stat struct were getting repointed or overwritten by the time the values were shuttled into the Ruby glue. Aside from the variation between 32b and 64b; the variations were repeatable (always the same changes; always the same wrong data); so I thought I saw something that wasn't there. Properly duping the struct before passing to the Ruby thread resolved it.,Sorry; some of the data included is invalid. I'll repost when confirmed; if necessary. :-/,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
28310,,,,x,,,,Change the element type of 'attributes' to FSAttribute.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
67087,,x,,,,,,resolved,Added 2.7.7 version of antlr to assembly and feature.xml,reopened because solution not optimal reverted above change,import for antlr is now: antlr*;version='[2.7.6;4)'  The bundle has to be released again and put to assembly.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
26184,,x,,,,,,patch applied.,If a directive implementation sees it's parameters are constant; it could evaluate them at initialization time; and substitute a more efficient version for evaluation at runtime.,A simple patch; don't mind applying it; but I'm not sure I understand why this is needed. Can you give a use case when this would be helpful?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
29014,,x,,,,,,applied patch; slight indentation reformating. Thanks Tommaso!,patch with above modifies supplied,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
77185,,x,,,,,,Closing all resolved/fixed issues of already released versions of Roller.,Done in trunk; before 3.0 branch,1) Apache license headers applied to all files. 2) Entire application repackaged from org.roller to org.apache.roller. 3) The Enhanced JavaScript editor (editor-text-js.jsp) has been completely removed from Roller (LGPL) 4) The Weblog Entry spell checked has also been completely removed from Roller (LGPL) Fixed and tested on BSC;Sfbay and Blogs-tst,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
70304,,x,,,,,,Fine. So I resolve this with just upgrading the used SLF4J API,>So can we then resolve this with just upgrading the exported SLF4J API and without the spi and helpers export ? I think so,So can we then resolve this with just upgrading the exported SLF4J API and without the spi and helpers export ?,Both mina and karaf have now been fixed.,I get it now; I wasn't seeing the spi dependency; but it's transitive via helpers. In any case; mina is fixed in trunk (2.0.0-RC2-SNAPSHOT) so that it no longer depends upon either spi or helpers.,The jar included with servicemix 4.2.0 is mina-core-2.0.0-RC1.jar. I haven't modified it at all.,Jason - what version of mina are you using? trunk depends upon org.slf4j.helpers; not org.slf4j.spi.,Reverted the export of the slf4j.helpers and slf4j.spi packages in Rev. 995563.,Reopening to resolve this veto.,-1 on exporting spi and helpers. These packages are for implementers of SLF4J; not API consumers. The only exports from commons log should be logging APIs. If we decide to expose an SPI; that should be done in a Sling package and then mapped internally to the bundle to the SPI of whatever implementation we happen to be using at the time.,Thanks for the information. I have applied your patch in Rev. 995520.,I moved spi/helpers to the private packages header again and got the following bundle problems: org.apache.felix.karaf.features.core [14]: package; (&(package=org.slf4j.helpers)(version>=1.4.0)(!(version>=2.0.0)))) org.apache.mina.core [25]: package; (&(package=org.slf4j.spi)(version>=1.5.0))) org.apache.felix.karaf.shell.log [30]: package; (&(package=org.ops4j.pax.logging.spi)(version>=1.4.0)(!(version>=2.0.0)))) (this still persists when I move the headers back because it's a dependency on pax; which I removed) I'm using servicemix 4.2; which uses karaf 1.4.0. I know this is a pretty old version of karaf; but I've been pretty hesitant to switch to 2.0.0 because of all the unknown regression issues that might pop up.,Thanks for providing the patch. I agree with updating to the 1.5.11 version of slf4j API (and helper bundles). But I am a bit unsure about exporting the spi and helpers packages. Do you have bundles importing these packages ? and to what avail ?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
50483,,x,,,,,,Integrated in tapestry-trunk-freestyle #511 (See [https://builds.apache.org/job/tapestry-trunk-freestyle/511/]) åÊåÊåÊåÊTAP5-1628 minor rewording (javadoc only) bobharner : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1167084 Files : * /tapestry/tapestry5/trunk/tapestry-core/src/main/java/org/apache/tapestry5/corelib/base/AbstractField.java * /tapestry/tapestry5/trunk/tapestry-core/src/main/java/org/apache/tapestry5/corelib/components/Submit.java,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
50490,,x,,,,,,Integrated in tapestry-trunk-freestyle #515 (See [https://builds.apache.org/job/tapestry-trunk-freestyle/515/]) åÊåÊåÊåÊTAP5-1621 - Fixed test joshcanfield : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1167447 Files : * /tapestry/tapestry5/trunk/tapestry-ioc/src/test/java/org/apache/tapestry5/ioc/internal/services/TypeCoercerImplTest.java,Integrated in tapestry-trunk-freestyle #514 (See [https://builds.apache.org/job/tapestry-trunk-freestyle/514/]) åÊåÊåÊåÊTAP5-1621 - Fixed Object[] -> Boolean joshcanfield : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1167386 Files : * /tapestry/tapestry5/trunk/tapestry-ioc/src/main/java/org/apache/tapestry5/ioc/services/TapestryIOCModule.java,Integrated in tapestry-trunk-freestyle #513 (See [https://builds.apache.org/job/tapestry-trunk-freestyle/513/]) åÊåÊåÊåÊTAP5-1621 - TypeCoercer change: replaced Long -> Boolean with Number -> Boolean. Added Object -> Boolean joshcanfield : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1167289 Files : * /tapestry/tapestry5/trunk/tapestry-ioc/src/main/java/org/apache/tapestry5/ioc/services/TapestryIOCModule.java * /tapestry/tapestry5/trunk/tapestry-ioc/src/test/java/org/apache/tapestry5/ioc/internal/services/TypeCoercerImplTest.java,Need to update the diagram to represent the change. http://tapestry.apache.org/typecoercer-service.html,A workaround is to add the following coercions to your AppModule. public static void contributeTypeCoercer(Configuration<CoercionTuple> configuration) { åÊåÊåÊåÊåÊåÊåÊåÊ/** åÊåÊåÊåÊåÊåÊåÊåÊåÊ* Prevent toString() conversion to get to boolean åÊåÊåÊåÊåÊåÊåÊåÊåÊ*/ åÊåÊåÊåÊåÊåÊåÊåÊconfiguration.add(CoercionTuple.create(Object.class; Boolean.class; åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊnew Coercion<Object; Boolean>() { åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊpublic Boolean coerce(Object input) { åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊreturn input != null; åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊ} åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊ})); åÊåÊåÊåÊåÊåÊåÊåÊ/** åÊåÊåÊåÊåÊåÊåÊåÊåÊ* Number -> Boolean - make sure that Object -> Boolean isn't used! åÊåÊåÊåÊåÊåÊåÊåÊåÊ*/ åÊåÊåÊåÊåÊåÊåÊåÊconfiguration.add(CoercionTuple.create(Number.class; Boolean.class; åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊnew Coercion<Number; Boolean>() { åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊpublic Boolean coerce(Number input) { åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊreturn input.byteValue() != 0; åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊ} åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊ})); åÊåÊåÊåÊ},,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
70122,,x,,,,,,applied patch (thanks) in r1055887,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
15560,,,,,,x,,Since no additional information has been provided and we can't duplicate; I'm marking this resolved. Please reopen if you can provide additional information that helps us replicate the problem.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
15330,,,x,,,,,As of r438174 ; the shopping-cart is parked in the sandbox (sandbox/struts2/apps/shopping-cart) waiting to see if someone's wants to maintain it; but it hasn't been removed from the repository yet.,Resolving as won't fix; because the shopping cart example app has been removed.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
80738,,,,x,,,,Rejected for 0.20. Allow me to clarify my position. I was prepared to accept this for 0.20. Right or wrong; it's by all accounts the dominant convention for similar .i files from other projects; and that's good enough for me. However! It depends on QPID-4207; and that's much too big change to dist metadata for our final release candidate. This will have to wait.,I disagree with Gordon. Generating bindings is a client development activity in my view. With the .i files exported in this way developing bindings is no longer restricted to those with access to the qpid tree; but the only requirement to develop a new client binding is the client include files. This strong decoupling is a very good thing from my point of view. Obviously you wouldn't export .i files that relate to individual bindings to the include files; but the .i that give the general typemaps that are useful for every binding and point at all the necessary include files seem like very good candidates for export to me.,Personally I find this odd. They are not needed for 'client development' in my view; but for generating the bindings. They are source components of the bindings not installable artefacts of the client library itself.,This is committed in r1420320. http://svn.apache.org/viewvc?view=revision&revision=1420320,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
