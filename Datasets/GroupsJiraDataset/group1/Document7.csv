id,love,joy,surprise,anger,sadness,fear,notes,comment N,comment N-1,comment N-2,...,comment 2,comment1,,,,,,,,,,,,,,,,
59616,,x,,,,,,Closing this since it was committed in 1.4.0. Fixing tests is covered in SQOOP-397.,,,,,,,,,,,,,,,,,,,,,
3908,,,x,,,,,I fixed this in the ActionTag a while ago...,,,,,,,,,,,,,,,,,,,,,
50483,,x,,,,,,Integrated in tapestry-trunk-freestyle #511 (See [https://builds.apache.org/job/tapestry-trunk-freestyle/511/]) åÊåÊåÊåÊTAP5-1628 minor rewording (javadoc only) bobharner : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1167084 Files : * /tapestry/tapestry5/trunk/tapestry-core/src/main/java/org/apache/tapestry5/corelib/base/AbstractField.java * /tapestry/tapestry5/trunk/tapestry-core/src/main/java/org/apache/tapestry5/corelib/components/Submit.java,Okay; changed to: If true; then the field will render out with a disabled attribute (to turn off client-side behavior). When the form is submitted; the bound value is evaluated again and; if true; the field's value is ignored (not even validated) and the component's events are not fired.,Yep; sounds good! Thanks! Though I prefer the term similar to 're-evaluated' over 'checked' so you know the whole expression is; err; evaluated (!); and it's not just some cached value being checked. But anything is better nothing; so; um; cheers!,Okay; I get it. How about the following: åÊåÊåÊåÊåÊIf true; then the field will render out with a disabled attribute åÊåÊåÊåÊåÊ(to turn off client-side behavior). When the form is submitted åÊåÊåÊåÊåÊthe bound value is checked again and; if true; the field's åÊåÊåÊåÊåÊvalue is ignored (not even validated) and the component's åÊåÊåÊåÊåÊevents are not fired.,Um; I mean; '...for does this not effectively...',It is less to do with the @Persist annotation and more to do with not knowing the disabled parameter is used / re-evaluated during the server-side form submit event. Once the <input> element has rendered; it is not obvious the disabled parameter will ever be used / re-evaluated again; for I would expect it's sole purpose is to only render the HTML 'disabled' attribute. I guess I should (have) really ask(ed) why the disabled parameter is evaluated again on form submission; for this not effectively prevent you from re-enabling the component (via javascript) on the web page?,Integrated in tapestry-trunk-freestyle #506 (See [https://builds.apache.org/job/tapestry-trunk-freestyle/506/]) åÊåÊåÊåÊFixed TAP5-1628 (Have Submit documentation explicitly state when the disabled attribute is evaluated); javadoc changes only. bobharner : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1165938 Files : * /tapestry/tapestry5/trunk/tapestry-core/src/main/java/org/apache/tapestry5/corelib/base/AbstractField.java * /tapestry/tapestry5/trunk/tapestry-core/src/main/java/org/apache/tapestry5/corelib/components/Submit.java,Fixed in rev 1165938; although with different text: åÊåÊåÊåÊåÊIf true; then the field will render out with a disabled attribute åÊåÊåÊåÊåÊ(to turn off client-side behavior). When the form is submitted; disabled åÊåÊåÊåÊåÊfields' values are ignored (not even validated); and the component's åÊåÊåÊåÊåÊevents; if any; are not fired. But I'm not sure a better description of the disabled parameter helps people know when to apply the @Persist annotation.,,,,,,,,,,,,,,
13658,,,,,,,,> Would it have an impact to remove this 'name' attribute from the generated 'form' tag ? YES! If you need XHTML strict compliance; just drop a new copy of form-common.ftl into template/simple; you can easily take out the section that generates the name=... It would probably cause us major problems; but you might be able to code around it for a single app. You can reopen as a feature request; but I think it is sufficient that you can change the templates yourself.,,,,,,,,,,,,,,,,,,,,,
58727,,,,,,,,Example RequestDocumentor output for the StatelessEngineTest,,,,,,,,,,,,,,,,,,,,,
18707,,,x,,,,,Ah; I can close it myself...,For the sake of completeness: I have also posted a stackoverflow question about this: http://stackoverflow.com/a/13088148/1006823 In the answer I have outlined how I finally solved the problem. I just had to extract the actual page mounting out of my WebApplication class; which seemed like a drawback first; but actually I am pretty happy that the mount stuff is separate now :) That said; feel free to close this ticket if you do not think the framework should support this. At anyone needing this; have a look at the link above - actually it is pretty simple once you know it :),I see no way to generate urls without the information from the request and application (servlet context).,I'm not sure how this is possible in Wicket 1.3/1.4. The ServletContext is needed and the filter path where WicketFilter listens to be able to calculate the relative urls. If you need full url (like http://host/...) then you can use a helper class that uses bi directional map (String -> Class<Page>). In Wicket code you just need to do somthing like: void Helper.mount(webApp) { åÊåÊfor (entry : map) { åÊåÊåÊåÊwebApp.mountPage(entry.key; entry.value) åÊåÊ} } In your non-Wicket code: åÊåÊprefix + map.getKey(pageClass) where prefix is the part that Wicket needs usually to calculate the urls: http://host/contextPath/filterPath.,,,,,,,,,,,,,,,,,,
44952,,x,,,,,,As suggested above; I moved the detector classes from o.a.t.detect to o.a.t.parser subpackages in revision 1159985. That should complete the last remaining open issue with this feature; so resolving as fixed.,I think we are pretty much done with this issue already. Before closing this; I'd like to move the new classes from within o.a.t.detect to appropriate o.a.t.parser subpackages in tika-parsers. That way the detection logic is closer to the related parser classes and we don't have to worry about split-package warnings from OSGi.,In revision 1042497 I added an auto-loading mechanism for detectors so that tools like the Tika facade or the AutoDetectParser class can automatically pick up all detector implementations in the current classpath. This way also the container-aware detectors can be used with minimal changes to client code. To prevent excessive performance overhead; both the Zip and POIFS detectors will first check for the relevant magic byte header and will only do the more expensive format check if the byte header matches and if the given stream is a TikaInputStream instance. In revision 1042498 I added a new --detect option to the CLI for easier testing of the auto-detect functionality. Also; since the container-aware detectors are now automatically loaded and used; there's no longer any need for the explicit --container-aware-detector option and I've turned it into a no-op.,I refactored the code a bit in revision 1042476 to make it easier to compose with other kinds of detectors. Most notably I removed the ContainerDetector interface and made the POIFSContainerDetector and ZipContainerDetector classes directly implement the Detector interface.,I've added some Detector documentation in r985242; please everyone dive in with bits I have missed!,I committed my patch in revision 982175. > memory and processing impact of opening the container I think this acceptable as the extra cost is only associated with specific media types; and we can use the open container feature you added to TikaInputStream to allow later parsing stages to avoid duplicating these costs. Also; since this functionality is now only triggered when the detector is passed a TikaInputStream; a performance-conscious user can easily prevent the extra processing. We might also want to add some extra flag for this if needed. > detectors run in the right order This was a part of my thinking behind the proposed getSupportedTypes() method. With that we could choose to only run these kinds of more complex detectors when simpler detectors have first identified the basic container format.,BTW; the current new Detector implementations are a bit troublesome as they break the contract that the detect() method must not close() the given stream and should use mark() and reset() where necessary to avoid changing the state of the stream. The rationale behind this contract is that you should be able to call parse() on the same stream instance after detecting its type. The attached patch fixes this issue by using the TikaInputStream.getFile() method to access the underlying file (when available or spooled) when detecting these kinds of complex container formats. If the given stream is not a TikaInputStream; then just the generic application/zip or application/x-tika-msoffice type is returned.,Using the container aware detector will give a more accurate answer generally; but at the cost of more memory use; and longer processing time. (Oh; and plus the need for various parser dependencies) There was some reluctance on-list about making this the default; due to the memory and processing impact of opening the container; which we'll need to take notice of. There's also the issue of making sure the detectors run in the right order; which may matter for some but not for others. Alas I don't have a good answer for the way to handle all these different needs...,It's a bit more work; yes. What I'm trying to achieve here is for someone who just uses 'new Tika().detect(...)' to be able to benefit from these extra detectors when they're available in the classpath.,Ah; sorry Nick - I hadn't looked into code yet. I thought; that we stuck in container if it matches to some signature.,Alex - have a look at the code; I think it already does what you're asking of it For OLE2; when we detect the ole2 signature; we load the file into POIFS. We then ask the detector what it is based on this For Zip; we look at each entry in the zip file in turn. If it's one we recognise the name of; and that tells us all we need; we return. Otherwise; we open up that entry; and grab the mime type from that; and return.,Jukka - that might end up being more work though? Also; short of refactoring the current mime types to split out all the different bits; I'm not sure we will have that many new detectors ever?,It's better to have some flag; that will say 'Stop; if this rule matched'; because applying of all rules; could lead to weak performance It's better to have something like; for example for zips rule for jar: zip-type == X1 rule for odf: zip-type == X2 ..... zip-type will calculated once on first invocation; and then re-used. And all rules (for jar; odf; etc.) have no flag 'Stop here'; while there will rule for ordinary zip's; that will have this flag; and we'll stop after checking of all subtypes. The same is could be implemented for OLE2 and other container formats; like OGG; etc.,Hmm; I guess you're right; perhaps we won't need such multi-level detector functionality. The alternative is to simply load all available Detectors; run them on the input document and finally select the most specific of the returned media types.,2Nick: does this will allow to implement support for self-extracted archives? Because; if we'll implement this as separate checker; then we'll need to implement archive extraction/detection inside this checker - this could lead to code duplication.,At the moment; the ContainerAwareDetector checks the first 8 bytes of the file. If they match the OLE2 header signature; it hands it off to POIFS. If the first 4 bytes match the zip header signature; it does zip checking. If neither of them match; it falls back to the default detector To me; this seems simpler!,It would be great if the AutoDetectParser could automatically leverage such detectors that use external parser libraries. The AutoDetectParser can't directly link to such parsers due to dependency issues; but we could use the service provider mechanism just like we do with Parser classes to automatically load all the Detectors available in the classpath. To do this effectively; I'd also add a Detector.getSupportedTypes() method like below so that more complex and potentially more expensive (need to read the entire document) detectors like POIFSContainerDetector could only be called if a more generic detector first determines that the input document matches the supported base type. /** Returns the set of base media types supported by this detector when used with the given parse context. The base media type can be <code>application/octet-stream</code> for generic detectors or a more specific type like <code>text/plain</code> or <code>application/zip</code> for detectors that can only distinguish between subtypes of that base type. * @since Apache Tika 0.8 @param context parse context @return immutable set of media types */ Set<MediaType> getSupportedTypes(ParseContext context);,Nick; awesome job! Comments below: I think the only bit left for now is to document it. We don't currently have a Detection section in the documentation. Shall I create a new one; put in the basics from one of the apachecon Tika talks; then add a section on container aware detection? Yep; I would do this. I would just add some APT documentation and create a section called 'Detection'; with some useful information on there. You could also then from that APT page; link to the page on the Wiki where the discussion on container Metadata occurred too: http://wiki.apache.org/tika/MetadataDiscussion Cheers; Chris,I've added support for OOXML files (detection + container re-use); as well as Jar files I believe the only zip based container format we can't currently detect with this is iWork. I've figured out how to tell it's an iWork document; but not how to tell which iWork document subtype it is. I think the only bit left for now is to document it. We don't currently have a Detection section in the documentation. Shall I create a new one; put in the basics from one of the apachecon Tika talks; then add a section on container aware detection?,Nick; awesome!,As no-one has objected; I've committed this initial code in r980058. With this commit; OLE2 based detection should be complete; and some Zip based detection is there; but some still remains to be added.,Patch which implements limited ole2 and odf detection by parsing the containers. May not be the best way to do it however...
28338,,,,,,,,added fixVersion,reopened for fixVersion,This problem won't be fixed. First; the encoding is not yet linked to the engine nor to the launching. Second; UIMA-2256 will make this change redundant.,,,,,,,,,,,,,,,,,,,
61104,,,,,x,x,,I hope someone can fix this; but I know that at this time it's not something I can tackle without generous hand-holding. If there are no takers soon; I'll go ahead and close the issue. This is part of an effort to close old issues that I have reported. Search tag: elyograg2013springclean,I just thought of a localparam syntax for this: {!cache=nowarm},I never actually answered your first question. Yes; I do want most entries in the filter cache to be usable for autowarming. Most users have relatively few boolean clauses in their filter queries. Employees are the common exception. We get a few hundred boolean clauses in ours. Plans are being discussed to greatly reduce that; but I'm not sure we'll ever get away from it entirely.,I would like to have our application code tag those nasty employee filters with something that makes them ineligible for autowarming; but still eligible for caching; which would keep them around until the next commit. I am pretty sure our code is capable of knowing that the user is a special user; typically admin or system. An update cycle runs once a minute for the index as a whole; but changes are tracked on a per-shard basis. Commits on each shard are only done if something on that particular shard actually changes. The large shards where this is a problem typically go several minutes between commits; and that might extend to an hour or more. I will talk to our developers about using the cache=false localparam for now; but I am hoping for the ability to use the cache for those nasty filters but not include them for warming. Having recently toyed with the cache code ( SOLR-2906); I know this may not be trivial.,Are there other auto-warming queries you want to have done? Because it almost sounds like you just want to turn off autowarming in the filter cache. Or if they're unlikely to be re-used anyway; would it work to set cache=false on the original fq?,I don't think I can implement this. My knowledge of Solr internals simply isn't strong enough.,,,,,,,,,,,,,,,,
70014,,,,,,,,Marking resolved; feel free to reopen if needed,Thanks for your contribution! I'm not a fan of thread locals at the framework level if we can avoid them; so I implemented a different mechanism in revision 1084217; using optional interfaces. The SlingRemoteExecutionRule class is a RequestCustomizer which does nothing by default; but if you want to use thread locals in your project inheriting your own rule class from that one should work. Please let us know if this works for you; and I'll close this issue if it does.,The patch provides one possible approach based on passing the Request object to a RequestProcessor. The RequestProcessor instance is obtained from a ThreadLocal which can be specified by the TestCase in the Before execution phase depending on the testcase being run,Patch for supporting addition of credentials based on a ThreadLocal request processor,,,,,,,,,,,,,,,,,,
74046,x,x,,,,,,Looks good; the other services had the type hinting too; so this was indeed an erroneous situation. Applied & Committed; thanks!,,,,,,,,,,,,,,,,,,,,,
61559,,,,,x,,,The other precedences are OK; as far as I can tell... not worth messing around in the code for no demonstrable benefit.,I don't see anything else that looks wrong; so what do people think about doing this?,I went ahead and looked at the ternary operator (those I could find with grep) and here's the results. Not sure it's worth doing; anyone want to chime in? Although this construct is 'exciting'... luceneSort || sortMissingFirst && !reverse || sortMissingLast && reverse ? '' : 'zzz';,Dear God! You mean the intent here is: return (pf.filter==null && pf.postFilter==null) ? qr.getDocSet() : null; ??? gotta confess I just saw the pattern and jumped to conclusions; hadn't examined the code at all. But you've just made the job tougher... Wait; I know! I'll just write something in awk to convert everything in the source tree. The ternary operator really annoys me for this very reason... rant; rant; rant.....,the last line is: return pf.filter==null && pf.postFilter==null ? qr.getDocSet() : null; This is correct; but feel free to add parens to clarify.,Sorry for the spam; but there are backslashes in front of the pipe symbols in all the REs; silly website doesn't let them through |,I love it when a better solution occurs to me the instant I post something..... ||[^\(]+==.*?,,,,,,,,,,,,,,,
26551,,,,,x,,,used struts for 2 years now - no clue whether it has been fixed,Hi; Taking a look at this old bug. It puzzles me what it's about. If you're still interested; could you be more specific as to what specific error messages you are looking for? Otherwise; I'd like to close it. Thanks.,As per http://nagoya.apache.org/bugzilla/show_bug.cgi?id=15947; please i) please configure Bugzilla to also allow for 1.4 since it appears to be this; ii) provide a command-line parameter/build.xml target that tells in detail about the velocity version. Both -debug and -verbose don't appear to provide any better information than the velocity.log file. But I am happy to attach the velocity.log and both tee'ed ant-runs if you wish.,I'm guessing you'd need to either patch the source; or invoke Ant with the -debug or -verbose options. What version of Velocity are you using? 1.0 is very old.,the html file basically only has <!-- start the processing --> åÊåÊ#header() åÊåÊåÊåÊåÊåÊ#footer() <!-- end the processing --> I figured some more information could be found in velocity.log rhauser@RHAUSERPCGF590K:~/<7>anakia/build> g error * velocity.log:Mon Jan 13 19:50:24 CET 2003 [error] ResourceManager : unable to f ind resource 'VM_global_library.vm' in any resource loader. velocity.log:Mon Jan 13 19:50:24 CET 2003 [info] Velocimacro : error using VM åÊlibrary template VM_global_library.vm : org.apache.velocity.exception.ResourceN otFoundException: Unable to find resource 'VM_global_library.vm' velocity.log:Mon Jan 13 19:50:25 CET 2003 [error] RHS of #set statement is null . Context will not be modified. ./site.vsl [line 2; column 3] rhauser@RHAUSERPCGF590K:~/<7>anakia_rh/build> but how does that get me closer to being able to rebuild the ant-faq with anakia from the faq.xml? see also: http://nagoya.apache.org/bugzilla/show_bug.cgi?id=15949,,,,,,,,,,,,,,,,,
38439,,,,,,,,Appled patch with some changes to compile with the new public rendering API.,,,,,,,,,,,,,,,,,,,,,
398,,x,,,,,,+1 overall. Here are the results of testing the latest attachment http://issues.apache.org/jira/secure/attachment/12509655/patch.txt against trunk revision 1227927. +1 @author. The patch does not contain any @author tags. +1 tests included. The patch appears to include 3 new or modified tests. +1 javadoc. The javadoc tool did not generate any warning messages. +1 javac. The applied patch does not increase the total number of javac compiler warnings. +1 findbugs. The patch does not introduce any new Findbugs (version 1.3.9) warnings. +1 release audit. The applied patch does not increase the total number of release audit warnings. +1 core tests. The patch passed core unit tests. +1 contrib tests. The patch passed contrib unit tests. Test results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/882//testReport/ Findbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/882//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html Console output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/882//console This message is automatically generated.,,,,,,,,,,,,,,,,,,,,,
2557,x,,x,,,,,I like MemoryResourceCalculator (or MemoryBasedResourceCalculator) better as well; that was my first choice; and is what the attached patch uses. Arun went with that on YARN-2 but people objected; if people are OK with it now then let's go with it. I don't think proliferation of many class names will be an issue.,,,,,,,,,,,,,,,,,,,,,
45983,,,,,x,,,No longer required; solved with THRIFT-1366. There will be no D7 support.,Sorry for the spam - I just discovered that JIRA allows to have sub-tasks,,,,,,,,,,,,,,,,,,,,
29404,,,,,,x,,To be consistent with the preferred syntax in JIRA-1146; we will adopt the following syntax: <remoteAnalysisEngine remoteReplyQueueScaleout='nn1' > .... </remoteAnalysisEngine> I will start to do the work based on the above syntax if there is no objection _x0089_ÛÒ Tong,,,,,,,,,,,,,,,,,,,,,
4691,,x,,,,,,Fixed; closing,,,,,,,,,,,,,,,,,,,,,
46218,,,,,,,,was introduced with THRIFT-1267,,,,,,,,,,,,,,,,,,,,,
5721,x,,,,,,,All of the components in the configuration get reset before parsing begins. This gives each component an opportunity to read features and properties from the configuration; and also to set its internals to the state it needs to be in before it is used by the configuration.,Thanks for the reply. Can you clarify one more thing. I'm using XML schemas only and no DTD; so the only option is what you are suggesting. Also; you are saying that it gets dumped on reset to remove entities from the previous parse; but there was no previous parse. It is the first/initial parse that gets them reset. Is that the correct thing to do? I can see that they would need to be reset per parse. Thanks; Julio,This is working as designed. The table of entities in the XMLEntityManager is transient. This table gets filled by the DTDScanner as it reads entity declarations in the DTD. It gets dumped on reset to remove entities from the previous parse. If you want the parser to recognize arbitrary entities (which aren't declared anywhere) then you should probably create your own parser configuration; perhaps one which extends one of the Xerces configurations. If you extended IntegratedParserConfiguration for instance; and overloaded createEntityManager with your own extentsion of XMLEntityManager which you load with some persistent predefined entities; you can achieve what you want. Just be warned that these implementation classes may change between releases. If you're comfortable with that; then this approach should work for you.,,,,,,,,,,,,,,,,,,,
61118,,,x,,,,,I do have some interest in working on this; but it's not currently on my radar. Implementing SOLR-4241 would illustrate the issues that need fixing ... although if this is tackled first; writing SOLR-4241 would be much easier.,I have closed older issues SOLR-2728 and SOLR-2729; any work on those issues can continue in this one. SOLR-2729 has a patch attached. I haven't checked to see if this issue is a duplicate; but I would not be surprised if it is. This is part of an effort to close old issues that I have reported. Search tag: elyograg2013springclean,Here are some general ideas; preliminary because I have not taken a close look at the code yet. For reference; here is a completed status response on a full-import from 3.5.0:  <?xml version='1.0' encoding='UTF-8'?> <response>  <lst name='responseHeader'>   <int name='status'>0</int>   <int name='QTime'>0</int> </lst> <lst name='initArgs'>   <lst name='defaults'>     <str name='config'>dih-config.xml</str>   </lst> </lst> <str name='status'>idle</str> <str name='importResponse'/> <lst name='statusMessages'>   <str name='Total Requests made to DataSource'>1</str>   <str name='Total Rows Fetched'>11287894</str>   <str name='Total Documents Skipped'>0</str>   <str name='Full Dump Started'>2012-04-03 17:38:01</str>   <str name=''>Indexing completed. Added/Updated: 11287894 documents. Deleted 0 documents.</str>   <str name='Committed'>2012-04-03 20:16:32</str>   <str name='Total Documents Processed'>11287894</str>   <str name='Time taken '>2:38:31.314</str> </lst> <str name='WARNING'>This response format is experimental.  It is likely to change in the future.</str> </response>  I was thinking it might be a good idea to have two response sections in addition to the echoParams section already mentioned - one for a human readable response and one for a relatively terse machine readable response. The human readable version would be fairly open to change; and could include extra verbiage so it's very understandable for a person. The machine readable version would have more elements; each of which is very simple; probably just a numeric value or a true/false indicator. A design decision needs to be made early - do we include all elements in every response (with the value set to zero; blank; or false); even if they don't apply to the current status? My first instinct is to include all elements; but maybe that's wrong.,Here's an idea; at least for 3x; assuming it's not unilaterally killed by the bug-fix-only mode: A configuration knob to use the old response or the new response. It would default to old. For 4.0; that configuration knob seems like a good idea; defaulting to the new response. In 4.1 or 5.0; the old response gets removed.,I don't think this can be done for 3.x as the branch is in bug-fixes-only mode. Also; this will create backwards-incompatible changes for users' scheduling programs; so this kind of thing is better suited for a new major release.,I personally would like to see this included in 3x; since that's what I use. How do the rest of you feel about that?,,,,,,,,,,,,,,,,
60817,,,,,,,,removing fixVersion=4.0 since there is no evidence that anyone is currently working on this issue. (this can certainly be revisited if volunteers step forward),,,,,,,,,,,,,,,,,,,,,
58767,,,,,,x,,Unfortunately no: - looking at ServerSession.userAuth where it sets the state to Running: åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊbuffer = createBuffer(SshConstants.Message.SSH_MSG_USERAUTH_SUCCESS; 0); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊwritePacket(buffer); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊsetState(State.Running); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊthis.authed = true; åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊthis.username = username; åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊunscheduleAuthTimer(); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊscheduleIdleTimer(); the event is triggered before this.username is updated so the observer doesn't have access to that value. If the set is moved to later than I can eliminate two hacks (I suspect this.username should be updated far earlier when userauth_request arrives; but that would be a change in getUsername's semantics); however ... - as I mentioned above; instead of overloading ServerSession I should be defining my own service type and adding that; I've created SSHD-211 and attached a patch to illustrate the basic idea,Andrew; do you think the above commit is sufficient for your needs ?,URL: http://svn.apache.org/viewvc?rev=1434652&view=rev,This should solve my immediate problem (once the git repos are settled I will apply and test). However; looking at my code (which is now kind of working!) and SSHD-205 I suspect there's a better more invasive solution. Since my service is custom; instead of overloading ServerSession and looking for events; I should be registering my own service with SshServer. To sketch the idea out: - add an SshService factory to SshServer that maps a service name onto a service. The table would include ssh-userauth (rfc4252); and ssh-connection (rfc4254); and my custom service - separate ssh-userauth and ssh-connection from ServerSession so that they are are standalone services; and the latter just worries about the transport (rfc4253) - when the transport receives SSH_MSG_SERVICE_REQUEST; it could then instantiate the requested service and pass non-transport requests along to it - ssh-userauth; once authentication has finished; would also instantiate the requested service (passing it the authenticated user credentials) and update ServerSession My custom service would then see the following events from ServerSession / ssh-userauth - authenticated / requested when instantiated (or perhaps a separate explicit message) - a separate closed message when ServerSession sees the connection dropped et.al. Once the git repo is up; I might just play with the idea. It is very invasive.,The SSHD repository is in maintenance mode; so I can't commit what I've done now; but I've added a Session#getState() method and a SessionListener#sessionChanged() method so that you will be able to register a listener and be informed of session state changes. In your case; you'll have to check the sessionChange call with a Running state and the sessionClosed call.,,,,,,,,,,,,,,,,,
13391,,,,,,,,I am also having the same issue with a java.sql.Timestamp based attribute. The date I entered into the field was 'not a date'. Of course; XWorkBasicConverter fails to convert successfully and throws an XWorkException; then it is downhill from there on. When attempting to find the method to call in OgnlRuntime it appears to look for a String parameter; when it should be looking for the java.sql.Timestamp parameter.,I think it's related to the same problem with primitives (and wrappers) convertion,,,,,,,,,,,,,,,,,,,,
20748,,,,,,,,Integrated in Apache Wicket 1.4.x #58 (See [http://hudson.zones.apache.org/hudson/job/Apache%20Wicket%201.4.x/58/]) åÊåÊåÊåÊ,,,,,,,,,,,,,,,,,,,,,
62999,,,,,,,,@Noble Paul I cooked something resembling a backport here SOLR-3079,,,,,,,,,,,,,,,,,,,,,
28310,,,x,,,,,Change the element type of 'attributes' to FSAttribute.,Side note: I was surprised that nothing in UIMA detected this situation at run-time. Apparently; the element type can be anything. It's not enforced.,,,,,,,,,,,,,,,,,,,,
70304,x,x,,,,,,Fine. So I resolve this with just upgrading the used SLF4J API,,,,,,,,,,,,,,,,,,,,,
20729,x,,,,x,,,Sorry; I've reread the IOC code; and you're right. This is indeed not an issue. My apologies..,,,,,,,,,,,,,,,,,,,,,
48885,,,x,,,,,I'm working with Liferay 5.1.2 / Tapestry 4.0.2 and that patch did not work for me. The IllegalStateException I obtain is thrown by service method of AbstractEngine: Error producing exception report: java.lang.IllegalStateException ERROR [STDERR] Session id : ERROR [STDERR] ERROR [STDERR] java.lang.IllegalStateException ERROR [STDERR] com.liferay.portlet.StateAwareResponseImpl.setRenderParameter(StateAwareResponseImpl.java:154) ... ERROR [[RP]] Servlet.service() for servlet RP threw exception [exec] java.lang.IllegalStateException Code: @InjectObject('service:tapestry.portlet.ActionResponse') public abstract javax.portlet.ActionResponse getActionResponse(); getActionResponse().sendRedirect(Portal-Login-Url); The Exception is thrown; but the redirect still works and every action done before seems to be rolled back (redirect to Portal-Login works; but Portlet-Login not) So i modified the service method of AbstractEngine to catch IllegalStateException: public void service(WebRequest request; WebResponse response) throws IOException { ... catch (PageRedirectException ex) { åÊåÊåÊåÊhandlePageRedirectException(cycle; ex); } catch (RedirectException ex) { åÊåÊåÊåÊhandleRedirectException(cycle; ex); } catch (StaleLinkException ex) { åÊåÊåÊåÊhandleStaleLinkException(cycle; ex); } catch (StaleSessionException ex) { åÊåÊåÊåÊhandleStaleSessionException(cycle; ex); } //New catch(IllegalStateException ex) { åÊåÊåÊåÊåÊhandleIllegalStateException(cycle; ex); } ... I know; thats not the ideal solution; but it works with Liferay.,,,,,,,,,,,,,,,,,,,,,
26184,,,,,,,,patch applied.,,,,,,,,,,,,,,,,,,,,,
56783,,,,x,,,,This test is not appearing in the nightly build results. When it does (and is passing); I'll close this issue.,http://svn.apache.org/viewvc?view=rev&revision=654588,Discussion related to this issue can be found in the archives.,,,,,,,,,,,,,,,,,,,
75082,,,,,,x,,I intend to close this issue as fixed in a week's time. Please post your comments if you're able to test by then.,,,,,,,,,,,,,,,,,,,,,
20061,,,,,,,,Fixed with r1097472.,,,,,,,,,,,,,,,,,,,,,
47248,,,,,,,,In r681863,The attached patch should fix this issue,,,,,,,,,,,,,,,,,,,,
35420,,,,,,x,,put backdoor cleanup v3.3 target,Can we move this out to 3.3.0 ? If so; mark it accordingly.,,,,,,,,,,,,,,,,,,,,
61898,,,x,,,,,bulk close for 3.4,Jenkins is reporting that branch_3x solr/src/test compilation is failing after this issue was committed. I've opened SOLR-2653 to address the problem.,trunk rev: 1146685 branch 3x rev: 1146806 Thanks David and Peter!,Patch to reflect relocated code.,No problem; man! I'm just happy you're doing the work on the reorg instead of me....,I'm just waiting for the recent code reorganization to get back to 3x I'm working on it! Hopefully finished today or tomorrow.,I'm just waiting for the recent code reorganization to get back to 3x to make this easier on myself; especially the merge step. I could have two patches; but it seems like the code reorg is hard enough as it is; making additional changes in the underlying 3x code base would just add useless complexity. But I'm willing to be convinced otherwise.,If nobody objects I'll commit this Monday. +1,don't wait too long; no need to wait until monday. +1; commit it now! Esp for a bug fix; unless one thinks there is something likely controversial about it; or one is unsure about something and is thus requesting feedback.,OK; I've applied the patch to both 3x and trunk and it looks good. If nobody objects I'll commit this Monday. don't wait too long; no need to wait until monday.,OK; I've applied the patch to both 3x and trunk and it looks good. If nobody objects I'll commit this Monday.,Here's the patch I used. As before; it's just David's with the extra changes omitted.,I'm trying to attach it; but jira is throwing a stack trace. I mentioned this problem on #asfinfra an hour or so ago - medthomas has tracked down the problem; to the ASF JIRA plugin needing to be updated for the just-upgraded JIRA instance; and he's working on fixing the problem.,Quick test works - patched the 3.2 source and rebuilding the directory and subdirctory listings work as expected. The patch I used is the same as David's but just re-rolled without the changes to SolrDisptatchFilter.java I'm trying to attach it; but jira is throwing a stack trace.,The relayout of import statements in SolrDisptatchFilter.java is inadvertent. The QueryRequest.java one-liner was a null-check that I felt was an improvement so that I didn't have to pass in an empty params list to QueryRequest's constructor.,Thanks for the patch. Is every thing in there related to this bug? Some of it looks like other cleanup.,The attached patch fixes this bug and adds new tests for a directory listing and getting a file. This bug was triggered with the introduction of SOLR-2263 in which RawResponseWriter was changed to implement BinaryQueryResponseWriter. This wasn't a problem in and of itself; but the SolrDispatchFilter checks if a response writer is the binary variant and if so calls the write(OutputStream...) variant. But the responses from ShowFileRequestHandler that list directory contents are incompatible with the RawResponseWriter if RawResponseWriter's write(OutputStream...) method is uses; instead of a character based stream. The solution was to move the defaulting of the 'raw' response type from ShowFileRequestHandler.init() into into a condition within handleRequestBody() where it knows the response is a file.,This ought to be a trivial fix; so I hope we can get it in 3.1.1; or is 3.3 going to be the next minor version?,Bulk move 3.2 -> 3.3,Same for trunk $ svn info Path: . URL: https://svn.apache.org/repos/asf/lucene/dev/trunk/solr Repository Root: https://svn.apache.org/repos/asf Repository UUID: 13f79535-47bb-0310-9956-ffa450edef68 Revision: 1130610 Node Kind: directory Schedule: normal Last Changed Author: rmuir Last Changed Rev: 1130527 Last Changed Date: 2011-06-02 14:58:22 +0200 (Thu; 02 Jun 2011) Stacktrace: INFO: [] webapp=/solr path=/admin/file params={} status=0 QTime=7 Jun 2; 2011 5:49:29 PM org.apache.solr.common.SolrException log SEVERE: java.io.IOException: did not find a CONTENT object         at org.apache.solr.response.RawResponseWriter.write(RawResponseWriter.java:113)         at org.apache.solr.servlet.SolrDispatchFilter.writeResponse(SolrDispatchFilter.java:333)         at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:261)         at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)         at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)         at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)         at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)         at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)         at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)         at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)         at org.mortbay.jetty.handler.HandlerCollection.handle(HandlerCollection.java:114)         at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)         at org.mortbay.jetty.Server.handle(Server.java:326)         at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)         at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)         at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)         at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)         at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)         at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)         at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582),,
57081,,,,,,,,Closing as fixed.,,,,,,,,,,,,,,,,,,,,,
12989,,,,,,,,Already resolved with WW-3414,,,,,,,,,,,,,,,,,,,,,
12834,,,,,,,,Integrated in Struts2 #551 (See https://builds.apache.org/job/Struts2/551/) WW-3914 solves problem with returning always system implementation of FileManager (Revision 1405930) Result = SUCCESS lukaszlenart : Files : /struts/struts2/trunk/xwork-core/src/main/java/com/opensymphony/xwork2/util/fs/DefaultFileManagerFactory.java /struts/struts2/trunk/xwork-core/src/test/java/com/opensymphony/xwork2/util/fs/DefaultFileManagerFactoryTest.java,,,,,,,,,,,,,,,,,,,,,
74301,x,,,,,,,Applied in r648154. Thanks!,,,,,,,,,,,,,,,,,,,,,
70122,x,,,,,,,applied patch (thanks) in r1055887,The patch enhances the tests to reproduce the problem and a simple bugfix.,,,,,,,,,,,,,,,,,,,,
20954,,,,,,,,this setting is global for all modal windows and so tweaking it from the modalwindow class doesnt really make sense. a cleaner solution then overriding the method with an empty function is to use iheadercontributor and output a bit of js into the page 'Wicket.Window.unloadConfirmation = false;',,,,,,,,,,,,,,,,,,,,,
36205,,,,,,,,as for V2.1.4 and later; we do not seen any reproduce; so mark this issue as fixed,,,,,,,,,,,,,,,,,,,,,
77185,,,,,,,,Closing all resolved/fixed issues of already released versions of Roller.,,,,,,,,,,,,,,,,,,,,,
36911,,,,,,,,This is on top of http://svn.apache.org/repos/asf/myfaces/trinidad/branches/2.0.0.1-branch,Reopening this for inclusion in 2.0.0.1-branch,ASF enabled patches,Attaching a patch file created with updated svn.,tri-doc-20110902.patch contains the documentation changes for this patch,Documentation change for patch provided.,The patch (tri-code-24082011.patch) introduces a way to specify css rules specific to touchScreen devices. TouchScreen device agents have capability marked by 'touchScreen' with valid values of none; single and multiple. Syntax implemented allows user to specify rules as follows: @agent (touchScreen:none) { åÊåÊåÊ/* Some styles that should not be rendered on touchScreen devices. */ } @agent (touchScreen:single) { åÊåÊåÊ/* some styles specific for touchScreen with single touch. */ } @agent (touchScreen:multiple) { åÊåÊåÊ/* some styles specific for touchScreen with multiple touch. */ } @agent (touchScreen) { åÊåÊåÊ/* some touchScreen specific styles for all touch devices: both single and multiple touch. */ } @agent webkit and (version: 9) and (touchScreen:single) { åÊåÊåÊ/* some touchScreen specific styles for touch devices with single touch running webkit version 6. */ } @agent gecko and (version: 6); webkit and (touchScreen:single) { åÊåÊåÊ/* styles to be rendered on version 6 of gecko agent and single touch devices running webkit */ },Patched based on @agent (touchScreen) syntax,Will be backing this out. After looking into this more; the separate renderkit for tablets is overkill and causes issues with people that have made custom skins. I am thinking that an extension to @agent in the CSS skin parser would be preferable.,Commit the patch,Patch file implementing this fix on top of http://svn.apache.org/repos/asf/myfaces/trinidad/trunk,,,,,,,,,,,
33144,,,,,,x,,Closing because this has been in RESOLVED state for over one year; if it turns out to not be fixed please reopen.,all discussion http://www.mail-archive.com/tuscany-dev@ws.apache.org/msg21712.html,,,,,,,,,,,,,,,,,,,,
67087,,,,,,,,resolved,,,,,,,,,,,,,,,,,,,,,
8053,x,,,,,,,Robert; åÊåÊåÊåÊYour patch is in; please help verify; thanks. Rgds; PeiYong,Created an attachment (id=2169) .NET Project Files in Attached Zip File,,,,,,,,,,,,,,,,,,,,
57170,,x,,,,,,Fixed thus: http://svn.apache.org/viewvc?rev=574613&view=rev,Scheduled to version 4.2.,This affects 4.1.3. I'll let Farid decide whether it's simple enough to do for 4.2 or if we need to schedule it for later.,This is good improvement.,Assigned to Farid; the Windows infrastructure maintainer.,Makes sense to me. What do you think about it; Farid?,> BUILDDIR should default to the source directory; that is; the same directory containing the generate.bat script. ...or the current directory if this directory is different from the directory where the generate.bat script is located.,,,,,,,,,,,,,,,
15560,,,,,,x,,Since no additional information has been provided and we can't duplicate; I'm marking this resolved. Please reopen if you can provide additional information that helps us replicate the problem.,Can anyone provide more information about the original report; or should we close this report for lack of additional information?,I have been looking through the code for the Dispatcher Filter; and the line causing the problem is after the line for accessing the static content. Additionally; I added 'webwork.action.extension=html' to the showcase app; and could not duplicate the error you were seeing. The only difference was that I needed to modify the href/action values from .action to .html (there also seems to be a setter issue at the moment). I suspect this might be a configuration problem. Can you provide more information about your environment? Page source from the page that has the problem? Thanks; Ian,I have been looking through the code for the Dispatcher Filter; and the line causing the problem is after the line for accessing the static content. Additionally; I added 'webwork.action.extension=html' to the showcase app; and could not duplicate the error you were seeing. The only difference was that I needed to modify the href/action values from .action to .html (there also seems to be a setter issue at the moment). I suspect this might be a configuration problem. Can you provide more information about your environment? Page source from the page that has the problem? Thanks; Ian,Yes; as I said in first topic; it works if extension is 'action'. Does webwork team treat it as a bug? or limitation for webwork?,I just realized what the issue is. ANY html in your application is going to be mapped to an action - even if it is a static page. The dojo widgets have a .html that is used as a basic template; and having the html extension is causing the problem. Try this - change the extenstion to anything other than .HTML - my guess is that it will work.,So let me get this straight - the error message goes away under two conditions. First is removing the <ww:head theme='ajax' /> tag; and the other is removing the theme='ajax' from the submit button. Is that correct? What theme do you have the form under? Can you provide the entire JSP page?,oh; it is not about <ww:submt...>. If I remove <ww:head theme='ajax'/>; the exception will disappear. But obviously; it becomes non-ajax call; which redirect to result page.,Once I change my code from: ... <ww:submit value='post' theme='ajax' resultDivId='change'/> .... To <ww:submit value='post'> It works well. So I think it is a bug in webwork ajax part. Further; this exception happens when it just gets into this page ( not throws when submit).,Yes; it is 'html' . I did not touch this option. I tested it in another pc in similar configuration. The exception persist : com.opensymphony.xwork.config.ConfigurationException: There is no Action mapped for namespace /webwork/dojo/webwork/widgets and action name BindButton. Check if there is such an action name with such namespace defined in the xwork.xml and also if such an action class exists. Check also the log to see if the action class is successfully loaded. at com.opensymphony.xwork.DefaultActionProxy.<init>(DefaultActionProxy.java:72) at com.opensymphony.xwork.DefaultActionProxyFactory.createActionProxy(DefaultActionProxyFactory.java:46) at com.opensymphony.webwork.dispatcher.DispatcherUtils.serviceAction(DispatcherUtils.java:193) at com.opensymphony.webwork.dispatcher.FilterDispatcher.doFilter(FilterDispatcher.java:184) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173) at com.opensymphony.module.sitemesh.filter.PageFilter.parsePage(PageFilter.java:118) at com.opensymphony.module.sitemesh.filter.PageFilter.doFilter(PageFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173) at org.tuckey.web.filters.urlrewrite.UrlRewriteFilter.doFilter(UrlRewriteFilter.java:738) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173) at com.edgenius.paradise.webapp.filter.GZIPFilter.doFilterInternal(GZIPFilter.java:42) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:76) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173) at org.displaytag.filter.ResponseOverrideFilter.doFilter(ResponseOverrideFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:75) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:76) ................... [@APPNAME@] ERROR [http-8080-Processor23] DispatcherUtils.serviceAction(210) | Could not find action com.opensymphony.xwork.config.ConfigurationException: There is no Action mapped for namespace /webwork/dojo and action name iframe_history. Check if there is such an action name with such namespace defined in the xwork.xml and also if such an action class exists. Check also the log to see if the action class is successfully loaded. at com.opensymphony.xwork.DefaultActionProxy.<init>(DefaultActionProxy.java:72) at com.opensymphony.xwork.DefaultActionProxyFactory.createActionProxy(DefaultActionProxyFactory.java:46) at com.opensymphony.webwork.dispatcher.DispatcherUtils.serviceAction(DispatcherUtils.java:193) at com.opensymphony.webwork.dispatcher.FilterDispatcher.doFilter(FilterDispatcher.java:184) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173) at com.opensymphony.module.sitemesh.filter.PageFilter.parsePage(PageFilter.java:118) at com.opensymphony.module.sitemesh.filter.PageFilter.doFilter(PageFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173) .......................,AFAIK Matt uses 'html' as extension for AppFuse; not 'HTML' Can you please recheck with this setting and tell us if exceptions are still thrown? Set this in webwork.properties: webwork.action.extension=html,,,,,,,,,,,
4758,,,,,,,,See comments above; closing,The error text states the problem of this issue. The elements are not valid according to the config's schema file. If you have questions; the schema for xsdconfigs lives in src/configschema/schema,,,,,,,,,,,,,,,,,,,,
78973,,,,,,x,,Point taken. Migration query is following in this case 'Update person set username='rave2011.myopenid.com'; openid='http://rave2011.myopenid.com/&#39; where username='http://rave2011.myopenid.com/&#39;'. We can add such migration steps in release also with some migration.txt or in change log file itself. Ideas?,,,,,,,,,,,,,,,,,,,,,
1101,,,,,,,,Please consider contributing your ruby binding; we'd love to include it in the release along with python; perl; etc...,,,,,,,,,,,,,,,,,,,,,
15330,,,,,,,,As of r438174 ; the shopping-cart is parked in the sandbox (sandbox/struts2/apps/shopping-cart) waiting to see if someone's wants to maintain it; but it hasn't been removed from the repository yet.,,,,,,,,,,,,,,,,,,,,,
79349,,,,,,,,Closing old resolved issues,,,,,,,,,,,,,,,,,,,,,
8640,,,,,,,,I think you want the XMLBEANS project; the xml to object mapping; rather than XBEAN; reusable server components,To reproduce; generate for the attached schema using defaults. Create an instance of ACORD and get the text. Can also see the bad behavior by creating sample XML using SampleXMLUtil.createSampleForType.,,,,,,,,,,,,,,,,,,,,
78329,,,,,,,,Issue fixed.,,,,,,,,,,,,,,,,,,,,,
36052,,,,,,,,Moving these all to a 'Doc 3.x' release version.,r1085213.,,,,,,,,,,,,,,,,,,,,
36048,,,,,,,,Right now ET_CALL; ET_NET and ET_TASK are the same unless task_threads is set > 0 So; ET_DEFAULT_THREAD_TYPE could just be ET_TASK if you want and it would accomplish the same thing.,,,,,,,,,,,,,,,,,,,,,
918,,,,,,x,,You should also consider using Avro for the marshalling/unmarshal of the records. http://avro.apache.org/ Lots of benefits - in particular it's cross-language. Re writing to disk - perhaps just re-use the ZK WAL code and write to a disk that's not storing the transactional log.,Several comments: Aspects: ah; these aspects. I always though of it as a software development process; not as providing a solution for compiling different versions of the code. I actually looked if Java already had something similar like the C preprocessor but didn't find it (I'm afraid I'm still from the pre-Java era). But it seems like a great solution. Binary traces: I thought about that solution but was forgetting it due to idea of not messing with the server code thus using the actual ZK traces. However; together with the need of extending those traces and the idea of using AspectJ; it seems a neat solution. Disk overhead: I was forgetting this problem. Using some kind of ring buffer seems to be a solution but we are actually interested in understanding failures; so keeping the info in memory doesn't seem to be a good idea (the failure may be too radical and we lose the info).,http://www.eclipse.org/aspectj/ http://en.wikipedia.org/wiki/AspectJ I use this for network fault injection testing - instrumenting network operations with random failures. Works extremely well and I don't need to modify the original source at all.,You may consider having a look at ZOOKEEPER-512 for a reference within the context of ZooKeeper.,Re: Aspects; Miguel take a look at AspectJ/Aspect Oriented Programming. Basically allows you to hook code into preexisting code if I understand it correctly. Sort of like auxilary methods in CLOS.,(Assumed JIRA picked up email replies. Seems not >:/) As far as I've seen; this overhead comes in two forms; CPU and disk. CPU overhead is mostly due to formatting. Disk obviously because tracing will fill your disk fairly quickly. Perhaps something could be done to combat both of these. To fix the formatting problem we could use a binary log format. I've seen this done in C++ but not in java. The basic idea is that if you have TRACE('operation %x happened to %s %p'; obj1; obj2; obj3); a preprocessor replaces this with TRACE(0x1234; obj1; obj2; obj3) where 0x1234 is an identifier for the trace. Then when the trace occurs a binary blob [0x1234; value of obj1; value of obj2; value of obj3] is logged. Then when the logs are pulled of the machine you run a post processor to do all the formatting and you get your full trace. Regarding the disk overhead; traces are usually only interesting in the run up to a failure. We could have a ring buffer in memory that is constantly traced to; old traces being overwritten when the ring buffer reaches it's limit. These traces should only be dumped to the filesystem when an error or fatal level event occurs; thereby giving you a trace of what was happening before you fell over. -Ivan,The idea behind using ZK's log4j logs was to modify ZK's server-side code as less as possible. ZK is used in critical applications so a design principle that we are using is to avoid anything that may impact its reliability. In that sense; ZK's WAL is probably not a good option as it is specially critical for the correct operation of ZK. Another option that occurred to me was to create another log4j logger; which would be used specifically for logging the traces we need. Either if we use the original log4j logger or a new one; we can improve the performance using the same mechanisms that are used to make the WAL efficient. In relation to Aspects; I didn't understand what do you mean. Can you give me some pointers? Thanks!,Typically log4j logs are expected to be consumed by users - i.e. debugging; here you're really talking about output that will be machine processed. Is this really logging in the log4j typical sense; perhaps a separate mechanism should be used? Another problem with log4j logging is that changes to the message format; say to make it more 'readable'; can cause problems for the down stream processor. Not to mention that a separate mechanism could be made much more efficient than the general log4j log mechanism. Perhaps ZK's own WAL could be used for this - reuse the WAL code or write the information directly to the ZK transaction log (might not be such a good idea; but should be considered as an option). Additionally you should consider something like Aspects for this project. This is a cross-cutting feature; something that aspects are well suited for. A benefit of this approach is that it would allow those interested in the feature to enable it while those uninterested would incur zero performance penalty.,Let me give a longer explanation of the project. Practical experience with Zookeeper has shown that sometimes there are failures whose causes are hard to understand. Some of these failures may be caused by elusive bugs in the code; others may be due to failures rarer than crashes; say corruptions of data somewhere in a server. Zookeeper's traces (i.e.; logs in TRACE level) provide some information that can be helpful to understand what happened. For instance; they contain information about the clients that are connected; the operations issued; etc. However; in real deployments with many clients (say; hundreds); traces are typically turned off to avoid the high overhead that they cause. Furthermore; the data in the traces is probably not enough for our purposes because it does not include; e.g.; the replies to operations or the data values. The project involves 3 subtasks: 1- improve the efficiency of logging 2- improve the traces with additional information needed 3- build the checking tool,,,,,,,,,,,,,
34486,x,x,,,,,,Odd that you can't get the attached to build as it builds fine for me with the current latest code; never mind because I've tried it for you and yes this has fixed the problems and it now works. Thanks Jim! (Side note; I agree 100% about moving all the non-Java container specific tests out of the java container project),,,,,,,,,,,,,,,,,,,,,
29014,x,,,,,,,applied patch; slight indentation reformating. Thanks Tommaso!,,,,,,,,,,,,,,,,,,,,,
31191,,,,,x,,,Fixed. Sorry folks; the 2 contributions ASM_8001_Java and ASM_12011 did not get committed from my local machine since the projects somehow were not part of my Eclipse workspace when I did the commits of these changes,,,,,,,,,,,,,,,,,,,,,
13977,,,,,,,,Assigning this to future until the dependent XWork enhancement is made.,,,,,,,,,,,,,,,,,,,,,
77769,,,,,,,,Closing resolved but not fixed (i.e.; duplicate; invalid; cannot reproduce; etc.) issues.,,,,,,,,,,,,,,,,,,,,,
20237,,,,,,,,See my comment in WICKET-3093.,,,,,,,,,,,,,,,,,,,,,
33755,,,,,,,,Closing the issue now that it has been resolved.,,,,,,,,,,,,,,,,,,,,,
29161,,,,,,,,Already fixed in UIMA-1379.,I think the source files should be within the org.apache.uima.tika package and not in org.apache.uima.,,,,,,,,,,,,,,,,,,,,
33117,,,,,,,,I've just made some observations on the tuscany-user mailing list which should appear in the mailing list archives shortly; under the thread that contains http://www.mail-archive.com/tuscany-user@ws.apache.org/msg02162.html,,,,,,,,,,,,,,,,,,,,,
50490,,,,,,,,Integrated in tapestry-trunk-freestyle #515 (See [https://builds.apache.org/job/tapestry-trunk-freestyle/515/]) åÊåÊåÊåÊTAP5-1621 - Fixed test joshcanfield : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1167447 Files : * /tapestry/tapestry5/trunk/tapestry-ioc/src/test/java/org/apache/tapestry5/ioc/internal/services/TypeCoercerImplTest.java,,,,,,,,,,,,,,,,,,,,,
45250,,,x,,,,,Resolving as fixed. We can do better positioning of the comments once someone has a concrete use case for that.,You can associate comments with cells; but it isn't all that easy. The 'findCellComment' on HSSFCell shows how to do it; which is: For every TextObjectRecord; find the CommonObjectDataSubRecord of type OBJECT_TYPE_COMMENT that precedes it On that CommonObjectDataSubRecord; get the object ID Find a NoteRecord with a shape ID that matches the object ID just found The NoteRecord holds the row and column details Normally the ordering of records in the file is CommonObjectDataSubRecord; TextObjectRecord; NoteRecord; cells; so you'd need to grab things as they went passed so they're to hand by the time you get to the cells.,Thanks! Patch applied (with minor changes) in revision 788364. Would there be some way to associate the comments with the cell's they apply to? I'd like to see the comment of a cell outputted along with the cell value. I'm leaving this issue until this has been resolved.,Patch adds text extraction from text shapes (comments and other),,,,,,,,,,,,,,,,,,
34779,x,,,,,,,fix works~,Commit ddce361ffa08306423f200eba9c03b3a171d8679 in branch refs/heads/master from Daniel Gruno [ https://git-wip-us.apache.org/repos/asf?p=trafficserver.git;h=ddce361 ] TS-1858: Fix redefinition of timersub on OmniOS with the ESI plugin.,,,,,,,,,,,,,,,,,,,,
27656,,,,,,x,,We'll look at the issue for 1.1,Multiple errors get overwritten much as multiple return values do. Look in ValidatorResult.java; line 117: hResults.put(field.getKey(); result); The problem is; both errors and values should be indexed in ValidatorResult; with this modification; you have to manually construct the key (using ValidatorUtils.replace()); but at least you don't lose info. I confess I'm not using Struts; but I'm using Validator in standalone fashion; so maybe my needs are very particular. MatÌ_as.,Created an attachment (id=4188) Proposed fix,I'm not so sure that this is a bug. In most cases; an indexed property is going to be used in a table-style of input with an iterator. You wouldn't want to display each error on the line; you'd display them at the top. If we went to storing indexed property error messages on the full property with index; you'd need to put an iterator around bean:errors in Struts (for example) to generate all the error messages. Willing to hear counter arguments. James,,,,,,,,,,,,,,,,,,
15698,,,,,,,,I believe this is an issue. I have an action saveAction which I want to chain to editAction whenever there is a validation error. This is often necessary because a JSP will be displayed which has dynamic content such as a selectable list of items. However; if editAction has validation support; it will never be executed (even if it would validate successfully).,As pointed out in my last comment; we should not consider this as an issue. Anyway; thanks for bringing up this discussion and offering your help.,As Alexandru already pointed out in a comment for WW-1093: The desired behaviour can be achieved without those changes if the chain-to action doesn't have the validation interceptor in place. It is not the best idea to set up ties between interceptors; they should really work independently. Also; there might be situations when you want to validation in place for the chain-to action; although there was a validation already (even at low chance; this is thinkable). The suggested patch would keep you from doing this.,Sorry; I forgot doing some cleanup work; e.g.: .... final ActionContext context = invocation.getInvocationContext(); HttpServletRequest request = (HttpServletRequest) context.get(HTTP_REQUEST); Boolean isEscape = (Boolean)request.getAttribute('webwork.validation.escape'); if (isEscape != null && isEscape.booleanValue()) { log.debug('Skipping workflow. Validation escape flag found in request.'); request.setAttribute('webwork.validation.escape'; new Boolean(false));//do cleanup return invocation.invoke(); } .... and also; since ww 2.2 suggests using chain for calling action from an action; so I suggest we can modify ChainingInterceptor and ActionChainResult too in order to implent above escaping feature.,,,,,,,,,,,,,,,,,,
63697,x,x,,,,,,Ah; fantastic - that works very well. Thanks!,I think that is possible with UpdateRequestProcessor. Instead of adding a custom tag to the XML; add them as normal fields (metadata1; 2; ...) which will be added to SolrInputDocument. In the processAdd method you will get access to the value by using SolrInputDocument#getValue(String field). Use them in whatever way you want; remove them from SolrInputDocument and add the final processed text to a new field using SolrInputDocument#addField and finally pass on for indexing by calling super.processAdd(SolrInputDocument).,I don't think the UpdateRequestProcessor will let me do what I want. Let me describe what we're trying to do - maybe I can do it easily without cloning XmlUpdateRequestHandler. We want to add additional data to the XML <doc> tag; a <RichContent> tag which has a couple attributes; and whose contents are textual data. We want to translate this data into different text and then attach it to one of the lucene fields in the SolrInputDocument; which can then be processed normally. What I want; I think; is to be able to override the readDoc() method in XmlUpdateRequestHandler. Does that make sense? I could easily be missing a simple solution; as I'm new to Solr.,this is an improvement; not a bug; so even if someone provides a patch we're not going to try and squeeze it in for 1.3.,We also had to do this to write a requesthandler that maintains original dates on overwrite adds. But then I found this: http://wiki.apache.org/solr/UpdateRequestProcessor - does the updateRequestProcessor solve your problem?,,,,,,,,,,,,,,,,,
61272,x,x,,,,,,Thanks Alexey; Mark. I took the latest patch from Alexey; incorporated Marks suggestion and committed this to trunk.,,,,,,,,,,,,,,,,,,,,,
56598,,,,,,,,Each instance in SQL Server gets its own port number. As long as the port number for the SQLExpress instance is accurate it should work okay.,,,,,,,,,,,,,,,,,,,,,
45050,,,,,,,,Actually I think I already applied similar changes when doing the POI 3.6 upgrade in TIKA-353. Resolving as fixed.,set fix version to unreleased version and affects version to released version,patch,,,,,,,,,,,,,,,,,,,
9989,,,,,,,,Xalan-Java appears to be operating correctly.,version='' does not specify a valid nmtoken; so the error message is valid. If we had something like version='123.456' then we could default to '4.0' because version '123.456' is not supported. But this is not a valid nmtoken as is indicated in section 16 of the XSLT 1.0 recommendation.,Input XML,XSL stylesheet,,,,,,,,,,,,,,,,,,
47855,x,,,,,,,Great! I'm glad you found it helpful.,Thanks for the patch; I extended it a lot; with docs; more tests; the exception logic and the ability to use the annotation on component methods. Fun stuff!,Good start with the patch. I'm looking to expand it to support @CommitAfter on component event methods as well.,Patch fixing the issue,,,,,,,,,,,,,,,,,,
20625,,,,,,,,Integrated in Apache Wicket 1.4.x #200 (See [https://hudson.apache.org/hudson/job/Apache%20Wicket%201.4.x/200/]) åÊåÊåÊåÊ,Integrated in Apache Wicket 1.5.x #395 (See [https://hudson.apache.org/hudson/job/Apache%20Wicket%201.5.x/395/]) åÊåÊåÊåÊ,Wicket quickstart project with a JUnit that fails due to the described behaviour.,,,,,,,,,,,,,,,,,,,
80738,,,x,,,,,Rejected for 0.20. Allow me to clarify my position. I was prepared to accept this for 0.20. Right or wrong; it's by all accounts the dominant convention for similar .i files from other projects; and that's good enough for me. However! It depends on QPID-4207; and that's much too big change to dist metadata for our final release candidate. This will have to wait.,,,,,,,,,,,,,,,,,,,,,
46997,x,x,,,,,,Ah; great; things are running now. Thanks guys.,HI Kevin If you have apt; you might try $ apt-get install libbit-vector-perl If you need to do it the hard(er) way; try: $ perl -MCPAN -e 'install Bit::Vector' If you've never used CPAN in this way; it might ask you many questions (take the defaults). It may try first to upgrade itself. It may be painful; may not work at all. There are slightly more manual ways to do it; in which you ask for a shell and can then set options (auto follow dependent packages is very useful). apt-get it aint,Doh; ok. Could you tell me how to install that? I know it has something to do with CPAN; but I'm not a perl person.,Can't locate Bit/Vector.pm this is a required module. stated in lib/perl/README,,,,,,,,,,,,,,,,,,
15084,,,,,,x,,Hellow; I have the same problem after i haved updated my libs. I'm developping a application based on struts 2.0.1 beta. It works just fine before i replace libs by 2.0.5. Original config of my application is from Struts 2 blank; so i've check all config files; and i find that web.xml in 2.0.5 doesn't have these lines : <listener> <listener-class>org.springframework.web.context.ContextLoaderListener</listener-class> </listener> so; i've deleted these lines and my app works.,,,,,,,,,,,,,,,,,,,,,
26594,,,,,,,,Close all resolved issues for Engine 1.5 release.,,,,,,,,,,,,,,,,,,,,,
38950,x,,x,,,,,I've re-worked my code and the problem has now 'gone away'. The original code; where the problem was found; was ported from a solution that worked fine using ADF controls. The same code resulted in this problem. I moved some controls on the page around and altered some of the attributes and the tree table now collapses and expands as expected. Quite why the re-work has now eliminated the problem I do not know but as I need to progress with other things I've decided to close this issue rather than waste anymore of anybody's time. Thanks for all your help anyway.,,,,,,,,,,,,,,,,,,,,,
154,,,,,,,,Marshall; I'm wondering if the bug has something to do with the following: when you create a client; the second parameter to the constructor determines the random seed used by the client. That second parameter I think is supposed to be the client's id; but what is passed is clients.size(). I might be wrong here but I don't see where this vector of clients is cleared in between tests; so is it true that at some point the set size is fixed and all the seeds are the same ?,,,,,,,,,,,,,,,,,,,,,
63070,,,,,,,,Bulk close for Solr 1.4,committed.,pretty trivial bug; but I thought I'd fix it while I was converting everything for reuse and with the new attribute API,,,,,,,,,,,,,,,,,,,
57772,,,,,x,,,forgott to reslove: Actually this was fixed with http://svn.apache.org/r1459344 (21.March.2013),,,,,,,,,,,,,,,,,,,,,
60912,,,,,,,,[branch_4x commit] Mark Robert Miller http://svn.apache.org/viewvc?view=revision&revision=1384969 SOLR-3527: SolrCmdDistributor drops some of the important commit attributes (maxOptimizeSegments; softCommit; expungeDeletes) when sending a commit to replicas.,,,,,,,,,,,,,,,,,,,,,
5784,,,,,,,,This bug is 3 years old. Anybody looking to fix it?,*** This bug has been marked as a duplicate of 14217 ***,,,,,,,,,,,,,,,,,,,,
8502,,,x,,,,,I tried using your testcase on Win95/IE4; using old versions of Xerces (back until 1.5.1); but I never got the crash you report. So; I am closing this bug; if you still see it; please reopen it. Alberto,,,,,,,,,,,,,,,,,,,,,
11149,,,x,,,,,I wasn't able to reproduce the problem with the attachments. I saw appropriate error messages; line numbers; etc. However; line number information was missing for the testcase idkeyerr10; so I've committed a patch which remedies this.,,,,,,,,,,,,,,,,,,,,,
52597,x,,,,,,,thanks Malith for your contribution...patch committed under rev. 1326522,,,,,,,,,,,,,,,,,,,,,
18059,,,,,,,,This was probably fixed by WODEN-86 which introduced support for the curly brace syntax in the http location template. This JIRA can now be closed.,This test case is now passing. Not sure what the fix was (i.e. to Woden or to the testcase) but I'm marking it resolved.,I regenerated the W3C reports. There are now 12 errors reported for Woden on this test case. [1] [1] http://dev.w3.org/cvsweb/~checkout~/2002/ws/desc/test-suite/results/Woden/LocationTemplate-1G/SOAPservice.results.xml?content-type=application/xml,I regenerated the results in r480113. I'll have the W3C reports refreshed.,,,,,,,,,,,,,,,,,,
58473,,,,,,,,rules/,,,,,,,,,,,,,,,,,,,,,
