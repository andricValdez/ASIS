id,love,joy,surprise,anger,sadness,fear,notes,comment N,comment N-1,comment N-2,...,comment 2,comment1,,,,,,,,,,
73819,,x,,,,,joy and satisfaction,looks good. Thanks!,The attached patch resolves the issue for me. Please take a look.,,,,,,,,,,,,,,
77849,,,,,,,satisfaction emotion,Confirmed with Dave that this can be closed.,,,,,,,,,,,,,,,
5134,,,,,,,gratitude emotion,Ludger; thanks for the patch. I've just committed it. See SVN rev 1103164. Thiwanka; thanks for your help in investigating this issue.,,,,,,,,,,,,,,,
58767,,,,,x,,little concern,Unfortunately no: - looking at ServerSession.userAuth where it sets the state to Running: åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊbuffer = createBuffer(SshConstants.Message.SSH_MSG_USERAUTH_SUCCESS; 0); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊwritePacket(buffer); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊsetState(State.Running); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊthis.authed = true; åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊthis.username = username; åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊunscheduleAuthTimer(); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊscheduleIdleTimer(); the event is triggered before this.username is updated so the observer doesn't have access to that value. If the set is moved to later than I can eliminate two hacks (I suspect this.username should be updated far earlier when userauth_request arrives; but that would be a change in getUsername's semantics); however ... - as I mentioned above; instead of overloading ServerSession I should be defining my own service type and adding that; I've created SSHD-211 and attached a patch to illustrate the basic idea,Andrew; do you think the above commit is sufficient for your needs ?,URL: http://svn.apache.org/viewvc?rev=1434652&view=rev,This should solve my immediate problem (once the git repos are settled I will apply and test). However; looking at my code (which is now kind of working!) and SSHD-205 I suspect there's a better more invasive solution. Since my service is custom; instead of overloading ServerSession and looking for events; I should be registering my own service with SshServer. To sketch the idea out: - add an SshService factory to SshServer that maps a service name onto a service. The table would include ssh-userauth (rfc4252); and ssh-connection (rfc4254); and my custom service - separate ssh-userauth and ssh-connection from ServerSession so that they are are standalone services; and the latter just worries about the transport (rfc4253) - when the transport receives SSH_MSG_SERVICE_REQUEST; it could then instantiate the requested service and pass non-transport requests along to it - ssh-userauth; once authentication has finished; would also instantiate the requested service (passing it the authenticated user credentials) and update ServerSession My custom service would then see the following events from ServerSession / ssh-userauth - authenticated / requested when instantiated (or perhaps a separate explicit message) - a separate closed message when ServerSession sees the connection dropped et.al. Once the git repo is up; I might just play with the idea. It is very invasive.,The SSHD repository is in maintenance mode; so I can't commit what I've done now; but I've added a Session#getState() method and a SessionListener#sessionChanged() method so that you will be able to register a listener and be informed of session state changes. In your case; you'll have to check the sessionChange call with a Running state and the sessionClosed call.,,,,,,,,,,,
74448,,,,,,,concern,Closing this one since it doesn't fit in with the current caja integration anymore.,Marking unassigned to indicate that nobody is actively working on this issue. Anyone interested in helping the project should should consider working on this issue.,To add a little more detail; I believe Casie is saying that the gadgets.* <--> Caja bindings are not yet implemented; while the opensocial.* <--> Caja bindings are implemented.,The issue isn't as simple as just requiring the caja library right now. Work needs to be done to 'allow' the gadgets api calls in caja. I can work on this soon as it will require some integration with the opensocial caja modifications. (Although; some one can feel free to add a patch if you know what to do!),Anything we can do to minimize the work needed by a developer to support Caja is a very good thing. Furthermore as Caja improves; we'll be able to Cajole more and more gadgets without developer modifications. If that Gadget can become Cajoled without the author having to work on it; that would be great. What concerns me is that many of the Caja failures are likely to be at run time instead of compile time. So should a gadget author have the ability to ask for their gadget not to be Cajoled incase they know it doesn't work? If don't give that option; we may need to monitor Caja runtime failures and fall back to the iFrame for certain gadgets.,This isn't the case. Passing &caja=1 will cajole the gadget. opensocial-samplecontainer does some black magic to make it appear to work and do the right thing; but what it's really doing is not how it should work in prod. The remaining outstanding issue with cajoling right now is that passing &caja=1 does the cajoling process; but it does not pull in the necessary javascript libraries. To do that we must either make caja a core js library or force a <Require feature='caja'>. The latter is easier; but I'm not sure it's the way that we ultimately want things to work. For testing purposes you can manually add <Require feature='caja'/> to the gadget and modify the iframe url to add &caja=1. I'll modify the title of this to better address the core of the problem.,,,,,,,,,,
62753,,,,,,,gratitude,Thank you!,committed r892775,,,,,,,,,,,,,,
3399,,,,,,,satisfaction,Changed MULTI_TEXTVALUE_SEPARATOR into a property configurable by injection of constant named xwork.validatorfileparser.multi_textvalue_separator. This makes it possible to have empty String as 'separator' if it apllies to your particular platform; without breaking the backward compatibility and changing default behaviour.,,,,,,,,,,,,,,,
5711,,,,,,,"neutral, does not specify explicitly any emotion",Venu committed your patch. It's in Xerces 2.6.0. Please verify.,Created an attachment (id=9177) Test program to show the problem of acceptNode getting called twice,Created an attachment (id=9176) Patch for bug which causes acceptNode to call twice when filter is set to LSParser,,,,,,,,,,,,,
34779,,,,,,,satisfaction,fix works~,Commit ddce361ffa08306423f200eba9c03b3a171d8679 in branch refs/heads/master from Daniel Gruno [ https://git-wip-us.apache.org/repos/asf?p=trafficserver.git;h=ddce361 ] TS-1858: Fix redefinition of timersub on OmniOS with the ESI plugin.,,,,,,,,,,,,,,
58537,,,,,x,,some gratitude but mostly neutral,Looks like STANBOL-258 describes the same Issue.,With the current full launcher in r1143385 the problem is still there on my Ubuntu Linux system when running integration tests or the full launcher; respectively. åÊjava.lang.NoClassDefFoundError: javax/xml/parsers/ParserConfigurationException,Thanks Rupert; this looks like it indeed. However; since Fabian is the one experiencing this; I would suggest he tries replacing the version number on the reengineer/xerces POM; and commit the change it this solves the problem. wdyt?,In my opinion deleting the local cache can not have any influence in runtime dependencies because the Apache Sling module adds all required dependencies to the launcher jar. Therefore my assumption is that any error related to bundles present/missing in the local cache can only appear at build time and not at runtime. Here is my interpretation of the Log provided by Fabian: Based on this line: 19.05.2011 19:54:17.555 *ERROR* [FelixStartLevel] org.apache.stanbol.enhancer.jersey [org.apache.stanbol.enhancer.jersey.cache.CachingDereferencerEngine] The activate method has thrown an exception (java.lang.NoSuchMethodError: org.apache.xerces.util.XMLChar.trim(Ljava/lang/String;)Ljava/lang/String;) java.lang.NoSuchMethodError: org.apache.xerces.util.XMLChar.trim(Ljava/lang/String;)Ljava/lang/String; I found out that the ext.com.hp.hpl.jena module of Clerezza export 'org.apache.xerces.util' and internally uses xercesImpl version '2.9.1'. The org.apache.stanbol.reengineer.xerces exports 'org.apache.xerces.*' and internally uses 'xercesImpl' version '2.7.1'. This might be the cause for this problem. Further digging into the differences between xercesImpl '2.7.1' and '2.9.1' also showed that the version '2.9.1' depends on two additional bundles åÊåÊxml-apis/xml-apis/1.3.04 åÊåÊxml-resolver/xml-resolver/1.2 and that the 'xml-apis' bundle exports the the 'org.xml.sax' package. Therefore the export of version '2.7.1' of the org.apache.stanbol.reengineer.xerces might also be the reason for the ClassNotFoundExceptions related to org/xml/sax/SAXException. Based on that I assume that updating the version of 'xercesImpl' in the 'org.apache.stanbol.reengineer.xerces' bundle should solve the problem for now. åÊ,Odd. I did the same; though my approach was more radical (rm -rf ~/.m2/repository) Anyway it's most likely about the dependency on Xerces. I am seeing if we can remove the reengineer/xerces bundle at all; so it might solve your problem.,I just checked on a second machine and did: rm -rf ~/.m2/repository/org/apache/stanbol mvn clean mvn clean -P kres mvn install -P kres Then started Stanbol with launchers/kres. The problem remains the same as described in this issue.,Worksforme; they're all active...,I'm trying that now from a completely clean local repo; but it isn't compiling right now as the maven central repo is timing out with me. I'll let you know when it wakes up.,Did you clean your whole local Maven repository? In my case; I had a completely empty repository and only compiled Stanbol with KReS. Perhaps this is a bug that does not occur if there are certain dependencies already in the Maven repository.,Checked again with r1125010 and had the same problem. The full launcher works fine. Attached the error.log file showing the bug. Seams to be a problem with missing runtime dependencies java.lang.NoClassDefFoundError: åÊorg/xml/sax/SAXException java.lang.NoClassDefFoundError: Could not initialize class com.hp.h pl.jena.datatypes.xsd.XSDDatatype,I don't have this. I have cleaned the local maven repository and recompiled to be sure. Then run 'mvn clean install -P kres' as usual. At http://localhost:8080/system/console/components the components you mention are all in active state. Can someone else try?,,,,,
31813,,,x,,,,surprise,Closing because this has been in RESOLVED state for over one year; if it turns out to not be fixed please reopen.,,,,,,,,,,,,,,,
14921,,,,,,,satisfaction,Makes sense to me.,,,,,,,,,,,,,,,
68539,,,,,,,"some anger, mostly neutral broadcast",Please be informed that I am no longer accessible through this email address. Pls refrain from sending further messages. I will just personally contact you with my new email address. For any concerns / issues / inputs relating to your transactions with Exist; kindly forward email to hr@exist.com. Thank you HR Dept,,,,,,,,,,,,,,,
11773,,,,,,,concern emotion,Triage: Not for Xalan-J 2.2. We still need to evaluate this in light of Gary's point: exactly what location should we report for result tree events in this kind of situation? I'm not sure we intended to set the locator in this particular situation. Also; if we never set the locator; then we're still following the SAX spec - while this is somewhat useful; it's still an optional feature.,,,,,,,,,,,,,,,
5373,,,,,,,satisfaction and gratitude,I mailed jsr-206-comments@jcp.org and got the following response from Jeff Suttor: 'hi Daniel; consistency and least astonishment are valuable. :) would you be open to filing an RFE http://bugs.sun.com or an issue http://jaxp.dev.java.net to insure this is addressed? as this would be a public API change; it will have to be part of JAXP.next. thanks; -- Jeff' I filed https://jaxp.dev.java.net/issues/show_bug.cgi?id=9,,,,,,,,,,,,,,,
41140,,,,,,,gratitude,Looks fine to me now. Thanks!,,,,,,,,,,,,,,,
58715,,,,,,,satisfaction,Fixed in revision 1073288,Changing the goal to 'single' works the same and it is a better solution; since 'attached' goal is deprecated. Committed this change in revision 1073288.,This error disapperar if we change the goal of the maven-artifact-plugin to 'attached' instead of 'assembly'. This goal should behave the same but do not affect the kres build process.,Can reproduce the error with the attached mvn-minimal-configuration-pom.xml; which includes only the following modules; omitting all modules except: * enhancer/SemiAutomaticContentEnhancer * kres/eu.iksproject.kres.shared/dependency/owlapi3 * kres/eu.iksproject.kres.ontologies,I attach the output of the last try (enhancer-16),Kres build process fails when executing fro the root of Stanbol with the above output: [INFO] ------------------------------------------------------------------------ [ERROR] BUILD ERROR [INFO] ------------------------------------------------------------------------ [INFO] Failed to resolve artifact. Missing: ---------- 1) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 åÊåÊTry downloading the file manually from the project website. åÊåÊThen; install it using the command: åÊåÊåÊåÊåÊåÊmvn install:install-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file åÊåÊAlternatively; if you host your own repository you can deploy the file there: åÊåÊåÊåÊåÊåÊmvn deploy:deploy-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file -Durl=[url] -DrepositoryId=[id] åÊåÊPath to dependency: åÊåÊ 1) eu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 åÊåÊ 2) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 ---------- 1 required artifact is missing. for artifact: åÊåÊeu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 from the specified remote repositories: åÊåÊcom.springsource.repository.bundles.external (http://repository.springsource.com/maven/bundles/external); åÊåÊcentral (http://repo1.maven.org/maven2); åÊåÊjava.net (http://download.java.net/maven/2); åÊåÊapache (http://repository.apache.org/content/groups/snapshots-group) [INFO] ------------------------------------------------------------------------ [DEBUG] Trace org.apache.maven.lifecycle.LifecycleExecutionException: Missing: ---------- 1) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 åÊåÊTry downloading the file manually from the project website. åÊåÊThen; install it using the command: åÊåÊåÊåÊåÊåÊmvn install:install-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file åÊåÊAlternatively; if you host your own repository you can deploy the file there: åÊåÊåÊåÊåÊåÊmvn deploy:deploy-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file -Durl=[url] -DrepositoryId=[id] åÊåÊPath to dependency: åÊåÊ 1) eu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 åÊåÊ 2) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 ---------- 1 required artifact is missing. for artifact: åÊåÊeu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 from the specified remote repositories: åÊåÊcom.springsource.repository.bundles.external (http://repository.springsource.com/maven/bundles/external); åÊåÊcentral (http://repo1.maven.org/maven2); åÊåÊjava.net (http://download.java.net/maven/2); åÊåÊapache (http://repository.apache.org/content/groups/snapshots-group) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:711) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalWithLifecycle(DefaultLifecycleExecutor.java:556) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.forkProjectLifecycle(DefaultLifecycleExecutor.java:1205) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.forkLifecycle(DefaultLifecycleExecutor.java:1033) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:643) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalWithLifecycle(DefaultLifecycleExecutor.java:556) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoal(DefaultLifecycleExecutor.java:535) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalAndHandleFailures(DefaultLifecycleExecutor.java:387) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeTaskSegments(DefaultLifecycleExecutor.java:348) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.execute(DefaultLifecycleExecutor.java:180) at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:328) at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:138) at org.apache.maven.cli.MavenCli.main(MavenCli.java:362) at org.apache.maven.cli.compat.CompatibleMain.main(CompatibleMain.java:60) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.codehaus.classworlds.Launcher.launchEnhanced(Launcher.java:315) at org.codehaus.classworlds.Launcher.launch(Launcher.java:255) at org.codehaus.classworlds.Launcher.mainWithExitCode(Launcher.java:430) at org.codehaus.classworlds.Launcher.main(Launcher.java:375) Caused by: org.apache.maven.artifact.resolver.MultipleArtifactsNotFoundException: Missing: ---------- 1) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 åÊåÊTry downloading the file manually from the project website. åÊåÊThen; install it using the command: åÊåÊåÊåÊåÊåÊmvn install:install-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file åÊåÊAlternatively; if you host your own repository you can deploy the file there: åÊåÊåÊåÊåÊåÊmvn deploy:deploy-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file -Durl=[url] -DrepositoryId=[id] åÊåÊPath to dependency: åÊåÊ 1) eu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 åÊåÊ 2) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 ---------- 1 required artifact is missing. for artifact: åÊåÊeu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 from the specified remote repositories: åÊåÊcom.springsource.repository.bundles.external (http://repository.springsource.com/maven/bundles/external); åÊåÊcentral (http://repo1.maven.org/maven2); åÊåÊjava.net (http://download.java.net/maven/2); åÊåÊapache (http://repository.apache.org/content/groups/snapshots-group) at org.apache.maven.artifact.resolver.DefaultArtifactResolver.resolveTransitively(DefaultArtifactResolver.java:360) at org.apache.maven.artifact.resolver.DefaultArtifactResolver.resolveTransitively(DefaultArtifactResolver.java:304) at org.apache.maven.plugin.DefaultPluginManager.resolveTransitiveDependencies(DefaultPluginManager.java:1499) at org.apache.maven.plugin.DefaultPluginManager.executeMojo(DefaultPluginManager.java:442) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:694) ... 21 more [INFO] ------------------------------------------------------------------------ [INFO] Total time: 2 minutes 48 seconds [INFO] Finished at: Fri Feb 11 17:26:58 CET 2011 [INFO] Final Memory: 118M/282M [INFO] ------------------------------------------------------------------------ I started to investigate this; that does not happen when compiling in the /kres folder I before launched the command (evry time): $ cd $M2_HOME/repository $ rm -rf hermit/ && rm -rf owl* && rm -rf eu Then from the the root of Stanbol $ mvn clean install -X -DskipTests I did this with different configurations: * All non-kres moduls commented >> success * All but the parent module >> failure * All but the parent;entityhub modules >> failure * All but the parent;entityhub;enhancers modules >> success So I started investigating the enhancer module; and commented all but that: * enhancer-1 >> failure (all modules) * enhancer-2 >> success (only the parent module) * enhancer-3 >> success (parent module + base enhancer modules) * enhancer-4 >> success (parent module + base enhancer modules + autotag;opennlp;lang-id) * enhancer-5 >> success (parent module + base enhancer modules + autotag;opennlp;lang-id;metaxa) * enhancer-6 >> success (parent module + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging) from this point on I have activated also 'parent' and 'entityhub' in the root pom: * enhancer-7 >> success (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais) * enhancer-8 >> success (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta) * enhancer-9 >> seccess (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta + jersey) * enhancer-10 >> success (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta + jersey + clerezza/enhancer) * enhancer-11 >> success (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta + jersey + clerezza/enhancer;clerezza/sparql) * enhancer-12 >> success (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta + jersey + clerezza/enhancer;clerezza/sparql + launcher/full) * enhancer-13 >> success (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta + jersey + clerezza/enhancer;clerezza/sparql + launcher/full;launcher/lite) * enhancer-14 >> success (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta + jersey + clerezza/enhancer;clerezza/sparql + launcher/full;launcher/lites + integration-tests) * enhancer-15 >> failure (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta + jersey + clerezza/enhancer;clerezza/sparql + launcher/full;launcher/lites + integration-tests + SemiAutomaticContentEnhancer) --> same as enhancer-1 I tries also the following: Activating 'enhancer' only in the parent pom (and kres; of course) * enhancer-16 >> failure (parent module + base enhancer modules (generic) + SemiAutomaticContentEnhancer) So the problem is related to some configuration incompatibility between enhancer/SemiAutoamticContentEnhancer and kres/eu.iksproject:eu.iksproject.kres.ontologies I will investigate more on that.,This problem is again on after moving the kres module compilation at the end of the process in the main stanbol pom.xml,Fixed in 1060423.,I encounter the problem again even after following the instructions in the readme. [INFO] Unable to find resource 'eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7' in repository central (http://repo1.maven.org/maven2) [INFO] ------------------------------------------------------------------------ [ERROR] BUILD ERROR [INFO] ------------------------------------------------------------------------ [INFO] Failed to resolve artifact. Missing: ---------- 1) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 åÊåÊTry downloading the file manually from the project website. åÊåÊThen; install it using the command: åÊåÊåÊåÊåÊåÊmvn install:install-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file åÊåÊAlternatively; if you host your own repository you can deploy the file there: åÊåÊåÊåÊåÊåÊmvn deploy:deploy-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file -Durl=[url] -DrepositoryId=[id] åÊåÊPath to dependency: åÊåÊ 1) eu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 åÊåÊ 2) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 ---------- 1 required artifact is missing. for artifact: åÊåÊeu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 from the specified remote repositories: åÊåÊcom.springsource.repository.bundles.external (http://repository.springsource.com/maven/bundles/external); åÊåÊcentral (http://repo1.maven.org/maven2); åÊåÊjava.net (http://download.java.net/maven/2); åÊåÊapache (http://repository.apache.org/content/groups/snapshots-group),Fixed in #1049533.,The problem is reproducible when deleting the eu/iksproject tree from the local Maven repo $ rm -rf ~/.m2/repository/eu/iksproject/ and then start a Maven build using the top level Stanbol POM. This problem is not fixed by adding the missing JARs as mentioned by Enrico. As Andreas noted there is somehow a difference between calling Maven build in the kres directory or using the top level POM.,The problem stated in this issue disappeared after a $ mvn dependency:resolve,I manually installed the jars according to the README but that did not resolve this problem. Interestingly there is a dfference between executing mvn install in the stanbol directory and the kres subdirectory. I did not see this error when executing the command in the kres directory. I got the error mentioned in STANBOL-10 then.,The KReS module relies on three external dependencies that are not available in the maven repository. As described in the main stanbol README (http://svn.apache.org/repos/asf/incubator/stanbol/trunk/README.txt) you should import those irbraries manually before compile KReS. From the KReS folder do the following: $ mvn install:install-file -Dfile=kres/lib/owlapi-3.0.0.jar \ åÊåÊåÊåÊåÊåÊåÊ-DgroupId=owlapi -DartifactId=owlapi -Dversion=3.0.0 -Dpackaging=jar $ mvn install:install-file -Dfile=kres/lib/HermiT.jar \ åÊåÊåÊåÊåÊåÊåÊ-DgroupId=hermit -DartifactId=hermit -Dversion=1.2.4 -Dpackaging=jar $ mvn install:install-file -Dfile=kres/lib/owl-link-1.0.2.jar \ åÊåÊåÊåÊåÊåÊåÊ-DgroupId=owl-link -DartifactId=owl-link -Dversion=1.0.2 -Dpackaging=jar Note that; as for issue STANBOL-10; tests for the rule module actually breaks; so you should compile it with the -DskipTests flag.,,
14849,,,,,,,"neutral, does not specify explicitly any emotion",Reporter asked for this to be closed.,,,,,,,,,,,,,,,
11480,,,,,,,"neutral, does not specify explicitly any emotion",Retest shows Running xalan on lre02 <?xml version='1.0' encoding='UTF-8'?> <out xmlns='www.lotus.com' xmlns:ped='http://tester.com' english='to leave'/> Running XSLTC with Xerces Parser on lre02 <?xml version='1.0' encoding='UTF-8' ?> <out xmlns:ped='http://tester.com' xmlns='www.lotus.com' english='to leave'/>,,,,,,,,,,,,,,,
17964,,,,,,,"neutral, does not specify explicitly any emotion",Fixed.,,,,,,,,,,,,,,,
76494,,,,,,,"satisfaction, closed issues",Closed issues related to Roller 5.0 release.,,,,,,,,,,,,,,,
52716,,,,,,,satisfaction,Fixed in the trunk and branch,Attaching the patch.,,,,,,,,,,,,,,
37992,,,x,,,,surprise and concern (recurring issue),The issue as described by (resolved) issue TRINIDAD-1171 occurs consistently in our environment using 1.2.10;,,,,,,,,,,,,,,,
27656,,,,,x,,repeated issues - little sad,We'll look at the issue for 1.1,Multiple errors get overwritten much as multiple return values do. Look in ValidatorResult.java; line 117: hResults.put(field.getKey(); result); The problem is; both errors and values should be indexed in ValidatorResult; with this modification; you have to manually construct the key (using ValidatorUtils.replace()); but at least you don't lose info. I confess I'm not using Struts; but I'm using Validator in standalone fashion; so maybe my needs are very particular. MatÌ_as.,Created an attachment (id=4188) Proposed fix,I'm not so sure that this is a bug. In most cases; an indexed property is going to be used in a table-style of input with an iterator. You wouldn't want to display each error on the line; you'd display them at the top. If we went to storing indexed property error messages on the full property with index; you'd need to put an iterator around bean:errors in Struts (for example) to generate all the error messages. Willing to hear counter arguments. James,,,,,,,,,,,,
20803,,,,x,,,anger,this will be tackled when we improve ajax; most likely in wicket.next or the version after that.,@Igor: Please read this bug comments too. It's already well established that generateCallbackScript completes the string. It's just nasty and uncontained. Consider the alternative I proposed.,generateCallbackScript() completes the fragment with the missing closing ),making changes to this can only be done in 1.5; because this results in api breaks. The thing is that getCallbackScript and generateCallbackScript could be really just 1 method.. Except i guess that some do use generate standalone But if you have a nice patch that would result in the same thing please attach it.,OK; so this string is an unmatched JS function invocation by design. That is just nasty. How about you convert it to something safe and correct like generateCallbackScript(String function; String... args) ? Then you'd do: {code} protected CharSequence getCallbackScript(boolean onlyTargetActivePage) { return generateCallbackScript('wicketAjaxGet'; getCallbackUrl(onlyTargetActivePage)); } {code} Immediately fixing the potentially broken inject-an-arbitrary-string-in-a-literally-quoted-value too.,,,,,,,,,,,
39032,,,,,,,"neutral, does not specify explicitly any emotion",Reopening issues to set version.,,,,,,,,,,,,,,,
29351,,,,x,,,little anger,This issue is maybe related to UIMA-1408.,Philip please provide more details until then the issue cannot be reproduced.,Hi Philip; the annotation which is selected in the outline view should be selected in the text editor. An annotation which is part of feature structure and selected should be also be selected in the editor. I think this is somehow broken on your machine; I would like to find out why and fix it. For this I need more information from you. Please go to the about dialog and click on configuration details and attach these to the issue. It would also be nice if you can attach a a screenshot which shows that the selection in the editor does not work when something in the outline is selected; maybe this gives a clue. Thanks; JÌ¦rn,,,,,,,,,,,,,
44873,,,,,,,"neutral, does not specify explicitly any emotion",This has been fixed for 1.1 by Upgading to POI 3.8 beta 5. Perhaps somebody with more power than me can mark this accordingly.,,,,,,,,,,,,,,,
57170,,,,,,,satisfaction,Fixed thus: http://svn.apache.org/viewvc?rev=574613&view=rev,Scheduled to version 4.2.,This affects 4.1.3. I'll let Farid decide whether it's simple enough to do for 4.2 or if we need to schedule it for later.,This is good improvement.,Assigned to Farid; the Windows infrastructure maintainer.,Makes sense to me. What do you think about it; Farid?,> BUILDDIR should default to the source directory; that is; the same directory containing the generate.bat script. ...or the current directory if this directory is different from the directory where the generate.bat script is located.,,,,,,,,,
48875,,,,,,,satisfaction and concern,This works great for me; but it has demonstrated another issue when some Tapestry's script files try to use the clientId in order to create javascript identifiers for variables. I'll open a new issue describing this.,,,,,,,,,,,,,,,
14387,,,,x,,,concern and a litle anger,we're moving away from dojo integration in struts2; so you won't likely get much traction on this issue. If you want/need this resolved; then reopen; but provide a patch that we can apply. The core devs aren't going to allocate time to the dojo plugin at this point.,,,,,,,,,,,,,,,
74491,,,,,,,satisfaction,Chain 1.2 is now available in the m2 repo. Updated patches to include logging 1.1.1 and scxml 0.8,,,,,,,,,,,,,,,
64300,,x,,,,,joy in agreement,closing.,Thanks Thorsten; I've been meaning to write a step-by-step guide on how to get up and running with your own data.,done: http://wiki.apache.org/solr/mySolr @Antonio; thx for the feedback; I added your comment into the wiki page.,Perhaps this should be a Wiki page to make it easier to change / collaborate?,Wow! you must be reading my mind I can contribute with questions As a newbie non-java user from an enterprise prospective! I am your idea target Having said that I like to know about the following: 1. The schema.xml and solrconfig.xml are in parts very well explained. But in some areas like as an example .. <indexDefaults> and other places there are no explanation. It would be nice to get more info there. Specifically for example if increase <mergeFactor> to 1000 what will happen? what are the highest value for each properties? what is for example a 'safe value'. 2. It would be nice to create a deployment scenarios i.e a single server install with XXX CPU and YYY memory just running Solr with AAA thousand docs how should your config look like and why? and you can get about xxx Query/Sec or something.. 3. It would be nice to have a multi server deployment with some server spec and then how should the deployment be. 4. It would also be nice to have more info regarding stopwords synonoms etc. usage and facet etc.. I know that all of the above are case by case cos configuration by default means case by case. But what I want to propose is a 'Guidelines or Best Practice' based on your production implementation/deployment you have done with Cocoon. It would be nice to have some real world stories. I think you should do like the subversion book! - A Solr open source book!,Initial version,,,,,,,,,,
76425,,,,,,,satisfaction,This was done long ago and is now in trunk and ready for release,,,,,,,,,,,,,,,
37251,,,,,,,satisfaction,This issue is already comitted,,,,,,,,,,,,,,,
34559,,,,,,,"neutral, does not specify explicitly any emotion",Lazy session associated has been implemented in the TuscanyValve The spec people are still discussing Scope so I am going to close this and we can open a new issue when the spec clearly defines how scopes operate.,,,,,,,,,,,,,,,
32383,,,,,,,concern,Closing because this has been in RESOLVED state for over one year; if it turns out to not be fixed please reopen.,,,,,,,,,,,,,,,
10446,,,,,,,"neutral, does not specify explicitly any emotion",This bug has been fixed in Xalan Java 2.5.2. Please verify.,Applied patch to CVS.,If the type of tge second argument is not node-set; throw run time error.,Created an attachment (id=6012) Patch for FuncDocument,,,,,,,,,,,,
59257,,,,,,,gratitude,Patch is in. Thanks.,,,,,,,,,,,,,,,
79211,,,,,,,gratitude,Thanks Marijan; will do!,,,,,,,,,,,,,,,
34239,,,,,,,satisfaction,Fixed in revision 406707.,,,,,,,,,,,,,,,
10696,,,,x,,,little anger,Closing this issue. Please re-open if you have a testcase.,Resolving as incomplete. We have no testcase.,I'm not sure that you are still interested in this old issue; but we would need a testcase to proceed. Please provide one or we will be closing this issued down.,,,,,,,,,,,,,
9989,,,,,,,concern,Xalan-Java appears to be operating correctly.,version='' does not specify a valid nmtoken; so the error message is valid. If we had something like version='123.456' then we could default to '4.0' because version '123.456' is not supported. But this is not a valid nmtoken as is indicated in section 16 of the XSLT 1.0 recommendation.,Input XML,XSL stylesheet,,,,,,,,,,,,
28865,,,,,,,"neutral, does not specify explicitly any emotion",Fixed a prompt that asks user to enter either 's' or 'q'.,,,,,,,,,,,,,,,
24867,,,,,,,"neutral, does not specify explicitly any emotion",Updated version of the patch. Removed the setter for the log storage provider in the stanza relay; and passed it either as constructor parameter of through provider registry as with other providers. If there is a need for a more generic stanza logger; these users could use the plain interface. The adapter I made is intended for filtering; so that only textual chat messages between users are let through; which I think is the most interesting detail to be logged. I updated the source file name and the comment to better indicate this.,,,,,,,,,,,,,,,
20927,,,x,,,,surprise,woops; thought this was already fixed...,,,,,,,,,,,,,,,
18707,,,,,,,joy in agreement,Ah; I can close it myself...,For the sake of completeness: I have also posted a stackoverflow question about this: http://stackoverflow.com/a/13088148/1006823 In the answer I have outlined how I finally solved the problem. I just had to extract the actual page mounting out of my WebApplication class; which seemed like a drawback first; but actually I am pretty happy that the mount stuff is separate now :) That said; feel free to close this ticket if you do not think the framework should support this. At anyone needing this; have a look at the link above - actually it is pretty simple once you know it :),I see no way to generate urls without the information from the request and application (servlet context).,I'm not sure how this is possible in Wicket 1.3/1.4. The ServletContext is needed and the filter path where WicketFilter listens to be able to calculate the relative urls. If you need full url (like http://host/...) then you can use a helper class that uses bi directional map (String -> Class<Page>). In Wicket code you just need to do somthing like: void Helper.mount(webApp) { åÊåÊfor (entry : map) { åÊåÊåÊåÊwebApp.mountPage(entry.key; entry.value) åÊåÊ} } In your non-Wicket code: åÊåÊprefix + map.getKey(pageClass) where prefix is the part that Wicket needs usually to calculate the urls: http://host/contextPath/filterPath.,,,,,,,,,,,,
485,,x,,,,,concern,+1 overall. Here are the results of testing the latest attachment http://issues.apache.org/jira/secure/attachment/12508207/ZOOKEEPER-1263.patch against trunk revision 1214571. +1 @author. The patch does not contain any @author tags. +1 tests included. The patch appears to include 6 new or modified tests. +1 javadoc. The javadoc tool did not generate any warning messages. +1 javac. The applied patch does not increase the total number of javac compiler warnings. +1 findbugs. The patch does not introduce any new Findbugs (version 1.3.9) warnings. +1 release audit. The applied patch does not increase the total number of release audit warnings. +1 core tests. The patch passed core unit tests. +1 contrib tests. The patch passed contrib unit tests. Test results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/844//testReport/ Findbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/844//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html Console output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/844//console This message is automatically generated.,Hi Pat; Thanks for the review and comments. I have attached latest patch with test cases. In the patch I couldn't completely remove the conditional logic from ZooKeeperServer. I have seen the testcases are directly instantiating the 'ZooKeeperServer' and starting the server. In this case the execution flow is not going through the ServerConfig/QuorumPeerConfig and will not be applying the defaulting logic[the timeout values will remain as -1]. So I retain the logic inside ZooKeeperServer.,Rakesh - in order to simplify the patch file conflict management I rolled these two issues into one patch. Note however - you have not updated the code in ServerConfig; so there is still an issue for the standalone case. Please update the patch and add test(s) for this. thanks.,This is the merged patch from ZOOKEEPER-1213 and ZOOKEEPER-1227; no other changes.,,,,,,,,,,,,
4169,,,,,,,"neutral, does not specify explicitly any emotion",I'd be okay with an enhancement which defaults to a SAX2-compliant parser when available; but this isn't always the case. MinML is a good fallback for those situations (e.g. applets).,,,,,,,,,,,,,,,
70682,,,,,,,satisfaction,Close after release,,,,,,,,,,,,,,,
12310,,X,,,,,,Very cool. Thank you.,,,,,,,,,,,,,,,
77424,,,,,,,satisfaction,The macro is also deprecated now; it is advised to use åÊåÊåÊåÊåÊåÊåÊåÊ#showRSSAutodiscoveryLink(),,,,,,,,,,,,,,,
60965,,,,,,,concern,Hoss; any interest in bring this patch forward to trunk?,Unassigned issues -> 4.1,It would be great to have this work in some form; even if it does not have the same API as before.,rmuir20120906-bulk-40-change,Hello - Could the deleteByQuery issue you mention be fixed with SOLR-3473? I've attached an updated patch for today's trunk. The previous patch was missing the signature field but i added it to one schema. Now other tests seem to fail because they don't see the sig field but do use the update chain. Anyway; it seems the BasicDistributedZkTest passes but i'm not very sure; there's too much log output but it doesn't fail.,bulk fixing the version info for 4.0-ALPHA and 4.0 all affected issues have 'hoss20120711-bulk-40-change' in comment,Updated patch to include my (meager) attempt at fixing the problem by making processAdd immediately execute a deleteByQuery if the add includes an updateTerm. I banged my head against a bunch of version mismatch errors to get into the current state of the patch; such that all the updates succeed; but the query assertions in the test still fail indicating that docs with duplicate signatures are making it into the index. On the up side: far fewer duplicates are making it into the index now then before the patch (when docs would only be deleted from the node that got the initial request if that node happened to be a shard leader)... wrong number of deduped docs (added 68 total) expected:<7> but was:<10> wrong number of deduped docs (added 71 total) expected:<7> but was:<8> wrong number of deduped docs (added 70 total) expected:<7> but was:<9> ...so apparently there is still some tiny corner case code path where dups are sneaking in (either that or the existing deleteByQuery code isn't reliable). I'm fairly certain i'm out of my depth at this point.,test demonstrating problem. where SignatureUpdateProcessorFactory lives in the chain doesn't affect the outcome.,i'm not entirely sure i'm understanding the problems. here's what i think i understand... 1) if you put dedup prior to distrib; then regardless of how it is configured it currently runs twice; which is bad - this seems like it is solved by SOLR-2822 2) if you want to use dedup to generate a sig for the uniqueKey field; then it really has to come before distrib; otherwise forwarding to the leader just wont work. (again: SOLR-2822 should make this do-able) 3) if you want to use dedup to generate a sig field that is not the uniqueKey field; AND you want to use 'overwriteDupes=true' then (currently) this needs to happen after distrib; because otherwise the info about the deletion _x0089_ÛÒ tracked in AddUpdateCommand.updateTerm - is lost when distrib does the forward. This seems like something that the distrib processor should deal with by ensuring it serializes/deserializes all of the key information in the AddUpdateCommand when sending/recieving a TOLEADER/FROMLEADER request (using SOLR-2822 vernacular) 3a) it's not enough to ensure that the 'updateTerm' is forwarded all the replicas in the shard; because other docs in other shards may have the same term value for the hash. (hence Markus's suggestions about doing a deleteByQuery _x0089_ÛÒ this should be in distribUP when AddUpdateCommand.updateTerm is non-null) 4) something about document cloning ... i still don't really understand this _x0089_ÛÒ not just in terms of dedup; but in generally i don't really understand why SOLR-3215 is an issue assuming we fix SOLR-2822.,To work around the problem of having the digest field as ID; could it not simply issue a deleteByQuery for the digest prior to adding it? Would that cause significant overhead for very large systems with many updates? Yeah; that might be an option - I don't know that it will be great perf wise; or race airtight wise; but it may a viable option. We would; from Nutch' point of view; certainly want to avoid changing the ID from URL to digest. Ah; interesting. If you are enforcing uniqueness by digest though; is this really a problem? It would only have to be in the Solr world that the id was the digest - and you could even call it something else and have an id:url field as well. Just thinking out loud. Or; perhaps we could make it so you could pick the hash field? Then hash on digest. If you are using overwrite=true; this should work right? Or perhaps someone else has some ideas...,That makes sense indeed. To work around the problem of having the digest field as ID; could it not simply issue a deleteByQuery for the digest prior to adding it? Would that cause significant overhead for very large systems with many updates? We would; from Nutch' point of view; certainly want to avoid changing the ID from URL to digest.,My next response on the ML: I take that back - I think that may be the only way to make this work well. We need that document clone; which will let you put the dedupe proc after the distrib proc. I think in general; the dedupe proc will only work if your signature field is the id field though - otherwise; hash sharding that happens on the id field is going to cause a problem.,,,,
68305,,,x,x,,,little anger,Updated the binding components' parent pom.xml http://svn.apache.org/viewvc?view=rev&revision=557983,Fixed for servicemix-ftp http://svn.apache.org/viewvc?view=rev&revision=557640 Fixed for servicemix-http http://svn.apache.org/viewvc?view=rev&revision=557757 Fixed for servicemix-jms http://svn.apache.org/viewvc?view=rev&revision=557769 Fixed for servicemix-truezip http://svn.apache.org/viewvc?view=rev&revision=557978 Fixed for servicemix-xmpp http://svn.apache.org/viewvc?view=rev&revision=557981,Fixed for servicemix-file: http://svn.apache.org/viewvc?view=rev&revision=557551,Fixed for servicemix-http! Thanks a lot to Gert Vanthienen! Author: tterm Date: Fri Apr 27 05:23:20 2007 New Revision: 533074 URL: http://svn.apache.org/viewvc?view=rev&rev=533074 Log: SM-932 Enable PMD/CheckStyle for binding components Added: incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/processors/AbstractProcessor.java Removed: incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/processors/Constants.java Modified: incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/BasicAuthCredentials.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/ContextManager.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/HttpBootstrap.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/HttpBridgeServlet.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/HttpComponent.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/HttpConfiguration.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/HttpConfigurationMBean.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/HttpEndpoint.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/HttpManagedServlet.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/HttpProcessor.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/HttpWsdl1Deployer.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/ManagedContextManager.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/ProxyParameters.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/SslParameters.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/endpoints/DefaultHttpConsumerMarshaler.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/endpoints/DefaultHttpProviderMarshaler.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/endpoints/HttpConsumerEndpoint.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/endpoints/HttpConsumerMarshaler.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/endpoints/HttpProviderEndpoint.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/endpoints/HttpProviderMarshaler.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/endpoints/HttpSoapConsumerEndpoint.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/endpoints/HttpSoapConsumerMarshaler.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/endpoints/SerializedMarshaler.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/jetty/JCLLogger.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/jetty/JaasJettyPrincipal.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/jetty/JaasUserRealm.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/jetty/JettyContextManager.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/jetty/ServiceMixSslSocketConnector.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/packaging/HttpServiceUnitAnalyzer.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/processors/CommonsHttpSSLSocketFactory.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/processors/ConsumerProcessor.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/processors/ProviderProcessor.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/tools/PortTypeDecorator.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/ConsumerEndpointTest.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/HttpAddressingTest.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/HttpConsumerTest.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/HttpManagedTest.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/HttpProviderTest.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/HttpSoapTest.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/HttpSpringTest.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/HttpTxTest.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/HttpURITest.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/HttpWsdlTest.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/HttpXBeanDeployerTest.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/ServerManagerTest.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/WsdlRoundtripTest.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/endpoints/Person.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/endpoints/PersonImpl.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/endpoints/SerializedMarshalerTest.java incubator/servicemix/trunk/deployables/bindingcomponents/servicemix-http/src/test/java/org/apache/servicemix/http/security/HttpSecurityTest.java,Additional http patch file to provide the missing AbstractProcessor file,Gert; the http patch doesn't work. There is a class missing: AbstractProcessor. I guess you forgot to add this class to svn before you do the svn diff.,The last patch file (*-http) contains all necessary modifications for servicemix-http. It also contains the updated pom.xml for the binding components. Just a few remarks: I have used some J2SE 5.0 constructs (varargs; generics; ...) during the cleanup (e.g. to reduce the amount of code per method). If you still want to be 1.4-compliant; these have to be modified SslParameters contains a call to hash(String... strings). If I don't enclose the parameters to this call in a new String[] { }; PMD (incorrectly) complains about an unused private method,Patches for servicemix-truezip and servicemix-xmpp,SM-932-jms.patch fixes PDM/CheckStyle errors for servicemix-jms,SM-932-ftp.patch fixes PDM/CheckStyle errors for servicemix-ftp,SM-932-file.patch fixes PDM/CheckStyle errors for servicemix-ftp,,,,,
29161,,,,x,,,little anger,Already fixed in UIMA-1379.,I think the source files should be within the org.apache.uima.tika package and not in org.apache.uima.,,,,,,,,,,,,,,
31087,,,,,,,satisfaction,Patch applied. Thanks Florian.,,,,,,,,,,,,,,,
69716,,,,x,,,little anger,I really meant to remove this functionality: What is the use for it anyway ? It doesn't hurt today (except for a few bytes eaten) but it may be confusing. So; if there is no clear use and requirement for it; I suggest to just remove it.,,,,,,,,,,,,,,,
76643,,,,,,,satisfaction,Closed issues related to Roller 5.0 release.,,,,,,,,,,,,,,,
17394,,,x,x,,,joy and gratitude,Andreas; I can see the benefit; but I'm not entirely sure how to do it. Perhaps you could provide a patch? David,Catching the InterruptedIOException and breaking to loop is indeed the simplest solution to the problem. However; I would prefer that SimpleHttpServer#destroy directly closes the ServerSocket without trying ExecutorServide#shutdownNow. The reason is that this would work on all platforms in the same way and on JVMs of the first type it would avoid spending unnecessary time in ExecutorServide#awaitTermination. Actually on this type of platform; the test cases for the HTTP transport probably spend more time waiting than to execute the actual tests...,applied fix from David. Many thanks Andreas -- dims,That's a really good bug report... this problem's been annoying me for a VERY long time. I really can't believe it's this simple... simply catching the InterruptedIOException and calling break in the catch block. I tried that and it seemed to work on people.apache.org. Patch at [1]. Can someone else sanity check it and try it on other platforms/jvms? David [1] http://people.apache.org/~davidillsley/wscommons/wscommons402.patch,,,,,,,,,,,,
45250,,,,x,,,concern and little anger,Resolving as fixed. We can do better positioning of the comments once someone has a concrete use case for that.,You can associate comments with cells; but it isn't all that easy. The 'findCellComment' on HSSFCell shows how to do it; which is: For every TextObjectRecord; find the CommonObjectDataSubRecord of type OBJECT_TYPE_COMMENT that precedes it On that CommonObjectDataSubRecord; get the object ID Find a NoteRecord with a shape ID that matches the object ID just found The NoteRecord holds the row and column details Normally the ordering of records in the file is CommonObjectDataSubRecord; TextObjectRecord; NoteRecord; cells; so you'd need to grab things as they went passed so they're to hand by the time you get to the cells.,Thanks! Patch applied (with minor changes) in revision 788364. Would there be some way to associate the comments with the cell's they apply to? I'd like to see the comment of a cell outputted along with the cell value. I'm leaving this issue until this has been resolved.,Patch adds text extraction from text shapes (comments and other),,,,,,,,,,,,
41306,,,,,,,neutral,The above code is a part of a dataTable of course ...,,,,,,,,,,,,,,,
61104,,,,x,,,little anger,I hope someone can fix this; but I know that at this time it's not something I can tackle without generous hand-holding. If there are no takers soon; I'll go ahead and close the issue. This is part of an effort to close old issues that I have reported. Search tag: elyograg2013springclean,I just thought of a localparam syntax for this: {!cache=nowarm},I never actually answered your first question. Yes; I do want most entries in the filter cache to be usable for autowarming. Most users have relatively few boolean clauses in their filter queries. Employees are the common exception. We get a few hundred boolean clauses in ours. Plans are being discussed to greatly reduce that; but I'm not sure we'll ever get away from it entirely.,I would like to have our application code tag those nasty employee filters with something that makes them ineligible for autowarming; but still eligible for caching; which would keep them around until the next commit. I am pretty sure our code is capable of knowing that the user is a special user; typically admin or system. An update cycle runs once a minute for the index as a whole; but changes are tracked on a per-shard basis. Commits on each shard are only done if something on that particular shard actually changes. The large shards where this is a problem typically go several minutes between commits; and that might extend to an hour or more. I will talk to our developers about using the cache=false localparam for now; but I am hoping for the ability to use the cache for those nasty filters but not include them for warming. Having recently toyed with the cache code ( SOLR-2906); I know this may not be trivial.,Are there other auto-warming queries you want to have done? Because it almost sounds like you just want to turn off autowarming in the filter cache. Or if they're unlikely to be re-used anyway; would it work to set cache=false on the original fq?,I don't think I can implement this. My knowledge of Solr internals simply isn't strong enough.,,,,,,,,,,
70122,,,,,,,gratitude and satisfaction,applied patch (thanks) in r1055887,The patch enhances the tests to reproduce the problem and a simple bugfix.,,,,,,,,,,,,,,
20625,,,,,,,satisfaction,Integrated in Apache Wicket 1.4.x #200 (See [https://hudson.apache.org/hudson/job/Apache%20Wicket%201.4.x/200/]) åÊåÊåÊåÊ,Integrated in Apache Wicket 1.5.x #395 (See [https://hudson.apache.org/hudson/job/Apache%20Wicket%201.5.x/395/]) åÊåÊåÊåÊ,Wicket quickstart project with a JUnit that fails due to the described behaviour.,,,,,,,,,,,,,
21977,,,,,,,concern and little anger,How about my comment at the end? 'Also; I'm suspicious of the logic for handling parent markup containers in AutoLinkResolver. It uses 'if' instead of 'while.' What if the autolink was two levels up in the inheritance hierarchy? I think that it should walk the parent links until it finds a null; not just check the first one.',very same issue,WICKET-1634 is the same issue (including a patch); so this one can be closed; too,,,,,,,,,,,,,
27962,,,,,,,satisfaction,Code delivered to SVN.,,,,,,,,,,,,,,,
45835,,,,,,,satisfaction,Integrated in Thrift #407 (See https://builds.apache.org/job/Thrift/407/) THRIFT-1517 TTransport.ReadAll() should set exception type to EndOfFile Patch: Stefan Gmeiner (Revision 1291039) Result = SUCCESS roger : http://svn.apache.org/viewvc/?view=rev&rev=1291039 Files : /thrift/trunk/lib/csharp/src/Transport/TTransport.cs,,,,,,,,,,,,,,,
2463,,,,,,,satisfaction and gratitude,Added a couple small points I missed before; and fixed (I hope) some formatting. Thanks. If anyone notices any misuses of the document formatting please let me know. Thanks!,,,,,,,,,,,,,,,
22691,,,,x,,,concern and little anger,By the way; the javadoc for the minimum and maximum validators are still not updated (and incorrect). They need to be precise as to whether or not the endpoints are included. For example: * Gets a Double maximum validator for checking if an number is smaller than the given maximum Should read 'is at most' or 'smaller than or equal to'. Same with the other validators (including the range validators).,,,,,,,,,,,,,,,
36052,,,,,,,neutral,Moving these all to a 'Doc 3.x' release version.,r1085213.,,,,,,,,,,,,,,
73415,,,,,,,gratitude,Patch applied. Thanks,The binary images that are mentioned and used in the reviewed code. Both images are made by me and can be freely used in Shindig.,,,,,,,,,,,,,,
7380,,,,,,,concern,As a work around; I scan the XML document to locate the namespaces which are then compared against a look-up file to see which schemas to load in the grammar. The only reason this was done is because DOMEntityResolver did not trigger for all namespaces. I am using version 2.7 and the option to trigger on all namespaces would be useful.,,,,,,,,,,,,,,,
15893,,,,x,,,concern and little anger,You are only flushing the writer; donå«t you need to close it too? writer.flush(); writer.close();,Is there a reason the writer.flush() is not called if a JSPfactory is not used? You should always flush() and close() your streams and writers.,,,,,,,,,,,,,,
80924,,,,,,,gratitude and satisfaction,The changes looks good for me. Reviewed with no commentaries.,Patch applied. Alex; could you review the changes please?,,,,,,,,,,,,,,
18020,,,,,,,neutral,r563181 pom.xml,,,,,,,,,,,,,,,
5713,,,,,,,neutral,Venu committed your patch for Xerces 2.6.0. Please verify.,,,,,,,,,,,,,,,
31554,,,,,,,neutral,Dave has let me know that this has resoved the issue,Attempt at a fix in 1.x r777627 and 1.5 branch r777632,,,,,,,,,,,,,,
180,,,,,,,neutral,Jimmy this ready for review/commit? If so please 'submit'. Thanks.,,,,,,,,,,,,,,,
644,,,,,,,satisfaction,Integrated in ZooKeeper-trunk #1266 (See https://builds.apache.org/job/ZooKeeper-trunk/1266/) ZOOKEEPER-1104. CLONE - In QuorumTest; use the same 'for ( .. try { break } catch { } )' pattern in testFollowersStartAfterLeaders as in testSessionMove. (Eugene Koontz via mahadev) mahadev : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1157690 Files : /zookeeper/trunk/src/java/test/org/apache/zookeeper/test/QuorumTest.java /zookeeper/trunk/CHANGES.txt,,,,,,,,,,,,,,,
8202,,,,,,,neutral,*** Bug 8704 has been marked as a duplicate of this bug. ***,,,,,,,,,,,,,,,
23785,,,,,,,neutral,I just put this in branch-0.8 too. In fact; it's probably worth putting everything in branch-0.8 at the moment unless it's a major or incompatible change.,,,,,,,,,,,,,,,
31064,,,,,,,satisfaction,Closing resolved issues,Resolved along the lines described in the description in 941719 - required the fixing of a couple of testcases in addition to the mainline code; since the initialization sequence is changed to require a Registry object to be supplied; used when creating the ContextClassLoader....,,,,,,,,,,,,,,
58484,,,,,,,concern but no anger,Build on Windows looks also okay but there are still other problem loading the model data for the entity hub.,,,,,,,,,,,,,,,
27659,,,,,,,neutral,Closing as FIXED,,,,,,,,,,,,,,,
40844,,,,,,,concern but no anger,Looks like a user issue to me; two pages at the same time accessing probably the same session. There is not additional user feedbac on this issue. I am closing it now.,Are you storing your data-model in the session? If yes; have you tried synchronizing access to the session to one window per user? If you don't want to synchronize; you should try to get rid of all session scoped beans. regards; Martin,,,,,,,,,,,,,,
15793,,,,,,,satisfaction,This has been fixed in CVS. You can get the latest xwork.jar (which fixes the problem) from http://ivyrep.opensymphony.com,,,,,,,,,,,,,,,
71565,,,,x,,,concern and little anger,It seems that this enhancement is atm out of scope for Sling - therefore closing this bug.,,,,,,,,,,,,,,,
722,,,,x,,x,fear and anger,Out of curiosity; could we save a FOLLOWING notification as our lastMessage then; even if we don't send it? That would give you the 'current' state more accurately than a stale LOOKING notification and it seems like it could solve this particular problem. We could; but that wouldn't give an accurate state as well. A peer might be in the LOOKING state (next FLE round) while the lastMessage gets sent. There will be race conditions. In my opinion; a better way of doing this is to send the current state instead of lastMessage. In which case; I agree with Flavio that sending the final notifications won't be necessary. This will also reduce the number of notifications exchanged.,,,,,,,,,,,,,,,
80768,,,,x,,,little anger,Now merged to the 0.20 release branch.,Though not in itself a priority change for 0.20; it sensibly goes along with QPID-4468. Reviewed by Rob. Approved for 0.20.,Rob reviewed this together with the changes for QPID-4468 (and 'thanked' me via email me for conflicting heavily with his changes for QPID-2796 ),Change made in http://svn.apache.org/viewvc?rev=1413363&view=rev,,,,,,,,,,,,
76385,,x,,,,,satisfaction but also little anger,Cool. Thanks for considering my bug report!,The Maxlength field for Yahoo! I got from clicking on 'Create New Account' here: https://login.yahoo.com/ and it shows: <input type='password' name='password' id='password' value='' size='32' maxlength='32' class='' aria-required='true'>; so it has maxlength. Facebook; I stand corrected; entering it again I just see this: <input type='password' class='inputtext' name='pass' id='pass' tabindex='2' />. No maxlength. So you win; you got two out of three. :) I'll reopen this JIRA; I probably won't be the one fixing it (or applying patches to same) due to more pressing concerns; but it will be open unless somebody else closes or fixes it. At the very least even if we keep the maxlength we should be able to print a text stating that up to 20 characters is OK (like Yahoo! does).,This is what I found. Facebook: <input type='password' class='inputtext' name='password_new' id='password_new' autocomplete='off'> Yahoo: <input type='password' name='.pw1' id='newpw1' size='30'> Google: <input type='password' name='Passwd' id='Passwd'> StackExchange: <input name='password' id='password' type='password' style='opacity: 0.3; z-index: 1; position: relative;' class='edit-field-overlayed'>,OK; I checked the new user registration page for Google Mail; Yahoo Accounts; and Facebook. Google does it the way you like (no maxlength HTML restriction used; just client-side javascript complaining after-the-fact); but Yahoo and Facebook both place in a maxlength restriction.,I guess I don't consider maxlength='20' on an input element to be 'validation'. In my mind; I would be able to enter any length password in that box and the 'client-side validation' would tell me that the password was too long without needing a round-trip to the server. Then; supposing that JavaScript is disabled or whatever; the form is submitted anyway; the web application responds with a copy of the form; complete with an error about the length of the password. I guess when you lay it out like you have done in your previous comment; it is obvious that the maxlength=20 attribute needs to go. Because it is a password field; you cannot reliably tell what has happened. If it were a country field; you would spot this happening immediately. For example; Twitter only allows your 'location' to be 30 characters long. When my friend tried to fill it out; he saw that the field said 'United Kingdom of Great Britai'. Note that in this instance; he chose to leave it like that; as a sort of protest against the length restriction. But you get my point; I think. The combination of type='password' and maxlength='X' introduces a unique problem; in that there is no way for you to know whether your input has been truncated. This is why I believe there should be some notification. (Note that Roller does not even tell you that your password can only be 20 characters.),Noah; if we were to retain the client-side restriction of 20 (it being 'fine' as you write); you'd never need the server-side validation to check the length. That you would want us to do the latter implies that you would want us to get rid of the former; especially since you earlier reported at 17:09 that you want to be able to copy and paste an arbitrarily long string without it being 'munged' (truncated) by the client into 20 spaces. If; as you request; I don't mention that we already do client-side validation in the JIRA title; and just mention the server-side validation; that would incorrectly imply that we don't already do client-side validation (else why ask for server-side?); improperly inflating the need to do server-side validation as well as making Roller look kind of bad (as if we're not already doing client-side checks.) If you'd like; however; I'd be happy to delete this JIRA entirely so we don't have to worry about its title (I'm thinking of changing it to 'Play Ella Fitzgerald music on Roller startup'; myself... :),I notice the title change to: > Remove client-side restriction on password length; switch to server-side validation instead. Might I suggest: > Use server-side validation of password length The client-side stuff is fine. No reason to jettison it. Most web applications I have worked with or used do both. With HTML or JavaScript on the client side; and whatever else on the server-side as a failsafe.,I would note that the new title does not accurately reflect the nature of my bug report. If I were to retitle it; I would put: 'Enhance Roller to do server-side validation of password length' I will leave this to your discretion; however. Completely coincidentally; there is a post about this password lengths on Hacker News right now: What technical reasons are there to have low maximum password lengths? http://security.stackexchange.com/questions/33470/what-technical-reasons-are-there-to-have-low-maximum-password-lengths Again though; that's not really the core of my bug report. I just think Roller should do server-side validation instead of munging critical authentication information; where that munging can result in people being effectively locked out of Roller.,I'm not quite sure what to make of your response; to be honest. As a member of the foundation; why would I want to 'smear' Roller? I'd also remind you that assuming the best in people is a core principal of how we are supposed to operate here.[1] To address your specific points: * The purpose of the second validation field in many web forms is to compensate for the likelihood that when a human types something (especially when it is hidden) there is a good chance that a mistake will be made. If you are able to side-step this problem by copying the password from a clipboard; that does not defeat the purpose of the validation; it obviates it. * What do you mean when you say that passwords are supposed to be easy to remember? Who supposes this? Passwords; in security literature; are usually defined as 'something you know'. For example; two-factor authentication is a combination of 'something you know' (i.e. a password) and 'something you have' (i.e. an authentication fob; random number generator; or whatever). Being able to remember a password is convenient for sure; but seems fundamentally unrelated to its use as an authentication mechanism. (i.e. Makes it no more or less secure.) * You point out that during your time at the Department of Defence; you never heard of anybody using password generators. I would counter by saying that combination password generators/managers are very popular. Unfortunately; I was unable to dig up any statistics on this. I did find that Norton (a Fortune 500 company specialising in computer security) have one they make for consumers.[2] However; I use 1Password; which I believe is the most popular app of this kind for OS X. Stu Helm; of AgileBits; says[3] that they are 'probably into the 100s of thousands [of users] if not more by now. What I can tell you is that we have 61;786 registered members on our forums.' * Limiting a ZIP code field to 5 characters seems sensible; I agree. But I would hope that if you were able to submit a form with more than 5 characters for this field; that the web application would validate that on the server; and return the user back to the form with an error. From my experience developing web applications; this could be as little as an additional three lines of code in a validation class. My argument is not that using HTML to limit the length of form fields is bad practice. (Though I am not sure where you got the 98% figure from.) My argument is that silently truncating data and not doing proper server-side validation is bad practice. I can't back this up with anything concrete; as the industry as a whole is too immature to have a reference canon. All I can say is that silently munging data is; in my experience; generally frowned upon; because it can lead to unexpected situations exactly like the one I ran into here. * You actually did solve my problem! I was able to log in again after trying a 20 character substring! So thanks for that. * I use the maximum length allowed by 1Password when generating my passwords. As I never have to look at them; or remember them; it makes no difference to me. And so there is no reason why I shouldn't just go with the most secure option every time. I tried to download Norton's password generator/manager tool; but unfortunately I needed a US iTunes account. I wouldn't be surprised if other popular tools allow passwords of this length. So; I guess my point is: I see no reason why any tool would limit the length or makeup of a password. Any such restrictions arbitrarily limit the strength of what passwords can used. And I don't understand why that would ever be a goal. But let's say that; in this instance; Roller does want to limit the length of passwords. My argument is that your password change form should do server-side validation and warn users instead silently truncating their data. The fact that I managed to effectively lock myself out of Roller is a demonstration that this is a real problem. It's only one data point though; so I am not sure of the prevalence. But if password generators/managers are becoming more popular; this could become more frequent. * About the title of the bug; in the description; I put: 'Sorry for the vague ticket title. I don't want to make presumptions about the issue.' My meaning was that I didn't know what the problem was. From my perspective I had a) set a new password; b) logged out; and then c) lost access to my Roller account. So I guess a more descriptive title might've been 'Setting a password doesn't work' or something. Where 'work' here is defined as leaving Roller in a state where I can log back in using the new password I just set. * I attached a screenshot with my last comment. This is what it looks like when I copy and paste a long password into the field. The space to the right of the field might suggest it to me. But it is by no means obvious. If I was asked to stop and consider it; I might conclude that the text has just been scrolled off to the left; and that the field has some right-padding. But the fact of the matter is that I did not expect the password to be truncated; and so completely missed this. If I had realised that the text had been truncated; I would have used the substring to access my account; and I would not have asked the infrastructure team on IRC to help me; or subsequently created both an infrastructure JIRA ticket and a Roller ticket. [1] https://svn.apache.org/repos/private/committers/voluntary-code-of-conduct.txt [2] https://identitysafe.norton.com/ [3] http://www.quora.com/1Password/How-many-users-does-1Password-have,Attaching screenshot.,No; copying and pasting pasting passwords is never a good idea (for one; it defeats the purpose of the separate validation field; which is to make sure the user entered in the correct password); nor are 50+ character passwords acceptable; as it's a given you're going to need to write down that string and save it someplace as there's no way you can remember that from memory (as I had just told you earlier.) Furthermore; passwords are supposed to be easy for a person to remember (so he doesn't have to write it down); but hard for anyone else to guess--autogenerated passwords don't do that; and they also run the risk (if the generator is no good); of repeatedly giving out the same passwords; creating a huge security hole. Throughout all my years in DOD security work I've never remotely heard of people using 51-character (or any length; for that matter) password generators for their own password. Having HTML fields space-limited is a perfectly acceptable HTML design used all over the place. For ZIP code; for example; there's nothing wrong with limiting the entry field to 5 characters than to allow to allow you to type 50 and then have to hardcode a validation error of 'ZIP code too long' and have to translate it into 15 languages. (You really don't think there's more useful use of developer time?) Can you please provide some documentation that limiting field lengths in HTML is a bad practice; instead of just typing bugs based on your personal belief that HTML fields should not have limited length? We have to change Roller code just because you're in disagreement with 98% of the HTML community? I can't solve your problem; Noah. Even if I allowed 60 character passwords; there's nothing preventing you from turning around and complaining about an 80 character password not working. Nor are we going to shut off length limitations in our HTML fields and switch to validation text. Any auto-generator of passwords that uses more than 20 characters; as in the 51 your password generator supposedly uses; must have a mathematically innumerate developer because with 20 ASCII characters the number of possible permutations moves well; well into the stratosphere already. Indeed; given that your original bug report was titled 'Complex passwords don't work'; when the issue merely is that we don't accept passwords greater than 20 characters; makes it clear you're trolling and deliberately smearing the Roller project. There's no way you could have missed the fact that those 51 characters were getting truncated to 20 when you were pasting them into the field; and you just caused me to waste a bunch of time re-confirming that non-alphanumeric characters work for passwords.,BTW; this wasn't a hypothetical. In case that helps clarify. See INFRA-6091 for more. :),I use a password manager that generates passwords for me. So I copy and paste those passwords out of the password manager; and into the form. I believe my use of a password manager in this way constitutes very good security practice. I am reopening this bug because I believe that when I copy and paste a password; if it is 'too long' for Roller; I should receive a validation error. The paste should not silently truncate my password. Otherwise; every user who pastes a password that is 'too long' will be 'locked out' of their account. Scare quoted 'too long' because I think '20' is arbitary; and can't think of any technical reason a password should be limited in length. It concerns me that you mention database changes. I hope that the password never touches the database... Scare quoted 'locked out' because obviously; I am not actually locked out. My password is just a substring of the password I thought it was. (In fact; this is confirmed. I am back in.),Complex passwords up to Roller's password limitation of 20 characters work fine; sample 51-character password given in JIRA won't work because Roller doesn't allow more than 20.,OK; I tried a password of '{}~;'.$%;:#[].^()' *including* the quotes and Roller trunk worked fine with it -- note it includes every special character in sample password you supplied and then some. I don't know how you could have changed your password to something 51 characters long because Roller (even versions as old as 3.1) limits the password length in the entry field to 20 characters (which is long enough). So if you copy-and-pasted 51 only the first 20 characters would apply.,What is the precise shortcoming for you-- (a) Roller passwords aren't long enough for your liking or (b) there are specific special characters you would like to see supported that Roller doesn't presently allow; or (c) Roller isn't providing sufficient validation at the time of password entry allowing you to enter invalid passwords that it subsequently doesn't accept? For Roller to be able to handle passwords of infinite length is a Won't Fix (fails cost/benefit considering the database and other changes that would entail); because after 15 or so alphanumeric characters you're not effectively providing any more security; especially since past that length people start to copy and paste passwords (or choose exceedingly easy to remember ones); creating the much larger security hole in the process. But it looks like we can provide better password validation including length limitations for newly entered passwords ('c' above).
918,,,,,,,concern,You should also consider using Avro for the marshalling/unmarshal of the records. http://avro.apache.org/ Lots of benefits - in particular it's cross-language. Re writing to disk - perhaps just re-use the ZK WAL code and write to a disk that's not storing the transactional log.,Several comments: Aspects: ah; these aspects. I always though of it as a software development process; not as providing a solution for compiling different versions of the code. I actually looked if Java already had something similar like the C preprocessor but didn't find it (I'm afraid I'm still from the pre-Java era). But it seems like a great solution. Binary traces: I thought about that solution but was forgetting it due to idea of not messing with the server code thus using the actual ZK traces. However; together with the need of extending those traces and the idea of using AspectJ; it seems a neat solution. Disk overhead: I was forgetting this problem. Using some kind of ring buffer seems to be a solution but we are actually interested in understanding failures; so keeping the info in memory doesn't seem to be a good idea (the failure may be too radical and we lose the info).,http://www.eclipse.org/aspectj/ http://en.wikipedia.org/wiki/AspectJ I use this for network fault injection testing - instrumenting network operations with random failures. Works extremely well and I don't need to modify the original source at all.,You may consider having a look at ZOOKEEPER-512 for a reference within the context of ZooKeeper.,Re: Aspects; Miguel take a look at AspectJ/Aspect Oriented Programming. Basically allows you to hook code into preexisting code if I understand it correctly. Sort of like auxilary methods in CLOS.,(Assumed JIRA picked up email replies. Seems not >:/) As far as I've seen; this overhead comes in two forms; CPU and disk. CPU overhead is mostly due to formatting. Disk obviously because tracing will fill your disk fairly quickly. Perhaps something could be done to combat both of these. To fix the formatting problem we could use a binary log format. I've seen this done in C++ but not in java. The basic idea is that if you have TRACE('operation %x happened to %s %p'; obj1; obj2; obj3); a preprocessor replaces this with TRACE(0x1234; obj1; obj2; obj3) where 0x1234 is an identifier for the trace. Then when the trace occurs a binary blob [0x1234; value of obj1; value of obj2; value of obj3] is logged. Then when the logs are pulled of the machine you run a post processor to do all the formatting and you get your full trace. Regarding the disk overhead; traces are usually only interesting in the run up to a failure. We could have a ring buffer in memory that is constantly traced to; old traces being overwritten when the ring buffer reaches it's limit. These traces should only be dumped to the filesystem when an error or fatal level event occurs; thereby giving you a trace of what was happening before you fell over. -Ivan,The idea behind using ZK's log4j logs was to modify ZK's server-side code as less as possible. ZK is used in critical applications so a design principle that we are using is to avoid anything that may impact its reliability. In that sense; ZK's WAL is probably not a good option as it is specially critical for the correct operation of ZK. Another option that occurred to me was to create another log4j logger; which would be used specifically for logging the traces we need. Either if we use the original log4j logger or a new one; we can improve the performance using the same mechanisms that are used to make the WAL efficient. In relation to Aspects; I didn't understand what do you mean. Can you give me some pointers? Thanks!,Typically log4j logs are expected to be consumed by users - i.e. debugging; here you're really talking about output that will be machine processed. Is this really logging in the log4j typical sense; perhaps a separate mechanism should be used? Another problem with log4j logging is that changes to the message format; say to make it more 'readable'; can cause problems for the down stream processor. Not to mention that a separate mechanism could be made much more efficient than the general log4j log mechanism. Perhaps ZK's own WAL could be used for this - reuse the WAL code or write the information directly to the ZK transaction log (might not be such a good idea; but should be considered as an option). Additionally you should consider something like Aspects for this project. This is a cross-cutting feature; something that aspects are well suited for. A benefit of this approach is that it would allow those interested in the feature to enable it while those uninterested would incur zero performance penalty.,Let me give a longer explanation of the project. Practical experience with Zookeeper has shown that sometimes there are failures whose causes are hard to understand. Some of these failures may be caused by elusive bugs in the code; others may be due to failures rarer than crashes; say corruptions of data somewhere in a server. Zookeeper's traces (i.e.; logs in TRACE level) provide some information that can be helpful to understand what happened. For instance; they contain information about the clients that are connected; the operations issued; etc. However; in real deployments with many clients (say; hundreds); traces are typically turned off to avoid the high overhead that they cause. Furthermore; the data in the traces is probably not enough for our purposes because it does not include; e.g.; the replies to operations or the data values. The project involves 3 subtasks: 1- improve the efficiency of logging 2- improve the traces with additional information needed 3- build the checking tool,,,,,,,
19423,,,,,,,neutral,Attached QuickStart. Access URL is https://localhost:8443/test/ajaxtest - click on the buttons several times - refresh page: the counters should now reflect the clicks - click on the buttons more times - refresh page: the counters do not reflect click after first refresh,,,,,,,,,,,,,,,
37860,,,,,,,neutral,Attention: - Please refer https://issues.apache.org/jira/browse/TRINIDAD-1145 for a possible fix,,,,,,,,,,,,,,,
51837,,,,x,,,little anger,The change you want would be nice; but is simply not possible. The form data is either available or not; if there's a file upload exception; then none of the data submitted in the form is available to Tapestry. This is a function of the multipart/form encoding type and the underlying Jakarta FileUpload library.,After working with the solution for this bug; it appears to be inconvenient. The uploadException appears to get thrown before the values from the form are bound to the page instance. So if I have the following code to handle the uploadException: public Object onUploadException(Throwable cause) { myForm.recordError('Files may not be larger than 1.5 MB. Please choose a smaller file.'); return this; } ... then the page is completely empty when the user is returned to the page. Most (all?) people would treat this as a validation error when the file size is exceeded. I'm hoping that we end up with something like this: <input t:type='upload' t:id='file' validate='required' maxsize='1500000'/> And a default error message similar to the one above would be returned to the user. Feasible?,Final solution is to notify the containing page with an uploadException event; let it decide what to do.,The only solution I can see for this is to add an 'incomplete' flag to the UploadedFile interface. I believe that once we hit this exception; we can't count on getting any other uploaded files; or potentially; any of the other query parameters. Possibly the correct course is to identify the page; and trigger a specific event to indicate the failure.,,,,,,,,,,,,
75121,,,,,,,neutral,[[ Old comment; sent by email on Mon; 2 Oct 2006 23:39:22 +0200 ]] Rahul; I'll fax it in tomorrow (I'm in GMT+1; soon midnight). Hallvard,,,,,,,,,,,,,,,
13382,,,,x,,,anger and argument,As you wish http://cwiki.apache.org/confluence/display/WW/Struts+2+Blank+Archetype,Lukasz; yes; something like that; thanks! But I thought about adding that note to another page that also had that failing command line: http://cwiki.apache.org/confluence/display/WW/Struts+2+Blank+Archetype,I added note about staging repo http://cwiki.apache.org/confluence/display/WW/Struts+2+Maven+Archetypes,Oleg What you want to change? Add comment about staging repo?,Change the documentation at least,The first thing that Maven users not familiar with Struts2 do is try to create a project from an archetype using the command from the online documentation. Please make them happy.,Ad.1 Yes; you are right and I will try to move Struts2 archetypes inside Struts2 project to be a submodule and included in release process of whole project Ad.2 It isn't so obvious but there were only few archetypes released so far; so it will be better to put a list of available versions of archetypes Regards _x0089_ÛÒ Lukasz,Lukasz: In order to be considered the final comments in the report: should I request an Enhancement for them?,Archetypes are ready to be released - the vote is in progress You can try to use staging repo as below mvn archetype:generate -DarchetypeCatalog=http://people.apache.org/builds/struts/2.1.8.1/m2-staging-repository/ Regards _x0089_ÛÒ Lukasz,,,,,,,
72474,,,,,,,satisfaction,Closing all resolved issues due to a successful 1.0.0-incubating release,http://cwiki.apache.org/confluence/display/SHIRO/How+to+Contribute,,,,,,,,,,,,,,
61118,,,,,x,,cocnern,I do have some interest in working on this; but it's not currently on my radar. Implementing SOLR-4241 would illustrate the issues that need fixing ... although if this is tackled first; writing SOLR-4241 would be much easier.,I have closed older issues SOLR-2728 and SOLR-2729; any work on those issues can continue in this one. SOLR-2729 has a patch attached. I haven't checked to see if this issue is a duplicate; but I would not be surprised if it is. This is part of an effort to close old issues that I have reported. Search tag: elyograg2013springclean,Here are some general ideas; preliminary because I have not taken a close look at the code yet. For reference; here is a completed status response on a full-import from 3.5.0:  <?xml version='1.0' encoding='UTF-8'?> <response>  <lst name='responseHeader'>   <int name='status'>0</int>   <int name='QTime'>0</int> </lst> <lst name='initArgs'>   <lst name='defaults'>     <str name='config'>dih-config.xml</str>   </lst> </lst> <str name='status'>idle</str> <str name='importResponse'/> <lst name='statusMessages'>   <str name='Total Requests made to DataSource'>1</str>   <str name='Total Rows Fetched'>11287894</str>   <str name='Total Documents Skipped'>0</str>   <str name='Full Dump Started'>2012-04-03 17:38:01</str>   <str name=''>Indexing completed. Added/Updated: 11287894 documents. Deleted 0 documents.</str>   <str name='Committed'>2012-04-03 20:16:32</str>   <str name='Total Documents Processed'>11287894</str>   <str name='Time taken '>2:38:31.314</str> </lst> <str name='WARNING'>This response format is experimental.  It is likely to change in the future.</str> </response>  I was thinking it might be a good idea to have two response sections in addition to the echoParams section already mentioned - one for a human readable response and one for a relatively terse machine readable response. The human readable version would be fairly open to change; and could include extra verbiage so it's very understandable for a person. The machine readable version would have more elements; each of which is very simple; probably just a numeric value or a true/false indicator. A design decision needs to be made early - do we include all elements in every response (with the value set to zero; blank; or false); even if they don't apply to the current status? My first instinct is to include all elements; but maybe that's wrong.,Here's an idea; at least for 3x; assuming it's not unilaterally killed by the bug-fix-only mode: A configuration knob to use the old response or the new response. It would default to old. For 4.0; that configuration knob seems like a good idea; defaulting to the new response. In 4.1 or 5.0; the old response gets removed.,I don't think this can be done for 3.x as the branch is in bug-fixes-only mode. Also; this will create backwards-incompatible changes for users' scheduling programs; so this kind of thing is better suited for a new major release.,I personally would like to see this included in 3x; since that's what I use. How do the rest of you feel about that?,,,,,,,,,,
