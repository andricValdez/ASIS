id,love,joy,surprise,anger,sadness,fear,notes,comment N,comment N-1,comment N-2,...,comment 2,comment1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
15893,,,,,,,,You are only flushing the writer; donå«t you need to close it too? writer.flush(); writer.close();,Is there a reason the writer.flush() is not called if a JSPfactory is not used? You should always flush() and close() your streams and writers.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
79309,,,,,,,,Closing old resolved issues,This task is going to take several hours (at least) to complete; especially as lots of new dependencies have been added to rave recently. Furthermore; the shindig dependencies turned up to not having their own appropriate license and notice files in place; which thus needs to be checked out first (by ourselves) too. For the next release (0.8-incubating) all this needs to be sorted out; before we can start creating a new release candidate... And therefore I'm upgrading this issue status to BLOCKER!,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
29492,,,,,,,,I think this should be fixed/changed for uima-base too. Is there a reason it wasn't?,There are different scripts between core framework and UIMA-AS. Will fix the UIMA-AS scripts with this issue.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
22766,x,x,,,,,,Fixed and I've tested it.,Everything works great now. Thanks.,Can you plese give it a try now? Hopefully the second attempt will work :),Sorry; overlooked that. Will commit it soon.,In the removePage() method you removed the indicesList.toArray() so I now get a ConcurrentModificationException because the code tries to iterate through a list at the same time it's removing items. You could use something like this public void removePage(int pageId) { if (idToWindowIndices == null) { rebuildIndices(); } List indices = (List)idToWindowIndices.get(pageId); if (indices != null) { Object[] indicesArray = indices.toArray(); // Make a copy of the list so we don't get a ConcurrentModificationException for (int i=0; i < indicesArray.length; i++) { int index = ((Integer)indicesArray[i]).intValue(); PageWindowInternal window = (PageWindowInternal)windows.get(index); if (window.pageId == pageId) { removePage(window.pageId; window.versionNumber; window.ajaxVersionNumber); } } } } The other alternative would be to pass the iterator through to the removePage() method so it can call Iterator.remove() but this seems a lot more complicated. Also the list should never really be that big so copying it to an array shouldn't impact performance.,Hi; thanks for the bug report. I wish we had more reports like this. I've attempted to fix the issue; can you plese test if the current trunk works for you?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
63758,x,,,,,,,Committed revision 682671. Added an excludes for **/target/ to the patch to make sure the DataImportHandler binaries do not get packaged. Thanks Jeremy!,Quick patch to add contrib/** to the package task. This may be all that is required; but I'm not for sure.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33984,,,,,,,,reattaching with grant of license,reattaching with grant of license,samples included in build,I have raised tuscany 628 to cover the exceptions being raised by the execution of the samples.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
14571,,x,,,,,,yay! it should be really really easy (not including the test; I think it's just deleting 6 characters),If time permits; I'm planning to do a backport of some issues for a Struts 2.0 maintainance release. This one would definitely make it into the port.,I agree! Please backport to a 2.0.x release!,Is there any chance this fix could be backported to a 2.0.x release?,Well; in the current code; your change has been made (by me it seems); so how warnings will be printed; but the property setting will continue. I still think this should be handled better; but it should be fine for now since it works the way we want but will just print out warnings in the semi-rare case the result uses the parameters for something they weren't intended for; which at this point; it seems only to be the ServletActionRedirectResult.,The reason exceptions are ignored is result parameters are not always meant to be applied as setters. For example; the redirect results programatically access the parameters and interpret them as parameters to set on the redirect request. Therefore; there is no corresponding setter and OGNL will throw an exception. Certainly; the current implementation is ideal; but just having exceptions thrown is not the solution. Perhaps we let results declare themselves as supporting 'strict' parameter assignments?,I'm habitual...here is the patch with the Struts 2 code formatting rather than my company's formatting. Sorry for the confusion! thanks; aaron,Don't use this one...non standard code formatting.,Patch for project created from project root; includes proposed fix and test case. Proposed fix is simply to call to a more restrictive setProperties() on the OgnlUtils class which prevents exceptions from being thrown during binding. Don't use this one...non standard code formatting. See newest attachment.,If you come up with a proposed fix; please post the patch to this ticket.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
34194,x,,,,,,,Patch applied. Thanks!,Patch is provided. A celtix configuration file called server.xml is added.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
56246,x,,,,,,,Fixed in nightly build 20010612. Will be fixed in Struts 1.0 final.,Created an attachment (id=207) Patch for LinkTag,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
58715,,,,,,,,Fixed in revision 1073288,Changing the goal to 'single' works the same and it is a better solution; since 'attached' goal is deprecated. Committed this change in revision 1073288.,This error disapperar if we change the goal of the maven-artifact-plugin to 'attached' instead of 'assembly'. This goal should behave the same but do not affect the kres build process.,Can reproduce the error with the attached mvn-minimal-configuration-pom.xml; which includes only the following modules; omitting all modules except: * enhancer/SemiAutomaticContentEnhancer * kres/eu.iksproject.kres.shared/dependency/owlapi3 * kres/eu.iksproject.kres.ontologies,I attach the output of the last try (enhancer-16),Kres build process fails when executing fro the root of Stanbol with the above output: [INFO] ------------------------------------------------------------------------ [ERROR] BUILD ERROR [INFO] ------------------------------------------------------------------------ [INFO] Failed to resolve artifact. Missing: ---------- 1) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 åÊåÊTry downloading the file manually from the project website. åÊåÊThen; install it using the command: åÊåÊåÊåÊåÊåÊmvn install:install-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file åÊåÊAlternatively; if you host your own repository you can deploy the file there: åÊåÊåÊåÊåÊåÊmvn deploy:deploy-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file -Durl=[url] -DrepositoryId=[id] åÊåÊPath to dependency: åÊåÊ 1) eu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 åÊåÊ 2) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 ---------- 1 required artifact is missing. for artifact: åÊåÊeu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 from the specified remote repositories: åÊåÊcom.springsource.repository.bundles.external (http://repository.springsource.com/maven/bundles/external); åÊåÊcentral (http://repo1.maven.org/maven2); åÊåÊjava.net (http://download.java.net/maven/2); åÊåÊapache (http://repository.apache.org/content/groups/snapshots-group) [INFO] ------------------------------------------------------------------------ [DEBUG] Trace org.apache.maven.lifecycle.LifecycleExecutionException: Missing: ---------- 1) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 åÊåÊTry downloading the file manually from the project website. åÊåÊThen; install it using the command: åÊåÊåÊåÊåÊåÊmvn install:install-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file åÊåÊAlternatively; if you host your own repository you can deploy the file there: åÊåÊåÊåÊåÊåÊmvn deploy:deploy-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file -Durl=[url] -DrepositoryId=[id] åÊåÊPath to dependency: åÊåÊ 1) eu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 åÊåÊ 2) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 ---------- 1 required artifact is missing. for artifact: åÊåÊeu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 from the specified remote repositories: åÊåÊcom.springsource.repository.bundles.external (http://repository.springsource.com/maven/bundles/external); åÊåÊcentral (http://repo1.maven.org/maven2); åÊåÊjava.net (http://download.java.net/maven/2); åÊåÊapache (http://repository.apache.org/content/groups/snapshots-group) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:711) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalWithLifecycle(DefaultLifecycleExecutor.java:556) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.forkProjectLifecycle(DefaultLifecycleExecutor.java:1205) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.forkLifecycle(DefaultLifecycleExecutor.java:1033) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:643) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalWithLifecycle(DefaultLifecycleExecutor.java:556) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoal(DefaultLifecycleExecutor.java:535) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalAndHandleFailures(DefaultLifecycleExecutor.java:387) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeTaskSegments(DefaultLifecycleExecutor.java:348) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.execute(DefaultLifecycleExecutor.java:180) at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:328) at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:138) at org.apache.maven.cli.MavenCli.main(MavenCli.java:362) at org.apache.maven.cli.compat.CompatibleMain.main(CompatibleMain.java:60) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.codehaus.classworlds.Launcher.launchEnhanced(Launcher.java:315) at org.codehaus.classworlds.Launcher.launch(Launcher.java:255) at org.codehaus.classworlds.Launcher.mainWithExitCode(Launcher.java:430) at org.codehaus.classworlds.Launcher.main(Launcher.java:375) Caused by: org.apache.maven.artifact.resolver.MultipleArtifactsNotFoundException: Missing: ---------- 1) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 åÊåÊTry downloading the file manually from the project website. åÊåÊThen; install it using the command: åÊåÊåÊåÊåÊåÊmvn install:install-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file åÊåÊAlternatively; if you host your own repository you can deploy the file there: åÊåÊåÊåÊåÊåÊmvn deploy:deploy-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file -Durl=[url] -DrepositoryId=[id] åÊåÊPath to dependency: åÊåÊ 1) eu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 åÊåÊ 2) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 ---------- 1 required artifact is missing. for artifact: åÊåÊeu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 from the specified remote repositories: åÊåÊcom.springsource.repository.bundles.external (http://repository.springsource.com/maven/bundles/external); åÊåÊcentral (http://repo1.maven.org/maven2); åÊåÊjava.net (http://download.java.net/maven/2); åÊåÊapache (http://repository.apache.org/content/groups/snapshots-group) at org.apache.maven.artifact.resolver.DefaultArtifactResolver.resolveTransitively(DefaultArtifactResolver.java:360) at org.apache.maven.artifact.resolver.DefaultArtifactResolver.resolveTransitively(DefaultArtifactResolver.java:304) at org.apache.maven.plugin.DefaultPluginManager.resolveTransitiveDependencies(DefaultPluginManager.java:1499) at org.apache.maven.plugin.DefaultPluginManager.executeMojo(DefaultPluginManager.java:442) at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:694) ... 21 more [INFO] ------------------------------------------------------------------------ [INFO] Total time: 2 minutes 48 seconds [INFO] Finished at: Fri Feb 11 17:26:58 CET 2011 [INFO] Final Memory: 118M/282M [INFO] ------------------------------------------------------------------------ I started to investigate this; that does not happen when compiling in the /kres folder I before launched the command (evry time): $ cd $M2_HOME/repository $ rm -rf hermit/ && rm -rf owl* && rm -rf eu Then from the the root of Stanbol $ mvn clean install -X -DskipTests I did this with different configurations: * All non-kres moduls commented >> success * All but the parent module >> failure * All but the parent;entityhub modules >> failure * All but the parent;entityhub;enhancers modules >> success So I started investigating the enhancer module; and commented all but that: * enhancer-1 >> failure (all modules) * enhancer-2 >> success (only the parent module) * enhancer-3 >> success (parent module + base enhancer modules) * enhancer-4 >> success (parent module + base enhancer modules + autotag;opennlp;lang-id) * enhancer-5 >> success (parent module + base enhancer modules + autotag;opennlp;lang-id;metaxa) * enhancer-6 >> success (parent module + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging) from this point on I have activated also 'parent' and 'entityhub' in the root pom: * enhancer-7 >> success (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais) * enhancer-8 >> success (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta) * enhancer-9 >> seccess (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta + jersey) * enhancer-10 >> success (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta + jersey + clerezza/enhancer) * enhancer-11 >> success (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta + jersey + clerezza/enhancer;clerezza/sparql) * enhancer-12 >> success (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta + jersey + clerezza/enhancer;clerezza/sparql + launcher/full) * enhancer-13 >> success (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta + jersey + clerezza/enhancer;clerezza/sparql + launcher/full;launcher/lite) * enhancer-14 >> success (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta + jersey + clerezza/enhancer;clerezza/sparql + launcher/full;launcher/lites + integration-tests) * enhancer-15 >> failure (parent module + entityhub + base enhancer modules + autotag;opennlp;lang-id;metaxa;geonames;entitytagging;opencalais;zemanta + jersey + clerezza/enhancer;clerezza/sparql + launcher/full;launcher/lites + integration-tests + SemiAutomaticContentEnhancer) --> same as enhancer-1 I tries also the following: Activating 'enhancer' only in the parent pom (and kres; of course) * enhancer-16 >> failure (parent module + base enhancer modules (generic) + SemiAutomaticContentEnhancer) So the problem is related to some configuration incompatibility between enhancer/SemiAutoamticContentEnhancer and kres/eu.iksproject:eu.iksproject.kres.ontologies I will investigate more on that.,This problem is again on after moving the kres module compilation at the end of the process in the main stanbol pom.xml,Fixed in 1060423.,I encounter the problem again even after following the instructions in the readme. [INFO] Unable to find resource 'eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7' in repository central (http://repo1.maven.org/maven2) [INFO] ------------------------------------------------------------------------ [ERROR] BUILD ERROR [INFO] ------------------------------------------------------------------------ [INFO] Failed to resolve artifact. Missing: ---------- 1) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 åÊåÊTry downloading the file manually from the project website. åÊåÊThen; install it using the command: åÊåÊåÊåÊåÊåÊmvn install:install-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file åÊåÊAlternatively; if you host your own repository you can deploy the file there: åÊåÊåÊåÊåÊåÊmvn deploy:deploy-file -DgroupId=eu.iksproject -DartifactId=eu.iksproject.kres.shared.dependency.owlapi -Dversion=0.7 -Dpackaging=jar -Dfile=/path/to/file -Durl=[url] -DrepositoryId=[id] åÊåÊPath to dependency: åÊåÊ 1) eu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 åÊåÊ 2) eu.iksproject:eu.iksproject.kres.shared.dependency.owlapi:jar:0.7 ---------- 1 required artifact is missing. for artifact: åÊåÊeu.iksproject:eu.iksproject.kres.ontologies:bundle:0.7 from the specified remote repositories: åÊåÊcom.springsource.repository.bundles.external (http://repository.springsource.com/maven/bundles/external); åÊåÊcentral (http://repo1.maven.org/maven2); åÊåÊjava.net (http://download.java.net/maven/2); åÊåÊapache (http://repository.apache.org/content/groups/snapshots-group),Fixed in #1049533.,The problem is reproducible when deleting the eu/iksproject tree from the local Maven repo $ rm -rf ~/.m2/repository/eu/iksproject/ and then start a Maven build using the top level Stanbol POM. This problem is not fixed by adding the missing JARs as mentioned by Enrico. As Andreas noted there is somehow a difference between calling Maven build in the kres directory or using the top level POM.,The problem stated in this issue disappeared after a $ mvn dependency:resolve,I manually installed the jars according to the README but that did not resolve this problem. Interestingly there is a dfference between executing mvn install in the stanbol directory and the kres subdirectory. I did not see this error when executing the command in the kres directory. I got the error mentioned in STANBOL-10 then.,The KReS module relies on three external dependencies that are not available in the maven repository. As described in the main stanbol README (http://svn.apache.org/repos/asf/incubator/stanbol/trunk/README.txt) you should import those irbraries manually before compile KReS. From the KReS folder do the following: $ mvn install:install-file -Dfile=kres/lib/owlapi-3.0.0.jar \ åÊåÊåÊåÊåÊåÊåÊ-DgroupId=owlapi -DartifactId=owlapi -Dversion=3.0.0 -Dpackaging=jar $ mvn install:install-file -Dfile=kres/lib/HermiT.jar \ åÊåÊåÊåÊåÊåÊåÊ-DgroupId=hermit -DartifactId=hermit -Dversion=1.2.4 -Dpackaging=jar $ mvn install:install-file -Dfile=kres/lib/owl-link-1.0.2.jar \ åÊåÊåÊåÊåÊåÊåÊ-DgroupId=owl-link -DartifactId=owl-link -Dversion=1.0.2 -Dpackaging=jar Note that; as for issue STANBOL-10; tests for the rule module actually breaks; so you should compile it with the -DskipTests flag.,,,,,,,,,,,,,,,,,,,,,,,,
68066,,,,,x,,,Fixed. Sorry for long waiting. I didn't find the time. Author: tterm Date: Mon Jul 21 01:53:35 2008 New Revision: 678365 URL: http://svn.apache.org/viewvc?rev=678365&view=rev Log: Preserving or configuring content-type of http-header Modified: servicemix/smx3/branches/servicemix-3.2/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/HttpEndpoint.java servicemix/smx3/branches/servicemix-3.2/deployables/bindingcomponents/servicemix-http/src/main/java/org/apache/servicemix/http/processors/ProviderProcessor.java,Can you give me an indication; when this issue will be solved?,So you don't expect more information from me? Regards; Jan Reynaerts,Guillaume: I know what he wants to do. It's not much to do. I will do it this during the week.,Could you please provide a patch / diff file instead ? See http://servicemix.apache.org/contributing.html for more informations.,I've attached the 2 patched files. I'm not sure if this is the right way to do it,Can't find the patch.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6272,,,,,,,,The problem is not in the SAX parser. The problem occurs if you give the -server flag to the jvm (jdk 1.4/1.3) e.g. java -server <sax parser class> on a really big file. Will cause a stackOverflow. Greg Meagher,I tried to SAX parse a simple xml file <?xml version='1.0' ?> <root> ...around 225MB of text content... </root> with xerces2.0.1 and xerces from CVS but could not reproduce the problem. Please attach a small java program/xml file to reproduce it. You can snip the huge 200MB content in your xml file and add a comment there before attaching .,I'm not using validation and the jdk is 1.3. As far as sample code: I can reproduce this problem with a very large xml file and a character() callback of simpley a return. For Example: If the XML file contained the following: åÊ<DOCUMENT vendor='BlueScooter;Inc.' version='1.0' operation='ADD'> <URL docpoolid='DC1-1' mimetype='text/html' url='http%3A%2F%2Ftest.file.bug134.com%2F/test.html' date='1003867000' size='7881' language='eng'/> <ABSTRACT>NO_ABSTRACT</ABSTRACT> <CONTENT> ....200 M of content. </CONTENT> and the character(char[] buffer; offset; count) {} callback contained simply a return .The stack will overflow almost immediately. Thanks for responding to this bug. If there is more you need please let me know. Greg Meagher,Are you using a schema to validate your instance file?. If yes; are you using large values for min/maxOccurs? If no; please attach your instance file with a sample program to reproduce the error. Also; which jdk/os are you using?.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
14206,,,,,,,,Ported the solution of WW-2551 to the Struts 2.0 branch.,This bug is the same of WW-2551; but it was not backported to Struts 2.0 branch.,Finally we have a test case! See the attachment at TILES-278.,I've confirmed that this issue is still present in Struts 2.1.1 The flush attribute of s:action has no impact on the tiles result. Unlike the tiles:insertDefintion tag that includes a flush attribute; the TilesResult always flushes. Recommendation: add a boolean flush parameter to TilesResult (default true) When false; a tiles result can then be rendered within the page of another result using s:action.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8053,x,,,,,,,Robert; åÊåÊåÊåÊYour patch is in; please help verify; thanks. Rgds; PeiYong,Created an attachment (id=2169) .NET Project Files in Attached Zip File,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
31554,,,,,,,,Dave has let me know that this has resoved the issue,Attempt at a fix in 1.x r777627 and 1.5 branch r777632,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
47248,,,,,,,,In r681863,The attached patch should fix this issue,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46997,x,x,,,,,,Ah; great; things are running now. Thanks guys.,HI Kevin If you have apt; you might try $ apt-get install libbit-vector-perl If you need to do it the hard(er) way; try: $ perl -MCPAN -e 'install Bit::Vector' If you've never used CPAN in this way; it might ask you many questions (take the defaults). It may try first to upgrade itself. It may be painful; may not work at all. There are slightly more manual ways to do it; in which you ask for a shell and can then set options (auto follow dependent packages is very useful). apt-get it aint,Doh; ok. Could you tell me how to install that? I know it has something to do with CPAN; but I'm not a perl person.,Can't locate Bit/Vector.pm this is a required module. stated in lib/perl/README,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
19722,,x,,,,,,Just an idea: how about treating a jar as versioned resource? For example in my case that would work beautifully: my star rating component was in its own jar file; so everything would have the same version somewhere above; and all the relative URLs would resolve just fine. Since jar is pretty much invisible at runtime maybe we can have some version marker inside package; and then version in the URL can be at the level; so all other relative URLs inside package would work fine below that level. That might make sense for other cases: for example a skin for application where bunch of images and css and scripts can be packaged.,Technically a resource is something that responds to a request with some kind of response to the client. A package is just a virtual location represented by a file system folder or a jar file location. So it should be treated differently from a resource. But I could imagine it makes sense to support urlFor(...) to resolve a package location. However this has to be discussed first and will not happen before 1.5.0 since we are almost gone final.,some obsolete documentation - thanks for the pointer :-),Oh; and if possible the change need to be better communicated/hinted in the documentation because dr. Google and wiki documentation point at the timestamp approach https://cwiki.apache.org/WICKET/caching-in-wicket-15.html,I think supporting package as a resource makes a lot of sense because it is widely used practice to lookup additional resources like images and css files based on 'root' location.,not pretty but working: String url = urlFor(new ResourceReference(StarRatingPanel.class; 'img') { @Override public IResource getResource() { return new IResource() { @Override public void respond(Attributes attributes) { } }; } }; new PageParameters()).toString(); log.info('url=' + url); Basically it's a kludge to resolve the url to a package location with a resource reference pointing to a non-existant resource. I don't know if a package counts as a resource. Maybe we should add some kind of official support for that?!,Like Martin said; you can use a custom caching strategy. sample ------------- private abstract class CustomResourceCachingStrategy implements IResourceCachingStrategy { private final IResourceCachingStrategy delegate; public CustomResourceCachingStrategy(IResourceCachingStrategy delegate) { this.delegate = delegate; } @Override public void decorateUrl(ResourceUrl url; IStaticCacheableResource resource) { if (shouldCache(resource)) { delegate.decorateUrl(url; resource); } } @Override public void undecorateUrl(ResourceUrl url) { delegate.undecorateUrl(url); } @Override public void decorateResponse(AbstractResource.ResourceResponse response; IStaticCacheableResource resource) { if (shouldCache(resource)) { delegate.decorateResponse(response; resource); } } åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊ// override for your needs e.g. by using a marker interface protected abstract boolean shouldCache(IStaticCacheableResource resource); } and use it like this: final IResourceCachingStrategy delegate = getResourceSettings().getCachingStrategy(); getResourceSettings().setCachingStrategy(new CustomResourceCachingStrategy(delegate));,The resource knows this by implementing IStaticCacheableResource. Create a custom resource that doesn't implement this interface and its url wont be versioned.,This approach makes creates tight coupling with top level entity: CachingStrategy and makes it necessary to use custom strategy. That does not seem to be better than little hint from resource if it participates in the versioning.,I think this is possible with custom caching strategy (see last comment by Peter above). Your custom strategy can do nothing in org.apache.wicket.request.resource.caching.IResourceCachingStrategy.decorateUrl(ResourceUrl; IStaticCacheableResource) for the resources you decide.,The approach implemented is a blanket one - what is removed is the ability to selective remove versioning from a particular resource. I do not need timestamp in particular; but a way to let wicket know that THIS resource should not use versioned URL. IMO this is a valid use case. Please consider returning some sort of marker method to ResourceReference to allow using custom versioning; or no versioning at all.,to manually remove the version dependant part of the url you eventually could use: åÊåÊApplication#getResourceSettings().getCachingStrategy().undecorateUrl(url),PackageResourceReference#getLastModified() was introduced when adding improved caching support for package resources. Recently there was a refactor (https://issues.apache.org/jira/browse/WICKET-3948) to remove some limitations of this approach. PackageResourceReference#getLastModified() became obsolete and was therefore removed. If you really need lastModified() from within PackageResourceReference you can use this (though it's a little inconvenient): åÊåÊPackageResourceReference reference = /* ... */; åÊåÊPackageResource resource = (PackageResource)reference.getResource(); åÊåÊTime lastModified = resource.getResourceStream().lastModifiedTime(); If we get another release candidate for 1.5 I will remove the need for the type-cast. IResourceSettings#setUseTimestampOnResources() has been replace by a more powerful solution. check https://cwiki.apache.org/WICKET/migration-to-wicket-15.html#MigrationtoWicket1.5-getResourceSettings%2528%2529.setAddLastModifiedTimeToResourceReferenceUrl%2528%2529hasbeenreplacedbyIResourceCachingStrategy to get all the details.,åÊval imgUrl = RequestCycle.get().urlFor(new PackageResourceReference(classOf[StarRatingPanel]; 'jquery.raty-1.0.1/img'){ åÊåÊåÊåÊåÊåÊoverride def getLastModified = null//prevent cacheable urls <-- this does not work any more åÊåÊåÊåÊ}; null) åÊåÊåÊåÊresponse.renderJavaScript('$j.fn.raty.defaults.path= '' + imgUrl + '';'; 'raty-images-fix'),,,,,,,,,,,,,,,,,,,,,,,,
10446,,,,,,,,This bug has been fixed in Xalan Java 2.5.2. Please verify.,Applied patch to CVS.,If the type of tge second argument is not node-set; throw run time error.,Created an attachment (id=6012) Patch for FuncDocument,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
29351,,,,,,,,This issue is maybe related to UIMA-1408.,Philip please provide more details until then the issue cannot be reproduced.,Hi Philip; the annotation which is selected in the outline view should be selected in the text editor. An annotation which is part of feature structure and selected should be also be selected in the editor. I think this is somehow broken on your machine; I would like to find out why and fix it. For this I need more information from you. Please go to the about dialog and click on configuration details and attach these to the issue. It would also be nice if you can attach a a screenshot which shows that the selection in the editor does not work when something in the outline is selected; maybe this gives a clue. Thanks; JÌ¦rn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
13391,,,,,,,,I am also having the same issue with a java.sql.Timestamp based attribute. The date I entered into the field was 'not a date'. Of course; XWorkBasicConverter fails to convert successfully and throws an XWorkException; then it is downhill from there on. When attempting to find the method to call in OgnlRuntime it appears to look for a String parameter; when it should be looking for the java.sql.Timestamp parameter.,I think it's related to the same problem with primitives (and wrappers) convertion,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
56124,,,,,,,,The problem is *not* really a bug in Struts but The problem is *not* really a bug in Struts but Bug #3534 of Catalina's Warp Connector; which causes the request's wrapped input stream to be closed to early. However; Strut's shouldn't work on as nothing has happened but should throw an exception to clearly indicate the error. Otherwise it is really hard to track down any problem related with invalid data of an submitted multipart form. åÊof Catalina's Warp Connector; which causes the request's wrapped input stream to be closed to early. However; Strut's shouldn't work on as nothing has happened but should throw an exception to clearly indicate the error. Otherwise it is really hard to track down any problem related with invalid data of an submitted multipart form.,Some additional note: The missing parameters always appear *after* the file to upload within the client request; i.e. POST /action/attachment-create HTTP/1.1 Host: localhost:7000 User-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:0.9.5+) Gecko/20011009 Accept: text/xml; application/xml; application/xhtml+xml; text/html;q=0.9; image/png; image/jpeg; image/gif;q=0.2; text/plain;q=0.8; text/css; */*;q=0.1 Accept-Language: de; en;q=0.50 Accept-Encoding: gzip; deflate; compress;q=0.9 Accept-Charset: ISO-8859-1; utf-8;q=0.66; *;q=0.66 Keep-Alive: 300 Connection: keep-alive Cookie: JSESSIONID=F81185664918B2B3A970034023759421 Referer: http://localhost:7000/action/attachment-edit-list?call-id=23054 Content-type: multipart/form-data; boundary=---------------------------1627350459202016671524971257 Content-Length: 5254 -----------------------------1627350459202016671524971257 Content-Disposition: form-data; name='description' Test..... -----------------------------1627350459202016671524971257 Content-Disposition: form-data; name='attachment'; filename='boot-compat.b' Content-Type: application/msaccess ???ZR?B??BB$?ZR???Z?? ??[???t?S???[K???r??t< t??8?t?C?u???X?N??^1????t!??t?< t? <0r<9w;0?????????s????????? -----------------------------1627350459202016671524971257 Content-Disposition: form-data; name='com.consol.cmjsp.control.action.BaseAction.FORM_ACTION' /attachment-create -----------------------------1627350459202016671524971257 Content-Disposition: form-data; name='call-id' 23054 -----------------------------1627350459202016671524971257--,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
20905,,,,,,,,1.3.x is no longer maintained outside of security-related issues; please upgrade to 1.4.x,this is class we using for attaching dynamic js resources,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
30436,,,,,,,,This one will probably not make 2.1 release. It is some bug in the SWT impl on the Mac; but for widgets that are now 'deprecated' in Eclipse. The fix will include upgrading the widgets used (and losing Eclipse compatiblity for levels prior to 3.1 I think - which was why this upgrade wasn't done earlier).,Marshall; I know you've been looking into Mac issues lately. Just making sure you didn't miss this one.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
71085,,,,,,,,Linked the API docs from the main navigation which completes this task for now.,Committed the generated apidocs to our site SVN at Rev. 773487 and updated the site base on people.a.o. The Sling 5 API docs have been generated as follows: $ svn export http://svn.apache.org/repos/asf/incubator/sling/tags/sling-5-incubator-source-release/ sling5 $ # Fix root pom.xml (see below) $ cd sling5 $ mvn -DexcludePackageNames='*.impl:*.internal:*.jsp:sun.misc:*.juli' org.apache.maven.plugins:maven-javadoc-plugin:2.5:aggregate,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
73415,x,,,,,,,Patch applied. Thanks,The binary images that are mentioned and used in the reviewed code. Both images are made by me and can be freely used in Shindig.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
76631,,,,,,,,Closing resolved/won't fix issues.,Roller requires Sun Java SE 5 and will not run with 1.4.2 or with GCJ.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
63070,,,,,,,,Bulk close for Solr 1.4,committed.,pretty trivial bug; but I thought I'd fix it while I was converting everything for reuse and with the new attribute API,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46878,,x,,,,,,Bryan; I agree on the folder structure change. This surely will break existing code. For your other point; it isn't really necessary that's right but in my opinion it fits much better in the Rails 'convention over configuration' principle. FYI; we are using those changes successfully in all our thrift sub-projects (we are having 5 of them).,I don't disagree that generating the folder structure to match the namespace structure is a good idea; but that is a breaking change; so I wonder if that shouldn't be in it's own issue and patch instead of under this one. For what it's worth; we use Thrift objects in Rails too; but we just require them in environment.rb. Is it important for the autoloading to pick up Thrift objects?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
16908,x,,,,,,,Thanks. The problem is with deferred node expansion; when this is on the Node appears as null instead of a Text node with an empty String. I'll merge a fix shortly.,yes a wsse:Password element is sent across the wire and the UsernameToken look like this exactly: <wsse:UsernameToken wsu:Id='UsernameToken-1' xmlns:wsse='http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd' xmlns:wsu='http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd'> åÊåÊåÊåÊåÊ<wsse:Username>ser</wsse:Username> åÊåÊåÊåÊåÊ<wsse:Password Type='http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordText'></wsse:Password> </wsse:UsernameToken> Seb.,Can you clarify whether a wsse:Password element is sent across the wire or not? So; does the UsernameToken look like this: <wsse:UsernameToken xmlns:wsu='http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd' wsu:Id='UsernameToken-15' xmlns:wsse='http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd'> åÊåÊåÊåÊ<wsse:Username>emptyuser</wsse:Username> åÊåÊåÊåÊ<wsse:Password Type='http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordText'/> </wsse:UsernameToken> or this: <wsse:UsernameToken xmlns:wsu='http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd' wsu:Id='UsernameToken-15' xmlns:wsse='http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd'> åÊåÊåÊåÊ<wsse:Username>emptyuser</wsse:Username> </wsse:UsernameToken> Colm.,I am reopening this issue. From my place i cannot commit code. @ Ruchith The problem is at server who recieves the empty password. the callback method gets null password in this case.,i think there is really a bug. I have exactly the same problem. When i send with my client a empty password; i receive on the server a null password and not an empty password. i think the problem is in org.apache.ws.security.message.token.UserNameToken : public String getPassword() { åÊåÊåÊåÊåÊåÊåÊåÊreturn nodeString(elementPassword); åÊåÊåÊåÊ} private String nodeString(Element e) { åÊåÊåÊåÊåÊåÊåÊåÊif (e != null) { åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊText node = getFirstNode(e); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊif (node != null) { åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊreturn node.getData(); åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊ} åÊåÊåÊåÊåÊåÊåÊåÊ} åÊåÊåÊåÊåÊåÊåÊåÊreturn null; åÊåÊåÊåÊ} the 'getFirstNode' return null so getpassword return null when an empty password is sended.,I'm going to mark this as won't-fix. I've added tests to WSS4J that verify that it's possible to send a blank password: <wsse:UsernameToken xmlns:wsu='http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd' wsu:Id='UsernameToken-15' xmlns:wsse='http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd'> åÊåÊåÊåÊ<wsse:Username>emptyuser</wsse:Username> åÊåÊåÊåÊ<wsse:Password Type='http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordText'/> </wsse:UsernameToken>,Can you supply a test-case? Colm.,We make a property map. and put WShandlerConstants.USER=testuser and then implement CallBackHandler as CallBackHandlerImpl where we set WSPasswordCallback.setPassword('') in handle method This CallBackHandlerImpl obj is again put into property map against WShandlerConstants.PW_CALLBACK_REF ACTION = USERNAME_TOKEN PASSWD_TYPE = PW_TEXT A WSS4jOutInterceptor from this property map and added in client out mode. wss4j reads the ('') value of password as null.,How are you setting the username and password? Colm.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
53769,x,,,,,,,åÊåÊåÊ[[ Old comment; sent by email on 16 Aug 2006 02:55:27 -0000 ]] Hi Kalpesh; åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊThanks for Your response. But the issue is that; I might be having 50 or even 500 multi select boxes in my application depending upon the records in my database. If I implement reset method; I dont want to iterate each check box and reset it to a default value. Is there any way to reset all the multi select boxes to a default value; in one shot. As per your suggestion; I need to get the request parameters and compare their values with those of the multi select box selected options and reset it accordingly? My question here is; multi-selectbox A(String[]) is having a default value null. Once data is loaded from database A's value is {x;y}. If user unselects both the x and y in browser for this multi-select box then it is still showing the {x;y} in my Action class when I pass the values back to database. what I'm expecting is a null value for A. Please let me know how to resolve this. Thanks and Regards; Sreedhar. http://issues.apache.org/struts/browse/STR-2927?page=comments#action_37962 ] the request only if the checkbox/select is selected. If you dont unselect it; you wont get the key=value in your request. method of the ActionForm; reset the value for the array i.e. retaining previous values if none is selected. ----------------------------------------------------------------------------- ----------------------------------- URL: http://issues.apache.org/struts/browse/STR-2927 Struts 1 Affects Versions: 1.2 Family is the HTML for my element. size='3' ><option value='1'>ABC</option> selected='selected'>DEF</option> <option value='6' selected='selected'>JKL</option> value='9'>MNO</option> selected='selected'>VWX</option> selected='selected'>YZA</option> <option value='1111'>FFFFF</option> <option value='209'>TQPN</option> </select> database. If I re-visit the application and deselect all the options selected in this box; it is not reflecting to show empty list. I'm using a string array in my form bean to hold these values. the String array should be empty or null. But it is still holding the previous set of values. any other action(selecting other values or deselecting one or more by keeping atleast one value selected) it works fine. automatically generated by JIRA. contact one of the administrators: http://issues.apache.org/struts/secure/Administrators.jspa information on JIRA; see: http://www.atlassian.com/software/jira,This is not a bug. This is how some browser behaves. You get key=value in the request only if the checkbox/select is selected. If you dont select or unselect it; you wont get the key=value in your request. In your reset method of the ActionForm; reset the value for the array to null. Thanks; -Kalpesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
45877,,,,,,,,Integrated in Thrift #426 (See https://builds.apache.org/job/Thrift/426/) THRIFT-1532/ THRIFT-1475 - fix record generation for erlang (Revision 1303663) Result = SUCCESS molinaro : http://svn.apache.org/viewvc/?view=rev&rev=1303663 Files : /thrift/trunk/compiler/cpp/src/generate/t_erl_generator.cc /thrift/trunk/lib/erl/Makefile.am /thrift/trunk/lib/erl/test/Thrift1475.thrift,I believe the fix for THRIFT-1532 also fixes this. I went a slightly different direction; so see THRIFT-1532 for details. Also please try out the patch and let me know if doesn't work in some cases.,I'm not clear how things are broken; do you have an example .thrift file and an example of how running it with the dialyzer fails? I tried  struct StructA {   1: string a;   2: binary b;   3: optional string c;   4: optional binary d;   5: required string e;   6: required binary f;   7: string g = 'foo'; }  Which generates  -record(structA; {a = undefined :: string();                   b = undefined :: string();                   c = undefined :: string();                   d = undefined :: string();                   e = undefined :: string();                   f = undefined :: string();                   g = 'foo' :: string()}).  Which arguably is not quite correct; but doesn't cause the dialyzer to fail with an error; so I'm not sure what the issue your patch fixes is. Can you include some information on how to reproduce and test this? Also; I'm wondering if the type signatures might cause issues in a server. Right not when a server gets a record which fields which are 'strings' the fields actually come in as binaries (assumably as an optimization as you might not need them as 'strings'; so dialyzer might complain about that; not sure).,Hey; anybody here?,Patch attached,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
43983,,,,,,,,Closed due to the release of Tiles 2.1.1,Added documentation for FreeMarker.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4694,,,,,,,,As Wing Yew said; the .xsb files are not compiled Java code; so we can't generate sources for them.,Note: While TypeSystemHolder.class is a java class file; the .xsb files are not. They are simply binary files. There is no 'source' for them.,OK; I ask a different way: is it worth it to request those sourcecodes generation. Or is it too complex or not possible?,Actually; no; there is no source code for those.,Would it be possible to get sourcecode for a) TypeSystemHolder b) .xsb 'classes'?,Johannes; The TypeSystemHolder class is still required at run-time. It contains information about the Schema<->Java relationship (name mappings etc) that is not available elsewhere. You need to make sure that you have the .jar containing this class and all the generated .xsb classes on the classpath at runtime (look for these classes in the directory that you specify as 'classgendir' in ant. This issue merely asked that this dependency be only a run-time one (rather than both compiletime and runtime) so that IDEs can show the generated classes without having to re-load their classpath every time the files get re-generated. And this seems to be fixed.,OK; generation and compilation of the generated sourcecode now seems to work. But usage fails: Exception in thread 'main' java.lang.ExceptionInInitializerError åÊåÊåÊåÊåÊåÊåÊåÊat net.eads.space.systemaccess.corba.corbaobject.CORBAObjectDocument$Factory.newInstance(CORBAObjectDocume åÊåÊåÊåÊåÊåÊåÊåÊat net.eads.space.systemaccess.corba.jacorb.XMLObjectInfo.createXML(XMLObjectInfo.java:73) åÊåÊåÊåÊåÊåÊåÊåÊat net.eads.space.systemaccess.app.IORParser.<init>(IORParser.java:39) åÊåÊåÊåÊåÊåÊåÊåÊat net.eads.space.systemaccess.app.IORParser.main(IORParser.java:52) Caused by: java.lang.RuntimeException: Cannot load SchemaTypeSystem. Unable to load class with name schemaorg_apac.corbaobject.TypeSystemHolder. Make sure the generated binary files are on the classpath. åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.xmlbeans.XmlBeans.typeSystemForClassLoader(XmlBeans.java:783) åÊåÊåÊåÊåÊåÊåÊåÊat net.eads.space.systemaccess.corba.corbaobject.CORBAObjectDocument.<clinit>(CORBAObjectDocument.java:19) åÊåÊåÊåÊåÊåÊåÊåÊ... 4 more Caused by: java.lang.ClassNotFoundException: schemaorg_apache_xmlbeans.system.net.eads.space.systemaccess.corba.co åÊåÊåÊåÊåÊåÊåÊåÊat java.net.URLClassLoader$1.run(URLClassLoader.java:200) åÊåÊåÊåÊåÊåÊåÊåÊat java.security.AccessController.doPrivileged(Native Method) åÊåÊåÊåÊåÊåÊåÊåÊat java.net.URLClassLoader.findClass(URLClassLoader.java:188) åÊåÊåÊåÊåÊåÊåÊåÊat java.lang.ClassLoader.loadClass(ClassLoader.java:306) åÊåÊåÊåÊåÊåÊåÊåÊat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:268) åÊåÊåÊåÊåÊåÊåÊåÊat java.lang.ClassLoader.loadClass(ClassLoader.java:251) åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.xmlbeans.XmlBeans.typeSystemForClassLoader(XmlBeans.java:769) åÊåÊåÊåÊåÊåÊåÊåÊ... 5 more Sourcecode created with 2.2.0 and ant task åÊåÊåÊåÊåÊåÊåÊåÊ<xmlbean schema='${schema.corbaobject}' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊsrcgendir='${src.corbaobject.dir}' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊsource='1.5' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊjavasource='1.5' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊfork='false' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊsrconly='true' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊverbose='false' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊtypesystemname='net.eads.space.systemaccess.corba.corbaobject'/>,My fault: I cannot reproduce after holidays. I guess I missed to replace somewhere in our build system the 2.0.0 version. Sorry for that!,Can you please give me more details; like maybe paste the generated file? I have looked at the code one more time and we have changed the line that used to output the static reference to TypeSystemHolder; definitely. I just can't understrand how this can happen... have you checked that you run at least XmlBeans 2.1.0 and you don't have any 'stale' source files in ant?,Reopened at the request of Johannes Stamminger commented on XMLBEANS-120: ---------------------------------------------- I just tried this thing ... and it still does not work for me: I created src files with ant task: åÊåÊåÊåÊåÊåÊåÊåÊ<xmlbean schema='${schema.corbaobject}' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊsrcgendir='${src.corbaobject.dir}' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊfork='false' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊsrconly='true' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊtypesystemname='net.eads.space.systemaccess.corba.corbaobject'/> And when compiling the sourcecode in another task this one still complains of TypeSystemHolder not existing: åÊåÊåÊåÊ[javac] Compiling 28 source files to /home/jstammi/Perforce2/systemaccess/main/build/classes/corbaobject åÊåÊåÊåÊ[javac] /home/jstammi/Perforce2/systemaccess/main/src/generated/corbaobject/net/eads/space/systemaccess/corba/corbaobject/Address.java:18: package schemaorg_apache_xmlbeans.system.net.eads.space.systemaccess.corba.corbaobject.TypeSystemHolder does not exist Please re-open this issue (I cannot do so; or do you prefer a new one?),BTW: it is another schema but the attached one. On interest I might add that one; too.,I just tried this thing ... and it still does not work for me: I created src files with ant task: åÊåÊåÊåÊåÊåÊåÊåÊ<xmlbean schema='${schema.corbaobject}' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊsrcgendir='${src.corbaobject.dir}' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊfork='false' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊsrconly='true' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊtypesystemname='net.eads.space.systemaccess.corba.corbaobject'/> And when compiling the sourcecode in another task this one still complains of TypeSystemHolder not existing: åÊåÊåÊåÊ[javac] Compiling 28 source files to /home/jstammi/Perforce2/systemaccess/main/build/classes/corbaobject åÊåÊåÊåÊ[javac] /home/jstammi/Perforce2/systemaccess/main/src/generated/corbaobject/net/eads/space/systemaccess/corba/corbaobject/Address.java:18: package schemaorg_apache_xmlbeans.system.net.eads.space.systemaccess.corba.corbaobject.TypeSystemHolder does not exist Please re-open this issue (I cannot do so; or do you prefer a new one?),Fixed with checkin 220181. Now refer to TypeSystemHolder via a reflection API instead of directly.,If anyone's intersted; I managed to make Eclipse happy without the TypeSystemHolder source by adding the output directory (where the TypeSystemHolder.class files get generated) to the project 'Libraries' in the Java Build Path for the project. I also made my maven build work by manually copying the TypeSystemHolder.class files up to the target directory in a java:compile pregoal: <preGoal name='java:compile'> <attainGoal name='generate-xmlbeans'/> <ant:copy todir='${maven.build.dest}'> <ant:fileset dir='${xmlbeans.output.dir}'> <include name='**/*.class'/> </ant:fileset> </ant:copy> </preGoal>,I just retested with 2.0 final version: definitely the sourcecode being generated is not compilable as it misses the TypeSystemHolder.java _SOURCECODE_. åÊ åÊNot with 2.0-beta1; nor with 2.0 final. åÊNot with '-scronly=true' nor without!! åÊ åÊThis is definitely no IDE problem (btw: I'm using IntelliJ; not Eclipse). åÊ åÊNote: the xmlbeans-generated .jar contains a TypeSystemHolder.class file. åÊ åÊThe annoying thing is: when creating the .jar with xmlbeans itself (only way working so far) I do not have full control about javac options used. åÊ åÊAnd IMHO this is no minor bug when creating not compilable sourcecode; please re-consider this.,I've just tried upgrading to 2.0; and I'm getting the same problem. I'm compiling with -srconly; and I get a TypeSystemHolder.class generated; but no TypeSystemHolder.java! This is not just an Eclipse issue - the TypeSystemHolder.java files seems to be simply not generated.,With the actual 2.0 release I get the same effect even without -srconly! No TypeSystemHolder.java is generated; which causes IDEs like Eclipse to complain. You can reproduce it simply by compiling one of the sample schemas: åÊcd xmlbeans-2.0.0/schemas åÊåÊ../bin/scomp -src src -d out easypo.xsd åÊåÊfind src -name '*TypeSystemHolder*.java' ... and nothing is found!,Johannes; I have no problems building that Schema file. I have become convinced that this is an Eclipse-only issue because it can't pick up dependencies from a different directory than the source. I am going to fix this by removing that compile-time dependency; but in order to do this I need some APIs that don't currently exist; so I was going to wait on it a bit.,XTCE 1.0 OMG specification (http://www.omg.org/cgi-bin/apps/do_doc?dtc/03-09-02.pdf) 2.0.1-beta1 does not create valid sourcecode for,Without -srconly there is created a .jar but the sourcecode written to disk is cannot be the one having been compiled as the generated interfaces contain references to not existing classes like ...schema.system.s88336473178149A1091FEBD8E40E9E6C.TypeSystemHolder that do not exist - and therefore are not compilable (though the corresponding .class file is found within the generated .jar). I'll attach the schema (XTCE OMG spec.) I observe the problems with (1.0.4 generates working sourcecode).,,,,,,,,,,,,,,,,,,
57161,,,,,,,,The tests have been added; so closing. Travis; please keep an eye on the results of the tests in our nightly builds and post patches for any build issues. We also need to open a new issue for each test that fails at runtime as a result of thread safety bug(s) in the library; in addition to those for any other failures.,Task assigned to Travis.,Attached a copy of the thread safety page for the record.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
18037,,,,,,,,r499213. The API changed as described in previous comments; so that WSDLReader.readWSDL methods now return Description instead of DescriptionElement. This change included fixing some bugs in OMWSDLReader.parseSchemaImport that had not surfaced previously because the OM implementation and test cases were only ever using DescriptionElement; but not Description.,I would like to implement this fix as soon as possible - I propose Thursday 18th January. Because it involves a change to the Woden API; I will try to coordinate this change with Axis2 and WSO2 (who are currently doing the WSDL 2.0 interop testing). The last Woden snapshot jar used by Axis2 is dated December; but I want to find out if they are doing daily Axis2 builds off Woden trunk and if so; get them to make the change at the same time. WSO2 will need to change their call to the readWSDL method. The required code change involves receiving a Description back from the readWSDL method; rather than receiving a DescriptionElement and having to call its toComponent() method to get the Description. The rationale is in the previous comments in this JIRA. So; for example: DescriptionElement descElem = wsdlReader.readWSDL('someURL'); Description descComp = descElem.toComponent(); becomes: Description descComp = wsdlReader.readWSDL('someURL'); If the WSDL infoset needs to be accessed via Woden's Element API; then just call the toElement() method on the Description component; or on any other component. E.g.: DescriptionElement descElem = descComp.toElement(); InterfaceElement interfacElem = InterfacComp.toElement();,Extract from Minutes of weekly Woden call Tuesday 9th January 2007: Discussed API changes to WSDLReader in WODEN-119 and WODEN-120 WODEN-119 is about passing wsdl uri to readWSDL methods as java.net.URI instead of java.lang.String. Arthur: could we just add new methods that take java.net.URI and leave the methods with String args? John: an original design goal was type safety in the API; so allowing only URI args instead of String args means the user must ensure that the wsdl uri argument is 'type safe' (i.e. in the correct format to create a java.net.URI). It also achieves consistency across the API as everywhere else java.net.URI is used to represent uris. The issue is not specifically about avoiding the need to handle MalformedURLException within the reader. Arthur: how do we handle API change without breaking existing users? John: Add new readWSDL methods with URI args; deprecate existing methods for M7 then remove them in the release that follows M7. Arthur: agreed. Graham: agreed. Jeremy has already +1 via the mailing list. WODEN-120 is about the readWSDL methods returning Description instead of DescriptionElement. We discussed the rationale as explained in the JIRA and agreed with this proposal (John; Arthur; Graham). Jeremy has already +1 via the mailing list. Noted that as deprecation of existing methods won't work (i.e. it's just the return type being changed); we will need to coordinate with Axis2 folks on their building of a Woden SNAPSHOT jar for inclusion in the Axis2 build. [action] John to coordinate this change with Axis2 / WSO2,+1 to this - like you say we need to ensure Axis2 change their usage of readWSDL as soon as we make this change. In fact the change to Axis2 needs to happen at the moment the Woden snapshot [1] and [2] is updated (which has been done by Dims in the past) ! Tricky to co-ordinate. [1] http://ws.zones.apache.org/repository/incubator-woden/jars/ [2] http://people.apache.org/repo/m1-snapshot-repository/incubator-woden/jars/,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
73819,,,,,,,,looks good. Thanks!,The attached patch resolves the issue for me. Please take a look.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6555,,,,,,,,Reporter took back the issue.,User retracted claim.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
64300,,,,,,,,closing.,Thanks Thorsten; I've been meaning to write a step-by-step guide on how to get up and running with your own data.,done: http://wiki.apache.org/solr/mySolr @Antonio; thx for the feedback; I added your comment into the wiki page.,Perhaps this should be a Wiki page to make it easier to change / collaborate?,Wow! you must be reading my mind I can contribute with questions As a newbie non-java user from an enterprise prospective! I am your idea target Having said that I like to know about the following: 1. The schema.xml and solrconfig.xml are in parts very well explained. But in some areas like as an example .. <indexDefaults> and other places there are no explanation. It would be nice to get more info there. Specifically for example if increase <mergeFactor> to 1000 what will happen? what are the highest value for each properties? what is for example a 'safe value'. 2. It would be nice to create a deployment scenarios i.e a single server install with XXX CPU and YYY memory just running Solr with AAA thousand docs how should your config look like and why? and you can get about xxx Query/Sec or something.. 3. It would be nice to have a multi server deployment with some server spec and then how should the deployment be. 4. It would also be nice to have more info regarding stopwords synonoms etc. usage and facet etc.. I know that all of the above are case by case cos configuration by default means case by case. But what I want to propose is a 'Guidelines or Best Practice' based on your production implementation/deployment you have done with Cocoon. It would be nice to have some real world stories. I think you should do like the subversion book! - A Solr open source book!,Initial version,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46068,,,,,,,,Integrated in Thrift #230 (See https://builds.apache.org/job/Thrift/230/) THRIFT-1284. cpp: fix processor inheritance Don't make processors that have a proper parent class also inherit from TProcessor. Patch: Adam Simpkins bryanduxbury : http://svn.apache.org/viewvc/?view=rev&rev=1160933 Files : /thrift/trunk/compiler/cpp/src/generate/t_cpp_generator.cc,I just committed this.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
20296,,,,,,,,Integrated in Apache Wicket 1.4.x #436 (See [https://hudson.apache.org/hudson/job/Apache%20Wicket%201.4.x/436/]) åÊåÊåÊåÊWICKET-3413 FLAG_INHERITABLE_MODEL and default model change reset 'inherited model' flag if model changed and a new one is not IComponentInheritedModel,Improved with r1070211 (1.4.x) and r1070210 (trunk).,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
485,,,,,,,,+1 overall. Here are the results of testing the latest attachment http://issues.apache.org/jira/secure/attachment/12508207/ZOOKEEPER-1263.patch against trunk revision 1214571. +1 @author. The patch does not contain any @author tags. +1 tests included. The patch appears to include 6 new or modified tests. +1 javadoc. The javadoc tool did not generate any warning messages. +1 javac. The applied patch does not increase the total number of javac compiler warnings. +1 findbugs. The patch does not introduce any new Findbugs (version 1.3.9) warnings. +1 release audit. The applied patch does not increase the total number of release audit warnings. +1 core tests. The patch passed core unit tests. +1 contrib tests. The patch passed contrib unit tests. Test results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/844//testReport/ Findbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/844//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html Console output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/844//console This message is automatically generated.,Hi Pat; Thanks for the review and comments. I have attached latest patch with test cases. In the patch I couldn't completely remove the conditional logic from ZooKeeperServer. I have seen the testcases are directly instantiating the 'ZooKeeperServer' and starting the server. In this case the execution flow is not going through the ServerConfig/QuorumPeerConfig and will not be applying the defaulting logic[the timeout values will remain as -1]. So I retain the logic inside ZooKeeperServer.,Rakesh - in order to simplify the patch file conflict management I rolled these two issues into one patch. Note however - you have not updated the code in ServerConfig; so there is still an issue for the standalone case. Please update the patch and add test(s) for this. thanks.,This is the merged patch from ZOOKEEPER-1213 and ZOOKEEPER-1227; no other changes.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2685,,,,,,,,Integrated in Hadoop-Mapreduce-trunk #1386 (See https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1386/) YARN-209. Fix CapacityScheduler to trigger application-activation when the cluster capacity changes. Contributed by Zhijie Shen. (Revision 1461773) Result = SUCCESS vinodkv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1461773 Files : /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRM.java /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestLeafQueue.java,Integrated in Hadoop-Hdfs-trunk #1358 (See https://builds.apache.org/job/Hadoop-Hdfs-trunk/1358/) YARN-209. Fix CapacityScheduler to trigger application-activation when the cluster capacity changes. Contributed by Zhijie Shen. (Revision 1461773) Result = FAILURE vinodkv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1461773 Files : /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRM.java /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestLeafQueue.java,Integrated in Hadoop-Yarn-trunk #169 (See https://builds.apache.org/job/Hadoop-Yarn-trunk/169/) YARN-209. Fix CapacityScheduler to trigger application-activation when the cluster capacity changes. Contributed by Zhijie Shen. (Revision 1461773) Result = FAILURE vinodkv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1461773 Files : /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRM.java /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestLeafQueue.java,Integrated in Hadoop-trunk-Commit #3537 (See https://builds.apache.org/job/Hadoop-trunk-Commit/3537/) YARN-209. Fix CapacityScheduler to trigger application-activation when the cluster capacity changes. Contributed by Zhijie Shen. (Revision 1461773) Result = SUCCESS vinodkv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1461773 Files : /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRM.java /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestLeafQueue.java,I just committed this to trunk and branch-2. Thanks Zhijie!,So; on a single-node cluster the patch works correctly. Cool; I am checking this in.,@Vinod; I tested the patch with the following logic: 1. Launch RM 2. Submit App 3. Check it is pending (Yes) 4. Launch NM 5. Check it is active (Yes) So; on a single-node cluster the patch works correctly.,The new version of the test makes more sense. Looks good.,So; in other words; if an application gets submitted to the RM before any NM registered; the application will be stuck in pending state. Right? Or you can just test this manually. Either of the above is fine by me.,Patch looks good; can you test this manually too? Something like this: Starting one NM with very little resources first and another with sufficient resources later and an app which can only run on the second NM.,+1 overall. Here are the results of testing the latest attachment http://issues.apache.org/jira/secure/attachment/12575660/YARN-209.4.patch against trunk revision . +1 @author. The patch does not contain any @author tags. +1 tests included. The patch appears to include 2 new or modified test files. +1 javac. The applied patch does not increase the total number of javac compiler warnings. +1 javadoc. The javadoc tool did not generate any warning messages. +1 eclipse:eclipse. The patch built with eclipse:eclipse. +1 findbugs. The patch does not introduce any new Findbugs (version 1.3.9) warnings. +1 release audit. The applied patch does not increase the total number of release audit warnings. +1 core tests. The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager. +1 contrib tests. The patch passed contrib unit tests. Test results: https://builds.apache.org/job/PreCommit-YARN-Build/615//testReport/ Console output: https://builds.apache.org/job/PreCommit-YARN-Build/615//console This message is automatically generated.,The log statement is removed and testActivatingPendingApplication is moved to TestRM and enhanced by checking the status before NM is added. @Bikas; I agree TestLeafQueue only is enough to verify the bug; but I think the test case that you provided before is valuable. Therefore; I included and updated it as a showing case of activating pending applications by adding more nodemanagers.,Patch looks good overall. I dont quite see what testActivatingPendingApplication() is buying us in its current form. If the leaf queue test fails before the fix and passes after it; then it should be enough IMO.,Reviewed the patch; looks fine; few minor comments I have: LeafQueue: The log statement isn't useful beyond debugging this issue; can be removed. testActivatingPendingApplication doesn't seem to belong to TestRMRestart; should move it to somewhere else. TestRM perhaps?,-1 overall. Here are the results of testing the latest attachment http://issues.apache.org/jira/secure/attachment/12575556/YARN-209.3.patch against trunk revision . +1 @author. The patch does not contain any @author tags. +1 tests included. The patch appears to include 2 new or modified test files. +1 javac. The applied patch does not increase the total number of javac compiler warnings. +1 javadoc. The javadoc tool did not generate any warning messages. -1 eclipse:eclipse. The patch failed to build with eclipse:eclipse. +1 findbugs. The patch does not introduce any new Findbugs (version 1.3.9) warnings. +1 release audit. The applied patch does not increase the total number of release audit warnings. +1 core tests. The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager. +1 contrib tests. The patch passed contrib unit tests. Test results: https://builds.apache.org/job/PreCommit-YARN-Build/605//testReport/ Console output: https://builds.apache.org/job/PreCommit-YARN-Build/605//console This message is automatically generated.,Extract the fixing code specifically for this issue from YARN-474; to make this issue unblocked. @Bikas' end-to-end test case is retained but simplified; because it is good example to demonstrate the problem described here.,@Hitesh; this is because in this ticket; there's no fix code. The failure is expected here. When YARN-474 is fixed; the failure should be gone.,@Zhijie; is the test failure related to your patch?,-1 overall. Here are the results of testing the latest attachment http://issues.apache.org/jira/secure/attachment/12574896/YARN-209.2.patch against trunk revision . +1 @author. The patch does not contain any @author tags. +1 tests included. The patch appears to include 1 new or modified test files. +1 tests included appear to have a timeout. +1 javac. The applied patch does not increase the total number of javac compiler warnings. +1 javadoc. The javadoc tool did not generate any warning messages. -1 eclipse:eclipse. The patch failed to build with eclipse:eclipse. +1 findbugs. The patch does not introduce any new Findbugs (version 1.3.9) warnings. +1 release audit. The applied patch does not increase the total number of release audit warnings. -1 core tests. The patch failed these unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager: org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart +1 contrib tests. The patch passed contrib unit tests. Test results: https://builds.apache.org/job/PreCommit-YARN-Build/564//testReport/ Console output: https://builds.apache.org/job/PreCommit-YARN-Build/564//console This message is automatically generated.,Given YARN-474 is fixed; the patch can be used to test the scenario that the applications are submitted before NM are registered.,Whenever more hardware is added to the cluster; LeafQueue#updateClusterResource will be triggered. The problem can be fixed by the patch for YARN-474 as well.,Right. Thats what the test in the attached patch does. But its a functional test.,Haven't looked at the code yet; trying to understand the scenario. So; in other words; if an application gets submitted to the RM before any NM registered; the application will be stuck in pending state. Right? If so; we can write a test like that.,-1 overall. Here are the results of testing the latest attachment http://issues.apache.org/jira/secure/attachment/12552973/YARN-209.1.patch against trunk revision . +1 @author. The patch does not contain any @author tags. -1 tests included. The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. +1 javac. The applied patch does not increase the total number of javac compiler warnings. +1 javadoc. The javadoc tool did not generate any warning messages. +1 eclipse:eclipse. The patch built with eclipse:eclipse. +1 findbugs. The patch does not introduce any new Findbugs (version 1.3.9) warnings. +1 release audit. The applied patch does not increase the total number of release audit warnings. +1 core tests. The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager. +1 contrib tests. The patch passed contrib unit tests. Test results: https://builds.apache.org/job/PreCommit-YARN-Build/176//testReport/ Console output: https://builds.apache.org/job/PreCommit-YARN-Build/176//console This message is automatically generated.,Attaching a fix for the issue. Also attaching a test that times out without this fix and passes with it. There might be a simpler way to test this.,,,,,,,,,,,,,
81230,,,,,,,,The above commits were approved by Justin on the dev list; and have now been merged to the 0.18 branch.,0001-QPID-3999-Java-Broker-Get-the-user-name-from-HttpSer.patch (9th July) and 0001-QPID-3998-QPID-3999-System-tests-for-Rest-API-small-.patch (10 July) applied to trunk; after the branch for 0.18 was created. Commits were http://svn.apache.org/viewvc?view=revision&revision=1360120 and http://svn.apache.org/viewvc?view=revision&revision=1360121 respectively.,Robbie; I uploaded a newer version of a patch with REST API tests. Could you please review and commit it?,Attached a patch with changes in SaslServlet allowing to get username from HttpServletRequest#getRemoteUser(),Attached patch with system tests for REST API,Added patch changing management web layer to allow execution of DELETE and PUT methods functionality with POST requests. Change management UI to use POST requests for resource deletion.,Attached a patch adding RequestHeaderPreAuthenticatedCredentialsFilter into broker-web to allow set principal/subject from the specified request header. This filter can be used to set request credentials with Single Sign-On systems like Siteminder SS0. Possibly; the better place for the filter could be inside of management plugin; so; it could be used with stand-alone brokers. However; I am not sure about it as the filter adds the potential security hole into the web console. That's why this functionality is implemented as a filter instead of adding the code directly into AbstractServlet.,Attached a patch adding temporary authorization checks for message copy/delete/move in management web console,Attached a patch changing web console to use anonymous subject for non-authenticated requests,Attached a patch with a special module to build qpid war to deploy and run Qpid in servlet container.,Attached a patch adding default constructors to management servlets and making all links in web UI relative to the web application context,,,,,,,,,,,,,,,,,,,,,,,,,,,
23492,,,,,,,,behvaiors:ajax calls is not always 1:1. some behaviors are purely clientside. also; this comes up often so we should offer the devs a choice to do this even if it can have unwanted sideeffects.,Here is a behavior based on JQuery.bind() that allows that. I created it to show how to use JQuery's mouseenter/mouseleave events but it can be used for this case too. I believe that assigning several behaviors on the same event is bad practice because this will make several Ajax calls to the server side. Better do one call and then at the server side delegate to all interested parties.,I just ran into this problem; and do not understand the last comment. Is this issue solved? Would it be possible with some hints for how developer should attach multiple behaviours to the same event?,I think we did allow users to delegate AJAX calls to their behavior as they want with the new event dispatcher API.,I've been trying to implement something like IMergeableBehavior; but because of so many specific properties each behavior can provide; I think it won't be a good idea. Maybe other things must be considered to solve this: 1) Defining an IEventBehavior - which would serve for Javascript events *only*; like onChange; etc... interface IEventBehavior extends IBehavior; IHeaderContributor { åÊåÊåÊåÊpublic String getEvent(); } 2) Defining a class called AggregatedEventBehavior - which would... aggregate IEventBehaviors of the same event type class AggregatedEventBehavior { åÊåÊåÊåÊpublic AggregatedEventBehavior(IEventBehavior... events) { åÊåÊåÊåÊåÊåÊåÊåÊ... // check for event type consistency åÊåÊåÊåÊ} åÊåÊåÊåÊ.. // other methos like render; onComponentTag; etc; like in IBehavior } 3) Only one ajax call to this aggregated behavior (avoiding multiple Ajax calls) 4) If developer choses to add more than one event of the same type to a component; the framework should throw an exception. If the intention is to actually attach more than one behavior to the same event; the developer will have to use an IAggregatedEventBehavior 5) The need of a new method: Component.add(AggregatedEventBehavior) 6) Somehow; avoid the use of AttributeModifiers that refers to Javascript events Cheers; Bruno,moving to 1.4.0 This won't make it for 1.3,Assigned version (beta 4),I don't think this is going to make 1.3.0. Unscheduling for the time being.,The situation would already be improved a lot if the javadoc would make it clear that it is not possible to add multiple behaviors to the same event. Yet another option is to provide an aggregation behavior. Something that would allow you to merge 2 behaviors into 1. I am not sure how this could work. I am not familiar with Wicket.Event (a 1.3 feature?).,I don't really like this. We could use Wicket.Event for attaching events on to component instead of the attributes; but this would result in multiple ajax calls. I doubt that this is desirable.,i dont like what you propose; but i wont -1 it either; so go ahead.,i would say just call all ajax events that are on the same event. Why not that can be explained perfectly. Ajax works but if you have pure client side scripts it could fail (it could! because we still have already the ability to merge the behaviors!; so that you can prepend or append!),there is really no good way to do this that will work across the board. if we do it for ajax then people will want it for other things as well one compromise i can think of is to do this: iterate over behaviors that implement the invoked listener interface and call equals on them - if they are equal then invoke the listener on them as well is this a good compromise?,This has been discussed on the user list as well if I'm correctly. I thought the consensus was not to do anything about it; though error reporting could be improved?,,,,,,,,,,,,,,,,,,,,,,,,
8098,,,,,,,,*** Bug 9236 has been marked as a duplicate of this bug. ***,David; I believe this bug is due to broken implementations of upperCase and lowerCase in the Macintosh transcoder routines. I've checked in revised copies of these; and am listing the diffs below. Could you apply the diffs to your version and confirm that this fixes your problem? Then update this bug report? Thanks! åÊåÊdiff -u -r1.2 -r1.3 åÊåÊ--- MacOSUnicodeConverter.cpp 9 Apr 2002 15:44:00 -0000 1.2 åÊåÊ+++ MacOSUnicodeConverter.cpp 19 May 2002 22:57:56 -0000 1.3 åÊåÊ@@ -55;7 +55;7 @@ åÊåÊåÊåÊ*/ åÊåÊåÊ åÊåÊåÊ/* åÊåÊ- * $Id: MacOSUnicodeConverter.cpp;v 1.2 2002/04/09 15:44:00 knoaman Exp $ åÊåÊ+ * $Id: MacOSUnicodeConverter.cpp;v 1.3 2002/05/19 22:57:56 jberry Exp $ åÊåÊåÊåÊ*/ åÊåÊåÊ åÊåÊåÊ åÊåÊ@@ -468;20 +468;16 @@ åÊåÊåÊ#if defined(XML_METROWERKS) åÊåÊåÊ // Use this if there's a reasonable c library available. åÊåÊåÊ // Metrowerks does this reasonably åÊåÊ- wchar_t * p = (wchar_t*) toUpperCase; åÊåÊåÊ wchar_t c; åÊåÊ- åÊåÊ- while ((c = *p) != 0) åÊåÊ+ for (XMLCh* p = (XMLCh*)toUpperCase; ((c = *p) != 0); ) åÊåÊåÊ *p++ = std::towupper(c); åÊåÊåÊ#elif defined(XML_MACOSX) || true åÊåÊåÊ // This might work; assuming we're on an ascii compiler. åÊåÊåÊ // We'll use this under ProjectBuilder for now. åÊåÊåÊ // Note that this only handles the ascii portion of the åÊåÊåÊ // string; leaving all other characters in original case. åÊåÊ- wchar_t * p = (wchar_t*)toUpperCase; åÊåÊ- wchar_t c; åÊåÊ- åÊåÊ- while ((c = *p) != 0) åÊåÊ+ XMLCh c; åÊåÊ+ for (XMLCh* p = (XMLCh*)toUpperCase; ((c = *p) != 0); ) åÊåÊåÊ { åÊåÊåÊ if (c >= 'a' && c <= 'z') åÊåÊåÊ c += 'A' - 'a'; åÊåÊ@@ -492;26 +488;23 @@ åÊåÊåÊ#endif åÊåÊåÊ} åÊåÊåÊ åÊåÊ+ åÊåÊåÊvoid MacOSUnicodeConverter::lowerCase(XMLCh* const toLowerCase) const åÊåÊåÊ{ åÊåÊåÊ // å´å´å´ TODO: Support CFString for this conversion åÊåÊåÊ#if defined(XML_METROWERKS) åÊåÊåÊ // Use this if there's a reasonable c library available. åÊåÊåÊ // Metrowerks does this reasonably åÊåÊ- wchar_t * p = (wchar_t*) toLowerCase; åÊåÊåÊ wchar_t c; åÊåÊ- åÊåÊ- while ((c = *p) != 0) åÊåÊ+ for (XMLCh* p = (XMLCh*)toLowerCase; ((c = *p) != 0); ) åÊåÊåÊ *p++ = std::towlower(c); åÊåÊåÊ#elif defined(XML_MACOSX) || true åÊåÊåÊ // This might work; assuming we're on an ascii compiler. åÊåÊåÊ // We'll use this under ProjectBuilder for now. åÊåÊåÊ // Note that this only handles the ascii portion of the åÊåÊåÊ // string; leaving all other characters in original case. åÊåÊ- wchar_t * p = (wchar_t*)toLowerCase; åÊåÊ- wchar_t c; åÊåÊ- åÊåÊ- while ((c = *p) != 0) åÊåÊ+ XMLCh c; åÊåÊ+ for (XMLCh* p = (XMLCh*)toLowerCase; ((c = *p) != 0); ) åÊåÊåÊ { åÊåÊåÊ if (c >= 'A' && c <= 'Z') åÊåÊåÊ c += 'a' - 'A';,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
18121,,,,,,,,Resolved with no further action; so closed.,Chathura; we'd like to close this JIRA if it's done. As the original reporter can you please close this or comment on any further issues.,I guess I should have marked this 'resolved'; instead of 'closed' (pending verification by the folks who opened the JIRAs).,I guess I should have marked this 'resolved'; instead of 'closed' (pending verification by the folks who opened the JIRAs).,The org.apache.woden.tool.converter.Convert class has been updated to ensure that the 'xsd' namespace declaration is not dropped from the newly generated <description> element; so long as it existed on the <definition> element being converted.,Converted faulty WSDL 2.0 document,WSDL 1.1 document used for the conversion,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
63697,x,x,,,,,,Ah; fantastic - that works very well. Thanks!,I think that is possible with UpdateRequestProcessor. Instead of adding a custom tag to the XML; add them as normal fields (metadata1; 2; ...) which will be added to SolrInputDocument. In the processAdd method you will get access to the value by using SolrInputDocument#getValue(String field). Use them in whatever way you want; remove them from SolrInputDocument and add the final processed text to a new field using SolrInputDocument#addField and finally pass on for indexing by calling super.processAdd(SolrInputDocument).,I don't think the UpdateRequestProcessor will let me do what I want. Let me describe what we're trying to do - maybe I can do it easily without cloning XmlUpdateRequestHandler. We want to add additional data to the XML <doc> tag; a <RichContent> tag which has a couple attributes; and whose contents are textual data. We want to translate this data into different text and then attach it to one of the lucene fields in the SolrInputDocument; which can then be processed normally. What I want; I think; is to be able to override the readDoc() method in XmlUpdateRequestHandler. Does that make sense? I could easily be missing a simple solution; as I'm new to Solr.,this is an improvement; not a bug; so even if someone provides a patch we're not going to try and squeeze it in for 1.3.,We also had to do this to write a requesthandler that maintains original dates on overwrite adds. But then I found this: http://wiki.apache.org/solr/UpdateRequestProcessor - does the updateRequestProcessor solve your problem?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
51837,x,,,,,,,The change you want would be nice; but is simply not possible. The form data is either available or not; if there's a file upload exception; then none of the data submitted in the form is available to Tapestry. This is a function of the multipart/form encoding type and the underlying Jakarta FileUpload library.,After working with the solution for this bug; it appears to be inconvenient. The uploadException appears to get thrown before the values from the form are bound to the page instance. So if I have the following code to handle the uploadException: public Object onUploadException(Throwable cause) { myForm.recordError('Files may not be larger than 1.5 MB. Please choose a smaller file.'); return this; } ... then the page is completely empty when the user is returned to the page. Most (all?) people would treat this as a validation error when the file size is exceeded. I'm hoping that we end up with something like this: <input t:type='upload' t:id='file' validate='required' maxsize='1500000'/> And a default error message similar to the one above would be returned to the user. Feasible?,Final solution is to notify the containing page with an uploadException event; let it decide what to do.,The only solution I can see for this is to add an 'incomplete' flag to the UploadedFile interface. I believe that once we hit this exception; we can't count on getting any other uploaded files; or potentially; any of the other query parameters. Possibly the correct course is to identify the page; and trigger a specific event to indicate the failure.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6447,,,,,,,,See bug 5694 for the DOMException problem.,It looks like the performance improvement in Xerces 2.0.0B4 might actually be a bug. Most of the time in Xerces 1.4.4 (or in Xerces 2.0.0B3) is spent in appending chunks of text. With the large number of entity references; those parsers (in the non-deferred DOM case) receive a chunk of text between entity references; then a predefined entity reference; then a chunk of text between references; etc. Each of those chunks is appended onto a single TEXT_NODE. In Xerces 2.0.0B4 the AbstractDOMParser is creating an ENTITY_REFERENCE_NODE for each reference to a predefined entity and TEXT_NODEs for the chunks of text in between. This eliminates all of the overhead of appending. However; that behaviour is not permitted by the DOM API Recommendation[1]. As soon as we fix that problem; we'll be able to reproduce the performance problem in Xerces-2; so I'll update the product and version; and reopen the bug. I'm not sure whether we'll be able to do anything about it; though. I was also able to reproduce the DOMException with j_caesar.xml that you mentioned; I'll open a separate bug for that. [1]: http://www.w3.org/TR/2000/REC-DOM-Level-2-Core- 20001113/introduction.html#ID-E7C30824,I can't reproduce the DOMException - given the fact that you only parse document and don't make any DOM modifications; this error does not make much sense.. (I've run the testcase using the test program you've provided and dom.Counter sample). I am not sure we can fix the performance bug in Xerces 1.4.4 - all Xerces developers now work on Xerces2. If you have any patches for Xerces 1; you are welcome to submit those. Thank you!,- I did not use deferred DOM. Using Xerces 1.1.3 - The j_caeasar_escaped.xml document takes 82528ms to parse - The j_caesar.xml document only takes 611ms to parse. Using Xerces2 beta4: - The j_caeasar_escaped.xml takes only 420 ms to parse; so the problem seems to be solved in this version :) - The j_caesar.xml document causes the following exception to be thrown: åÊåÊåÊåÊåÊ[java] org.w3c.dom.DOMException: DOM001 Modification not allowed åÊåÊåÊåÊåÊ[java] at org.apache.xerces.parsers.DOMParser.parse(DOMParser.java:190),Created an attachment (id=973) Zip file with test case (java source and XML docs),1. Do you use deferred DOM? 2. Can you try to run it against Xerces2 beta4 (or the latest code in CVS?) 3. Can you provide a sample file? Thank you.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
42670,,,,,,,,add separate handling for webkit browser,Hello Pascal; please add the patch with 'Grant license to ASF for inclusion in ASF works (as per the Apache License å¤5)' checked Regards Bernd,Add separate handling for webkit in make OveraySemitransparent function,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
17895,,,,,,,,Verified. I added the info to the RELEASE_NOTES file.,I'm closing this as we aren't planning to implement the only remaining issue. I propose we just add an item to the release notes that we're 99% conformant apart from child iframe support.,WOOKIE-308 is the only remaining issue affecting conformance; we aren't going to fix that for 0.9.2 so I'll re-open this issue and punt to 0.10.0 to fix along with WOOKIE-308,OK; I've checked again and it looks like the WebStorage spec changed or I misinterpreted it: while clear() must remove the entries; getItem() must return Null rather than undefined when requesting a non-existing item: widget.preferences.clear(); // get rid of everything widget.preferences.setItem('foo'; null); // set 'foo' to equal null widget.preferences.getItem('foo'); // tuple exists and is set to null; return null widget.preferences.getItem('completely_undefined_bar'); tuple doesn't exist; return null I've updated Wookie and we can now pass test 'at'. We don't pass 'au' but I'll raise another issue for that.,(commits in the w3c test cases repo; not wookie!),OK; looks like my commits fixing the two tests were reverted; so no wonder at and au fail now. I'll follow that up and see if I can resolve it.,Hmm; I updated the 'at' and 'au' test cases at W3C to check for typeof==='undefined' rather than Null so they shouldn't be failing now...,I have just re-run all these tests on Windows 7; in the following environments... IE 9 Firefox 9.0.1 Opera 11.10 Google Chrome 16.0.912.75 m and the results were the same in each case... Test 'return-empty-strings' fails because widget.id returns wookies internal generated Id (expected behavior for wookie) Test 'setItem-fires-event' fails (storage event from iframe) Test 'removeItem-fires-event' fails (storage event from iframe) Test 'clearItem-fires-event' fails (storage event from iframe) Test 'Test at' fails because widget expects window.widget.preferences.getItem('deletable') to be null. it is actually 'undefined' Test 'au' fails because widget expects prefs.getItem('test1') to be null. it is actually 'undefined' It looks to me that this is in keeping with Scotts results; ok to verifiy now?,So here's the summary: #1 Fixed #2 Not a bug - I think its reasonable we pass on generated ids in the metadata #3 I don't think its really relevant as its an edge case. If anyone asks for sending storage events to child frames we can do it; but its not exactly urgent. #4 This is a test error - I've filed a bug with w3c ... so I'm closing the issue,I've fixed the engine.js error - this was caused by trying to delete prefs that throw a NO_MODIFICATION_ALLOWED_ERR . However the test case itself seems to be wrong as it expects cleared prefs to be === Null rather than typeof 'undefined'.,Current test results (0.9.2 rev 1199782) show mostly green; the following red: 1 Test preferences_attrreadonly failed because preferences in window.widget is not read-only 2 Test return-emtpy-strings failed because one of the attributes returned an incorrect value 3 Test did not run or storage event was never fired. 4 Test au failed because the values of the stored preferences were not what they should have been. #1 is because the preferences attribute itself is not read-only #2 is because we always generate an ID for a widget; even if it doesn't have one by default. #3 is a bit of a strange one to implement I'm not sure what causes the problem with #4; but it throws an engine.js error.,,,,,,,,,,,,,,,,,,,,,,,,,,,
60790,,,,,,,,build.xml cleanup... Committed revision 1368286. - trunk Committed revision 1368287. - 4x,DIH... Committed revision 1368190. - trunk Committed revision 1368191. - 4x ...this should be done now; but i want to sanity check all the packaging before resolving.,contrib/uima and contrib/extraction ... Committed revision 1367384. - trunk Committed revision 1367385. - 4x,Finished these... solr/contrib/analysis-extras/CHANGES.txt solr/contrib/clustering/CHANGES.txt solr/contrib/langid/CHANGES.txt ...and committed checkpoint to reduce risk of conflicts as other people edit solr/CHANGES.txt... Committed revision 1367377. - trunk Committed revision 1367378. - 4x,1,If i don't see any objections; i'll start the grunt work to merge all the files into solr/CHANGES.txt sometime next week.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
23357,,,,,,,,It is just resolved in 2.0 and the changes for 1.x have been committed at the same moment. The dot: you'll find that the xml parser is not a general purpose xml parser complying to all details of xml. It doesn't have to. It just implements what is sufficient for Wicket. If only if there is a real need to implement an additional detail; than we'll do it. The dot; though in the spec; is nowhere used. So why bother and implement,Juergen; why do you close the issue so quickly? It's not applied to branch 1.x; and its' not even fixed properly in trunk. Did you see that I attached a patch and that I assigned this issue to myself? There is not only the hyphen; there is also the dot that is missing. And naming it VARIABLE_NAME2 is very dubious.,XML_NAME must not contain the colon,Updated patch; NCNameChar does not have the ':' sign See http://www.w3.org/TR/REC-xml-names/#NT-QName,Fixed in 2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4758,,,,,,,,See comments above; closing,The error text states the problem of this issue. The elements are not valid according to the config's schema file. If you have questions; the schema for xsdconfigs lives in src/configschema/schema,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5294,x,x,,,,,,After re-compiling the applcation and re-deploying everything worked properly; seems like during the first deployment something wrong happened and something got corrupted. Closing this issue as invalid. Thanks for your assistance.,Xerces 2.6.2 is a very old release. We've made many performance improvements and bug fixes since then. Please check whether this is still an issue with the latest Gump build [1]. If the problem still exists you should attach a complete test case (including the XML document and schema) to this JIRA issue so that we can reproduce it. [1] http://vmgump.apache.org/gump/public-jars/xml-xerces2/jars/,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
19905,,,,,x,,,Bummer! -- The solution too this problem was that my JVM had too little memory (64MB) for allocating all the byte buffers required for writing / reading serialized pages.,I will do some further investigation; not sure if it's a wicket problem or caused by the alternative serialization,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
50889,,,,,,,,Seems like this has all been done.,"'""apache' added font bug fixed""",The logo source for the one with the gray background uses a different font then the one with the black background; is this intentional? Also they both don't contain the letters 'apache' whereas the compiled one does.,I think special pages need a custom layout (about; getting started; home page; documentation; download etc.). According to priorities; I will produce needed layouts.,Tapestry Logo as Illustrator SVG : fixed with final dot after 'Code less; do more',NB: tapestry logo on homepage contains the word 'apache'.,Website redesign related files Contains: - CSS : a reset and custom style for tapestry.apache.org - layouts as static html: åÊåÊåÊ- - homepage åÊåÊåÊ- - documentation åÊåÊåÊ- - getting started - SVG for making headline/title images. Using fonts with big size would cause aliasing issues. I think it's better to use image for headlines.,Logo as Illustrator SVG.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
61559,,x,,,,,,The other precedences are OK; as far as I can tell... not worth messing around in the code for no demonstrable benefit.,I don't see anything else that looks wrong; so what do people think about doing this?,I went ahead and looked at the ternary operator (those I could find with grep) and here's the results. Not sure it's worth doing; anyone want to chime in? Although this construct is 'exciting'... luceneSort || sortMissingFirst && !reverse || sortMissingLast && reverse ? '' : 'zzz';,Dear God! You mean the intent here is: return (pf.filter==null && pf.postFilter==null) ? qr.getDocSet() : null; ??? gotta confess I just saw the pattern and jumped to conclusions; hadn't examined the code at all. But you've just made the job tougher... Wait; I know! I'll just write something in awk to convert everything in the source tree. The ternary operator really annoys me for this very reason... rant; rant; rant.....,the last line is: return pf.filter==null && pf.postFilter==null ? qr.getDocSet() : null; This is correct; but feel free to add parens to clarify.,Sorry for the spam; but there are backslashes in front of the pipe symbols in all the REs; silly website doesn't let them through |,I love it when a better solution occurs to me the instant I post something..... ||[^\(]+==.*?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
36717,,,,,,,,UIXListView also provides selection functionality through 'selectedRowKeys',UIXListView is derived off the UIXIterator and provides stamping of items vertically. In addition it provides grouping functionality through a treeModel and provides the wrapper around the treeModel for tree related operations similar to the UIXTree. 'groupDisclosedRowKeys' provides grouping functionality along with disclosure support,Attached is the component class. The implementation of it in the trinidad renderers will follow,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
53284,,,,,,,,Resolved in Version 1.2_QA_B1 . Therefore will be closing the issue,Fixed with moving to the axis2 trunk,The root cause of this is a defect in the Axis2 1.3 ApplicationXMLFormatter which ignores the 'preserve' flag passed in åÊåÊåÊåÊpublic void writeTo(MessageContext messageContext; OMOutputFormat format; åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊOutputStream outputStream; boolean preserve) throws AxisFault { The latest Axis2 code seems to have this fix; and thus we will be able to incorporate this only when we switch to the next version of Axis2. Thus I am postponing this issue to be fixed in Synapse 1.2 or later as Synapse 1.1.1 cannot fix this without a binary patch of Axis2,Indika; It might be worthwhile to check whether a response has already been submitted by the HTTP transport and throw a little more informative exception if that is the case. 'Transfer-encoding header already present' may sound a bit too scary and confusing. Oleg,Before sending message to a external endpoint ; synapse make a clone the MessageContext and this clone operation clones the properties ..etc... but it will never clone the SOAPEnvelope (except with in clone mediator and when converting soap11 to soap12 or vise visa .). Because of this; each MessageContext contains reference to the same SOAPEnvelope object. According to the scenario in the above synapse configuration; client send the rest request to the synapse and then synapse call to a rest endpoint. In this scenario; we send the cloned Message to the endpoint asynchronously and continue Message Mediation with the original Message . Each Message Context contains reference to the same SOAPEnvelope. Synapse do the rest call to the external endpoint and also continue message mediation . In the message mediation ; after message coming to the Log mediator ; it tries to log SOAPEnvelope(evaluates toString() method ) and then it throws the AxisFault 'java.util.NoSuchElementException ' . This is happen ; even client make a SOAP call and synapse do the rest call to the external endpoint(ant stockquote -Dtrpurl=http://localhost:8080/soap/StockQuote). In Both of above scenario what happen is ;when doing rest call; the SOAPEnvelope object has corrupted and because ; both Message Contexts refer to to the same SOAPEnvelope object ; in Log mediator when try to get string of SOAPEnvelope trows the the AxisFault 'java.util.NoSuchElementException ' due to the corrupted SOAPEnvelope. As a solution for above two scenarios ; we have to built the original SOAPEnvelope (only for above two scenario). The 'org.apache.http.ProtocolException: Transfer-encoding header already present ' Exception occurs due the side affect of the above AxisFault 'java.util.NoSuchElementException ' . This AxisFault did not catch in the Log mediator and therefore it goes up to the ServerWorker and ServerWorker log it an error and send it to the client as soap fault 'AxisEngine.sendFault(mc)'. At this point; synapse has already sent the http response with response Envelope received form the axis2server(OUT path) .Therefore ;sending soap fault from ServerWorker cause to resend the same Http response and occurs above 'org.apache.http.ProtocolException: Transfer-encoding header already present ' Exception. This situation can occur for any uncaught exception which cause to pop up it to the ServerWorker. you can see if you remove the log mediator from the configuration it will work properly . Thanks Indika,changed the fix version,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
13382,x,,,,,,,As you wish http://cwiki.apache.org/confluence/display/WW/Struts+2+Blank+Archetype,Lukasz; yes; something like that; thanks! But I thought about adding that note to another page that also had that failing command line: http://cwiki.apache.org/confluence/display/WW/Struts+2+Blank+Archetype,I added note about staging repo http://cwiki.apache.org/confluence/display/WW/Struts+2+Maven+Archetypes,Oleg What you want to change? Add comment about staging repo?,Change the documentation at least,The first thing that Maven users not familiar with Struts2 do is try to create a project from an archetype using the command from the online documentation. Please make them happy.,Ad.1 Yes; you are right and I will try to move Struts2 archetypes inside Struts2 project to be a submodule and included in release process of whole project Ad.2 It isn't so obvious but there were only few archetypes released so far; so it will be better to put a list of available versions of archetypes Regards _x0089_ÛÒ Lukasz,Lukasz: In order to be considered the final comments in the report: should I request an Enhancement for them?,Archetypes are ready to be released - the vote is in progress You can try to use staging repo as below mvn archetype:generate -DarchetypeCatalog=http://people.apache.org/builds/struts/2.1.8.1/m2-staging-repository/ Regards _x0089_ÛÒ Lukasz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
64407,,,,,,,,This bug was modified as part of a bulk update using the criteria... Marked ('Resolved' or 'Closed') and 'Fixed' Had no 'Fix Version' versions Was listed in the CHANGES.txt for 1.1 The Fix Version for all 38 issues found was set to 1.1; email notification was suppressed to prevent excessive email. For a list of all the issues modified; search jira comments for this (hopefully) unique string: 20080415hossman3,I just committed this. Thanks for the patch; and the tests!,initial version of patch,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
10101,x,,,,x,,,The attached stylesheet is an invalid XML document and there is also an invalid xpath expression. Please post all files required to reproduce this bug; including any extension java files. If you can simplify the stylesheet and java files; that will be great.,I am also noticing that full location information is not avaialable when this error occurs. You get the correct line number info but the SystemID is not reported.,Created an attachment (id=11016) XML File for XSL;,Created an attachment (id=11015) Stylesheet to force bug; see DEBUG comment to see offending XPath statement,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8640,,,,,,,,I think you want the XMLBEANS project; the xml to object mapping; rather than XBEAN; reusable server components,To reproduce; generate for the attached schema using defaults. Create an instance of ACORD and get the text. Can also see the bad behavior by creating sample XML using SampleXMLUtil.createSampleForType.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
11718,,,,,,,,*** This bug has been marked as a duplicate of 6155 ***,We had coverage of imported decimal-format declarations in numberformat tests 22; 23; 24; 43; 44; but all used named formats. New case 45 shows that the problem does exist with the default format. Simple workaround: name your format.,Since Gary says there's definitely something we should address here; I'm moving this to New so we can triage it. A handy-dandy test case from someone would be a big help too...,Just to clarify the issue: XSLT Section 12.3 states 'It is an error to declared either the default decimal-format or a decimal-format with a given name more than once (even with different import precedence); unless it is declared every time with the same value for all attributes (taking into account any default values).' This is handled in StylesheetRoot.recomposeDecimalFormats(). XalanJ is not conformant here. XalanJ will only accept the first default decimal-format or decimal-format with a given name and will issue a warning message for any other decimal-formats encountered without checking to see if the attributes match. I'm not sure if this addresses jschwendner's problem or not but it is something that should eventually be fixed. I'll put this on my list for today. Gary,Can you do two things to help us diagnose this? - Try it with the latest posted build 2.2D06? - Attach both of your .xsl stylesheets and an .xml document that show this bug so we can reproduce the specific case. Thanks.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
65661,,,,,,,,Fixed in http://svn.apache.org/viewvc?view=revision&revision=1210845,The ServiceMix 4 code implements this part of the JBI specification: /**  * Get the JBI context for this component. The following methods are valid to use on the context:  * <ul>  * <li>{@link ComponentContext#getMBeanNames()}</li>  * <li>{@link ComponentContext#getMBeanServer()}</li>  * <li>{@link ComponentContext#getNamingContext()}</li>  * <li>{@link ComponentContext#getTransactionManager()}</li>  * </ul>  * All other methods on the returned context must throw a <code>IllegalStateException</code> exception if invoked.  *   * @return the JBI context for this component; which must be non-null.  */ public ComponentContext getContext();  However; since ServiceMix 3 does implement the getLogger() method (in fact; it uses a full-blown ComponentContext implementation); so I wonder if we could ignore the specification here for ServiceMix 4 as well. What do people think? The obvious workaround would be to use any kind of logger (slf4j; commons-logging;...) in your own code _x0089_ÛÒ in ServiceMix 4; all of those are provided by pax-logging anyway so whichever you choose will be nicely integrated with the rest of the logging.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
36376,,,x,,,,,Oops; commit message had wrong ticket number in it; here is the commit: Author: sjiang Date: Fri Mar 19 00:59:56 2010 New Revision: 925063 URL: http://svn.apache.org/viewvc?rev=925063&view=rev Log: TS-260: fix remap filtering and parsing of src_ip Modified: incubator/trafficserver/traffic/trunk/proxy/http2/remap/UrlRewrite.cc Modified: incubator/trafficserver/traffic/trunk/proxy/http2/remap/UrlRewrite.cc URL: http://svn.apache.org/viewvc/incubator/trafficserver/traffic/trunk/proxy/http2/remap/UrlRewrite.cc?rev=925063&r1=925062&r2=925063&view=diff,Fixed previously removed filter implementation to parse src_ip and handle filtering.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
57286,,,,,,,,Not quite 100% done. Will finish in 4.2.2.,Changes in rev. 642015 merged in 4.2.x branch thus: http://svn.apache.org/viewvc?view=rev&revision=648752,Thanks. I'm still working on a patch for rw_tmpnam().,I verified that the changes made didn't break the fix to STDCXX-421. the testcase: export TMPDIR=/build/scottz/tmp; rm -rf $TMPDIR/*; ./exec -t 10 en_IN.UTF-8.sh still function properly.,The POSIX function tempnam doesn't fully specify how the name of the directory is obtained when the dir argument to the function is NULL. All known platforms (AIX; FreeBSD; HP-UX; IRIX; Linux; Solaris; Tru64) implement the following behavior: use the TMPDIR environment variable if it is set to a valid directory; otherwise use the dir argument if it points to a valid directory; otherwise us the P_tmpdir macro if it is defined to a valid directory in <stdio.h>; otherwise use /tmp The P_tmpdir macro is #defined to /tmp on AIX; Linux and Tru64 UNIX; and to /var/tmp on FreeBSD; HP-UX; Solaris; and IRIX.,See the following post(s) for proposed patches and a discussion: http://www.nabble.com/STDCXX-401-tt15967805.html http://www.nabble.com/-PATCH--STDCXX-401-part-2-tt15990851.html,The POSIX variable is actually TMPDIR _x0089_ÛÒ see http://www.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap08.html#tag_08_03 Scheduled for sometime after 4.2.,Lowered priority.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
75490,,,,,,,,Ok; since you have a workaround I will close this.,I am using Sun Java 1.6.0_11 on Windows XP x86-32 bit Service Pack 3 + all current patches. It turns out that the class was already final in 1.4.1. Further debugging revealed that putting the xml-sec 1.4.2 jar file on the Java endorsed path resolved the issue. Specifically the problem was that the class org.jcp.xml.dsig.internal.dom.DOMHMACSignatureMethod contains inner classes in 1.4.2 which are not in the version shipped in the Sun Java 1.6.0_11 rt.jar.,Unfortunately; the change to make XMLSignature a final class does break any existing subclasses. But this is the first case I have heard of an issue. So a question for you is why do you need to subclass it?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
11978,,,,,x,,,Unfortunatly; this minimal example is not very small ... When i try to simplify it to reduce size; it stops to crash because of different memory allocations sizes it goes through the other code branches. The problem can be reproduced only by transforming two files HAC_OPER_HIER.xml and HAC_OPER_LIST_FORM.xml with one XalanTransformer without recreating it (i modified attached xalanexe.cpp to reproduce it),Can you provide a minimal stylesheet and source document to reproduce this?,Simplest fix is to turn off the optimization that chooses if we need to return new calculated iterator or the old one; and always calculate new.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
49893,x,,,,,,,Fixed - thanks!,Created an attachment (id=9706) TapestryLinks.xml.diff,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33144,,,,,,,,Closing because this has been in RESOLVED state for over one year; if it turns out to not be fixed please reopen.,all discussion http://www.mail-archive.com/tuscany-dev@ws.apache.org/msg21712.html,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
22447,,,,,,,,A RangeValidator exists by now which looks very similar to yours.,Thanks; a good idea. Being a new feature; this belongs to 1.5 I think (and then we can do a generified version straight away). Java foundation classes should definitely include a Range<T> class.,Moved to next milestone release.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
18301,,,,,,,,Issue is resolved. Closing per Bryant's approval to do so.,Integrated in Wink-Trunk-JDK1.6-itests #50 (See http://hudson.zones.apache.org/hudson/job/Wink-Trunk-JDK1.6-itests/50/) Reduce logging in error path case Stacktraces/exception objects still avaialble in debug mode but in normal mode a simpler info message is logged. Exception still thrown to container and in Geronim/Tomcat this means the stack trace is still printed out to the container log outside of Wink. See [],Integrated in Wink-Trunk-JDK1.5-itests #49 (See http://hudson.zones.apache.org/hudson/job/Wink-Trunk-JDK1.5-itests/49/) Reduce logging in error path case Stacktraces/exception objects still avaialble in debug mode but in normal mode a simpler info message is logged. Exception still thrown to container and in Geronim/Tomcat this means the stack trace is still printed out to the container log outside of Wink. See [],Integrated in Wink-Trunk-JDK1.5 #248 (See http://hudson.zones.apache.org/hudson/job/Wink-Trunk-JDK1.5/248/) Reduce logging in error path case Stacktraces/exception objects still avaialble in debug mode but in normal mode a simpler info message is logged. Exception still thrown to container and in Geronim/Tomcat this means the stack trace is still printed out to the container log outside of Wink. See [],,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
12867,,,,,,,,Integrated in Struts2 #545 (See https://builds.apache.org/job/Struts2/545/) WW-3881 allows new html input types (Revision 1397712) Result = SUCCESS lukaszlenart : Files : /struts/struts2/trunk/core/src/site/resources/tags/ajax/autocompleter.html,Resolved,I have tested with the latest SNAPSHOT and all is OK now. Thanks for the fix.,Should work with latest SNAPSHOT. Can you please test?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
52716,,,,,,,,Fixed in the trunk and branch,Attaching the patch.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
20258,,x,,,,,,By the way; from my point of view 'Resolution: Fixed Fix Version/s:1.4.16' is much more suitable here than 'Resolution: Cannot Reproduce',Fixed already.,Ok. This is good. I'll see what's the problem with the collaplse/expand link with WICKET-3449.,Martin; you are right. This issue can't be reproduced for 1.4 and 1.5 snapshots. Only for 1.4.15,I think you use older version of Wicket somehow. Both tickets work OK with latest snapshots of 1.4 and 1.5,it sounds strange; that you can't reproduce the bug I checked it in different computers and the result was everywhere the same. There are no any tricks with reproducing; just press the button.,after pressing the button,before pressing the button,I cannot reproduce the problem. Clicking on 'Submit Query' button adds a new leaf node and the tree is still there. Please add more details how to reproduce it.,QuickStart project,Attach quickstart please.,,,,,,,,,,,,,,,,,,,,,,,,,,,
44105,,,,,,,,Closed due to the release of Tiles 2.1.0.,All the subtasks have been resolved.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
43512,,,,,,,,I think you have enable ajax. f:loadBundle has only request scope. If you request the table sort the ajax response didn't know anything about the resource bundle. Please use tc:loadBundle it has session scope. But tc:loadBundle has a different semantic. Please consult the demo or other examples how to use it.,Just noticed: In one of the columns I have a button that receives its label from the same property-file --> that label also disappears.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
80768,,,,,,,,Now merged to the 0.20 release branch.,Though not in itself a priority change for 0.20; it sensibly goes along with QPID-4468. Reviewed by Rob. Approved for 0.20.,Rob reviewed this together with the changes for QPID-4468 (and 'thanked' me via email me for conflicting heavily with his changes for QPID-2796 ),Change made in http://svn.apache.org/viewvc?rev=1413363&view=rev,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
62753,x,,,,,,,Thank you!,committed r892775,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33026,,,,,,,,Closing because this has been in RESOLVED state for over one year; if it turns out to not be fixed please reopen.,Works using the latest distro; now that TUSCANY-1588 is fixed.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
28310,,,,,,,,Change the element type of 'attributes' to FSAttribute.,Side note: I was surprised that nothing in UIMA detected this situation at run-time. Apparently; the element type can be anything. It's not enforced.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
36623,,x,,,,,,Reviewed and tested. Looks good so far; so I am closing this issue.,I've tested it out Ubuntu 9.04 64bit and so far no issues.,I committed the patches last night (v5 and cluster). John; Did you want to give it a once over and close out the bug? Leif and I tested it out on every available Linux distro we had installed (fedora 11 32bit and 64bit; rhel 4 and 5 32bit) There might have been an Ubuntu in there too; but I don't remember now...,Yeah; that was another way I was thinking it would work. Worked well with RHEL4 32bit and fc11 64bit with and without -m32.,Bryan; could you check out this patch; it avoids the #ifdef.,I was still getting the problem: ../../../external-apache/iocore/cluster/ClusterCache.cc:1794: warning: cast from pointer to integer of different size Attached is a patch to fix this issue. It now compiles and runs under rhel4 32bit.,Oh; and I restored -g for release.,newest patch with pentium->i586 + all the old patches + restoring old 32-bit atomics,The old 32-bit atomic code should probably be used for the atomics for gcc3. These is stored in the file: ink_atomic_solaris_i86pc.s which should probably be renamed. I am testing a patch to restore these and will have a new rollup out shortly.,This allows building 32 bits with patch #4 applied. It uses full memory barrier for 64 bit atomic operations but cas64 is a hack,Errors I got from gmake -k when trying to compile on RHEL4 32bit: [yts_dev bcall@armybright release]$ uname -a Linux armybright.corp.yahoo.com 2.6.9-78.EL #1 Wed Jul 9 15:27:01 EDT 2008 i386 [yts_dev bcall@armybright release]$ gcc --version gcc (GCC) 3.4.6 20060404 (Red Hat 3.4.6-10) Copyright (C) 2006 Free Software Foundation; Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. [yts_dev bcall@armybright release]$ cat /etc/redhat-release Red Hat Enterprise Linux AS release 4 (Nahant Update 7),v4 worked fine on my 32-bit box; but a few comments: 1) Can we restore the -g for the release build? -ggdb3 is extremely verbose; making all the binaries 3x as large. 2) If we're no incorporating the patches I did for -march= detection; I think we need to do what Andrew suggested; and change the order in configure.ac; e.g. CCFLAGS='-march=pentium $CCFLAGS' CXXFLAGS='-march=pentium $CXXFLAGS' 3) Finally; I did a test with -march=i486 with the v4 patch; and it does not work. So -march=pentium is a minimum. I think we should change this to -march=i586 though; it's more in-line with the naming conventions used by the distros. I'm doing a second review of the actual code changes too; hopefully we can land this soon.,To make tracking of the patchset easier I have a git server: git://jplevyak.homeip.net/trafficserver If you add this as an additional remote you can keep in sync with both the x86_64 patchset and the current trunk (if I fall behind) using git-merge. I will try not to let it fall too far behind the trunk.,includes all patches up to through 0001-Properly-search-usr-lib64-for-tclConfig.sh.patch also sync'd with mainline,Andrew; Leif's patch deals with this by not adding the -march=pentium if there is already an -march supplied. john,John; For the 'ts-64bit-v3.patch': adjust the $CFLAGS and $CXXFLAGS in your 'ac_cv_sizeof_int_p' test block so that the flags are appended to the string instead of prefixing the string. In this way; you will then be able to let the package builder override the architecture values like so: ./configure CFLAGS=-march=core2 CXXFLAGS=-march=core2 The g++ commands will come out a little redundant: g++ -DPACKAGE_NAME=... -march=pentium -march=core2 ... But g++ will honor the last param passed of the same type so core2 ends up taking effect over i386. Cheers; Andrew,0001-Properly-search-usr-lib64-for-tclConfig.sh.patch looks good to me. No conflicts with Tcl license to make that change; either. In case you were concerned. Cheers; Andrew,On a 'clean' 64-bit box; without 32-bit packages; our m4/tcl.m4 script can not locate tclConfig.sh. Attaching a proposed patch; which will search /usr/lib64 as well. This patch + v3 compiles fine on my box (with the exception that the v3 patch is no longer in sync with the trunk).,reviewed patch 0003- TS-13-Add-support-to-only-add-march-pentium-if-CFLAG.patch and the patch looks good. sr=bcall,Applying the ts-64bit-v3.patch allows 64-bit compilation. Confirmed on Fedora 11/x86_64,Attached is a patch that provides: 1) --with-architecture=<arch>; which can be used to explicitly set the architecture for -march with configure 2) Make sure that CFLAGS and CXXFLAGS don't append a -march=pentium if there already is a value for -march= in there. #1 provides a convenience feature; and #2 should make this more compatible with typical usage of configure (as above).,One option would be to have a --with-architecture or some such as a switch in configure. E.g. AC_ARG_WITH(architecture; [AC_HELP_STRING([--with-architecture=<arch>]; [explicitly specify the architecture to use with various compilers])]; ac_architecture=$withval) (not sure the above works; but something like that). And then use $ac_architecture if specified with the gcc compiler switches; and if not; default to some other 'heuristics' like we did before (we'll want to support other -march= values for other platforms later on I'm sure). This would allow me to configure TS with something like --with-architecture=core2 and be all set . Thoughts?,This might fix the HostDB problem. The HostDBInfo struct wasn't padded to a multiple of 8 bytes. diff --git a/iocore/hostdb/I_HostDBProcessor.h b/iocore/hostdb/I_HostDBProcessor.h index e1b0c36..75754d0 100644 _x0089_ÛÓ a/iocore/hostdb/I_HostDBProcessor.h +++ b/iocore/hostdb/I_HostDBProcessor.h @@ -242;6 +242;7 @@ struct HostDBInfo unsigned int ip; int hostname_offset; // int srv_host_offset; + inku64 dummy_pad; } data; unsigned int srv_weight:16; Since I haven't seen the problem I haven't tested it. If soneone who has seen it could test or tell me how that would be great.,> > -march=core2 -march=pentium Humm... good point. The original configure.ac just put -march=pentium in every time. It also hard coded the gnu c++ location to be /usr/bin/g++. I have an updated version of gcc in /usr/local/bin that is ahead in my PATH which I think it should take so I changed this to be just g++. Similarly; we should probably check to see if an march is already specified and only if it is not add -march=pentium for 32-bit builds (as this is the minium required to get the atomics to work). That requires a substring search of CFLAGS which strains my autoconf/bash abilities. Any suggestions would be welcome. > As for the hostdb's etc; we added some stuff to make versioning of these things actually work (so; it'll self-destruct if it's an old version). Maybe also add something here for 64-bit vs 32-bit in the header. > I'm looking into this to see if I can just make them compatible. If not; then a flag in the header.,I meant to say; in my example case; the compiler gets invoked with -march=core2 -march=pentium which one takes precedence here ? I'm assuming -march=pentium is the 'minimum' architecture to get the appropriate builtins?,hmmm; so; this latest patch does work on i386; but... What if I wanted to compile with -march=core2 for example? Is that going to work too ? E.g. I'd do maybe CXXFLAGS='-march=core2' ./confgure As for the hostdb's etc; we added some stuff to make versioning of these things actually work (so; it'll self-destruct if it's an old version). Maybe also add something here for 64-bit vs 32-bit in the header?,The only db file I remember is the 'host.db' file.,fixed 32-bit compiles,the problem with __syn_bool_XX is that those instructions are not supported on i386 and the x86_64 build didn't like -mpentium. A solution is to add: +AC_CHECK_SIZEOF(int *) # test for 64-bit pointers; this permits CFLAGS=-m32 for 32-bit compiles on 64-bit systems +if test '$ {ac_cv_sizeof_int_p} ' = '4'; then + CFLAGS='$CFLAGS -march=pentium' + CXXFLAGS='$CXXFLAGS -march=pentium' +else + CFLAGS='$CFLAGS' + CXXFLAGS='$CXXFLAGS' +fi to configure.ac The advantage of this is that it permits 32 bit compiles on native 64-bit systems by just doing configure CFLAGS=-m32 CXXFLAGS=-m32 v3 of the patch has this change and the corrected LIBTCL change. I am still looking at librecord... which db was it that had to be deleted? I don't remember this code; must have been after my time.,There is a problem with this patch on i386 (32-bit) platforms. When we use things like ink_atomic_cas64(long*; long; long);; gcc can't generate the atomic; and instead generates a symbol like __sync_bool_compare_and_swap_8 This causes the link phase to fail (obviously); since the symbol is undefined. Not sure what options we have; but possibly we'll have to #ifdef around the (new) code that now uses long (i.e. ink64) and the 64-bit versions of the atomic operations. Also; I'm not sure what is more portable; but we already have code like #include <limits.h> #if ( __WORDSIZE == 64 ) ... #endif No matter what; I think we should standardize on one way to detect 64-bit; maybe in one of our include files we create another define; e.g. #include <limits.h> #if ( __WORDSIZE == 64 ) #define INK_64BIT_PLATFORM 1 #endif or some such (and use that new define consistently throughout the code). Thoughts? _x0089_ÛÒ Leif,Patch that fixes a hard coded -ltcl in our Makefile.am. Breaks when trying to do a 64bit build on Fedora 11 core 64bit.,I am testing out the patch. I have only one minor fix to the patch where one of our Makefile.am files hard codes -ltcl instead of using $(LIBTCL). This broke the build on Fedora 11 core 64-bit. There looks to be an incompatibility with the librecords files and I got a core when trying to read the '32-bit' librecords files. I removed the old db files and let the 64-bit code recreate them. We might want to look into this more or just tell people that the 32-bit and 64-bit files are incompatible. I still need to test building the code as 32-bit and see if that didn't break.,Fixed issue with ink_queue. The freelists requires specialized code for each architecture to insert the version into the head pointer in unused bits. This code now runs under high load for extended periods of time in forward proxy mode with optimization turned on.,The comment is wrong as the Itanium has a relaxed consistency model. It should be x86 x86_64 Sparc.,I left in the old code which will work for 32-bit machines using gcc 3.x; so the only folks who will be out will be those who for some reason are running 64-bit but don't want to update their compiler. I did break the makefile for the other platforms as I removed the .s file since I am not an automake guru. Perhaps someone could tell me how to include that conditionally? (i.e. on _i386_ platforms)? The new c++0x standard will have atomic operations built in; and when that comes out we should use that. In the meantime; the GCC ones are also supported by Intel which covers another major compiler. The HP effort is a good idea for other platforms; as I have used it before and it is of good quality. Personally; I would just use the code below which is small; and passed the test_atomic regression until the c++0x or someone wants another platform/compiler in which case I would go with the HP code. Also; I am assuming sequential(esque) consistency which is true for i386; x86_64 and Sparc; but should be conditioned for on other architectures like Power. #if defined(_GNUC) && (GNUC_ >= 4) && (_GNUC_MINOR_ >= 1) // see http://gcc.gnu.org/onlinedocs/gcc-4.1.2/gcc/Atomic-Builtins.html static inline ink32 ink_atomic_swap(pvink32 mem; ink32 value) { return __sync_lock_test_and_set(mem; value); } static inline ink64 ink_atomic_swap64(pvink64 mem; ink64 value) { return __sync_lock_test_and_set(mem; value); } static inline void *ink_atomic_swap_ptr(void *mem; void *value) { return __sync_lock_test_and_set((void**)mem; value); } static inline int ink_atomic_cas(pvink32 mem; int old; int new_value) { return __sync_bool_compare_and_swap(mem; old; new_value); } static inline int ink_atomic_cas_ptr(pvvoidp mem; void* old; void* new_value) { return __sync_bool_compare_and_swap(mem; old; new_value); } static inline int ink_atomic_increment(pvink32 mem; int value) { return __sync_fetch_and_add(mem; value); } static inline int ink_atomic_increment64(pvink64 mem; ink64 value) { return __sync_fetch_and_add(mem; value); } static inline void *ink_atomic_increment_ptr(pvvoidp mem; intptr_t value) { return __sync_fetch_and_add((void**)mem; value); } static inline int ink_atomic_cas64(pvink64 mem; ink64 old; ink64 new_value) { return __sync_bool_compare_and_swap(mem; old; new_value); } // not used for Intel Processors which have sequential(esque) consistency #define INK_WRITE_MEMORY_BARRIER #define INK_MEMORY_BARRIER #else ... the old code ...,Discussing with John for portability there is the HP research 'atomic_ops' project http://www.hpl.hp.com/research/linux/atomic_ops/ I haven't looked at it thoroughly but it supports quite a few platforms (X86; Itanium; Alpha; PA-RISC; PowerPC; and SPARC) and OSs (Linux; Microsoft Windows; HP/UX; Solaris; and MACOSX). They do indicate some ports are more complete than others. The license is mixture of MIT-style for code linked in with the client with some GPL stuff pulled into a separate library.,Paul Querna had also started porting atomics to use the gcc builtins; and we should compare those two. One issue is that we need to support gcc compiler versions which do not support this. In particular; RHEL4 still uses gcc 3.x; and we unfortunately have to support this for the time being at least. Paul had suggested incorporating some stuff from APR; and use the builtins when possible; and APR otherwise. We should coordinate these two efforts.,This is an initial cut at a 64-bit linux port. It runs; good enough; to surf through and the debug build did 1300 ops/sec against 2 cooked linux disks /dev/sdb;/dev/sdd for a couple minutes. I am looking for a committer to help with code review; tracking down things I might have missed and to discuss the approach to atomics. I am using the gnuc builtin atomics __sync_XXXXX which gives portability to all GCC-based ports without requiring the assembly language that was used before.
44952,,x,,,,,,As suggested above; I moved the detector classes from o.a.t.detect to o.a.t.parser subpackages in revision 1159985. That should complete the last remaining open issue with this feature; so resolving as fixed.,I think we are pretty much done with this issue already. Before closing this; I'd like to move the new classes from within o.a.t.detect to appropriate o.a.t.parser subpackages in tika-parsers. That way the detection logic is closer to the related parser classes and we don't have to worry about split-package warnings from OSGi.,In revision 1042497 I added an auto-loading mechanism for detectors so that tools like the Tika facade or the AutoDetectParser class can automatically pick up all detector implementations in the current classpath. This way also the container-aware detectors can be used with minimal changes to client code. To prevent excessive performance overhead; both the Zip and POIFS detectors will first check for the relevant magic byte header and will only do the more expensive format check if the byte header matches and if the given stream is a TikaInputStream instance. In revision 1042498 I added a new --detect option to the CLI for easier testing of the auto-detect functionality. Also; since the container-aware detectors are now automatically loaded and used; there's no longer any need for the explicit --container-aware-detector option and I've turned it into a no-op.,I refactored the code a bit in revision 1042476 to make it easier to compose with other kinds of detectors. Most notably I removed the ContainerDetector interface and made the POIFSContainerDetector and ZipContainerDetector classes directly implement the Detector interface.,I've added some Detector documentation in r985242; please everyone dive in with bits I have missed!,I committed my patch in revision 982175. > memory and processing impact of opening the container I think this acceptable as the extra cost is only associated with specific media types; and we can use the open container feature you added to TikaInputStream to allow later parsing stages to avoid duplicating these costs. Also; since this functionality is now only triggered when the detector is passed a TikaInputStream; a performance-conscious user can easily prevent the extra processing. We might also want to add some extra flag for this if needed. > detectors run in the right order This was a part of my thinking behind the proposed getSupportedTypes() method. With that we could choose to only run these kinds of more complex detectors when simpler detectors have first identified the basic container format.,BTW; the current new Detector implementations are a bit troublesome as they break the contract that the detect() method must not close() the given stream and should use mark() and reset() where necessary to avoid changing the state of the stream. The rationale behind this contract is that you should be able to call parse() on the same stream instance after detecting its type. The attached patch fixes this issue by using the TikaInputStream.getFile() method to access the underlying file (when available or spooled) when detecting these kinds of complex container formats. If the given stream is not a TikaInputStream; then just the generic application/zip or application/x-tika-msoffice type is returned.,Using the container aware detector will give a more accurate answer generally; but at the cost of more memory use; and longer processing time. (Oh; and plus the need for various parser dependencies) There was some reluctance on-list about making this the default; due to the memory and processing impact of opening the container; which we'll need to take notice of. There's also the issue of making sure the detectors run in the right order; which may matter for some but not for others. Alas I don't have a good answer for the way to handle all these different needs...,It's a bit more work; yes. What I'm trying to achieve here is for someone who just uses 'new Tika().detect(...)' to be able to benefit from these extra detectors when they're available in the classpath.,Ah; sorry Nick - I hadn't looked into code yet. I thought; that we stuck in container if it matches to some signature.,Alex - have a look at the code; I think it already does what you're asking of it For OLE2; when we detect the ole2 signature; we load the file into POIFS. We then ask the detector what it is based on this For Zip; we look at each entry in the zip file in turn. If it's one we recognise the name of; and that tells us all we need; we return. Otherwise; we open up that entry; and grab the mime type from that; and return.,Jukka - that might end up being more work though? Also; short of refactoring the current mime types to split out all the different bits; I'm not sure we will have that many new detectors ever?,It's better to have some flag; that will say 'Stop; if this rule matched'; because applying of all rules; could lead to weak performance It's better to have something like; for example for zips rule for jar: zip-type == X1 rule for odf: zip-type == X2 ..... zip-type will calculated once on first invocation; and then re-used. And all rules (for jar; odf; etc.) have no flag 'Stop here'; while there will rule for ordinary zip's; that will have this flag; and we'll stop after checking of all subtypes. The same is could be implemented for OLE2 and other container formats; like OGG; etc.,Hmm; I guess you're right; perhaps we won't need such multi-level detector functionality. The alternative is to simply load all available Detectors; run them on the input document and finally select the most specific of the returned media types.,2Nick: does this will allow to implement support for self-extracted archives? Because; if we'll implement this as separate checker; then we'll need to implement archive extraction/detection inside this checker - this could lead to code duplication.,At the moment; the ContainerAwareDetector checks the first 8 bytes of the file. If they match the OLE2 header signature; it hands it off to POIFS. If the first 4 bytes match the zip header signature; it does zip checking. If neither of them match; it falls back to the default detector To me; this seems simpler!,It would be great if the AutoDetectParser could automatically leverage such detectors that use external parser libraries. The AutoDetectParser can't directly link to such parsers due to dependency issues; but we could use the service provider mechanism just like we do with Parser classes to automatically load all the Detectors available in the classpath. To do this effectively; I'd also add a Detector.getSupportedTypes() method like below so that more complex and potentially more expensive (need to read the entire document) detectors like POIFSContainerDetector could only be called if a more generic detector first determines that the input document matches the supported base type. /** Returns the set of base media types supported by this detector when used with the given parse context. The base media type can be <code>application/octet-stream</code> for generic detectors or a more specific type like <code>text/plain</code> or <code>application/zip</code> for detectors that can only distinguish between subtypes of that base type. * @since Apache Tika 0.8 @param context parse context @return immutable set of media types */ Set<MediaType> getSupportedTypes(ParseContext context);,Nick; awesome job! Comments below: I think the only bit left for now is to document it. We don't currently have a Detection section in the documentation. Shall I create a new one; put in the basics from one of the apachecon Tika talks; then add a section on container aware detection? Yep; I would do this. I would just add some APT documentation and create a section called 'Detection'; with some useful information on there. You could also then from that APT page; link to the page on the Wiki where the discussion on container Metadata occurred too: http://wiki.apache.org/tika/MetadataDiscussion Cheers; Chris,I've added support for OOXML files (detection + container re-use); as well as Jar files I believe the only zip based container format we can't currently detect with this is iWork. I've figured out how to tell it's an iWork document; but not how to tell which iWork document subtype it is. I think the only bit left for now is to document it. We don't currently have a Detection section in the documentation. Shall I create a new one; put in the basics from one of the apachecon Tika talks; then add a section on container aware detection?,Nick; awesome!,As no-one has objected; I've committed this initial code in r980058. With this commit; OLE2 based detection should be complete; and some Zip based detection is there; but some still remains to be added.,Patch which implements limited ole2 and odf detection by parsing the containers. May not be the best way to do it however...,,,,,,,,,,,,,,,,
5491,,,,,,,,reg_name has been accepted as valid URI syntax since Xerces 2.6.0. This may change in the future if XML Schema 1.0 moves up to the RFC 3986 syntax which excludes this production. Xerces CVS currently supports the XML Schema 1.0; 2nd edition which still references RFC 2396 for the anyURI type. The version of XML Schema 1.0 supported will be clearly marked in the documentation. The relevant RFCs for anyURI may be emphasized in a FAQ.,Interesting - you guys are doing a great job. I raised the issue against 2.5 because that is what Stylus Studio ships with. Given the comment from Roy Fielding its a shame that the Digital Radio Mondiale team who wrote ETSI TS 102 821 didn't register their URI schema. In fact this URI schema has some practical problems and it being esentially deprecated by RFC 3986 is an argument I can use to try and get it changed. Luckily Annex C is informative; not normative. I will try and get the ETSI spec changed and definately not incorporate the deprecated URI in the XML schema we are designing. We have a Digital Radio Mondiale meeting next week where I should be able to get this going. I think XERCES should follow (and track) the W3C standard so the current 2.6 behaviour is correct; the 2.5 behaviour is incorrect and if W3C changes the schema spec to reference 3986 then XERCES should change with it. As far as this bug is concerned it doesn't seem like you need to implement anything but it would be nice if the exact syntax accepted by the tool was somewhere in the user documentation (if it is then my mistake but I couldn't find it by googling). Julian,Just to clarify... The report was opened against Xerces 2.5.0. Xerces has allowed the reg_name syntax since Xerces 2.6.0; so as of today the schema validator will accept dcp.tcp.pft://192.168.0.1:1002:3002?fec=1&crc=0 as a valid value of type anyURI.,Roy Fielding has confirmed that this was a deliberate decision; and is indeed an incompatibility between 2396 and 3986. According to him; 'No URI schemes were defined using the reg_name syntax of 2396; and therefore it was removed.' Probably; nobody should be using such syntax now. What to do now? This is a tough call; but I tend to fall back on the letter of the law (or the spec). The schemas spec references 2396; not 3986. Therefore Xerces should be changed to allow this syntax. This might change in schema 1.1 though; which will likely reference 3986; not 2396. However; the current working draft still references RFC 2396. I've asked the schema working group to consider this issue.,The colon isn't the only issue. The @ sign is also prohibited in reg-names in 3986 and allowed in 2396. I wonder what the working group was thinking? I suspect they were trying to make it easier to distinguish reg-names from host-based authorities; and allow user info and port to be specified for registry based authorities. This particular issue is not listed in Appendix D2 of 3986; Modifications; so I wonder if the working group noticed it?,RFC 3986 does seem to prohibit this URI. In 3986 we have: åÊåÊåÊreg-name = *( unreserved / pct-encoded / sub-delims ) åÊåÊåÊunreserved = ALPHA / DIGIT / '-' / '.' / '_' / '~' åÊåÊåÊsub-delims = '!' / '$' / '&' / ''' / '(' / ')' åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊ/ '*' / '+' / ';' / ';' / '=' In 3986 the colon is a general delimiter; not a sub delimiter. I'm not sure what should be done here. Schemas Part 2 normatively references 2396; not 3986; so I suppose this should be allowed. On the other hand; I can't help but think that this is really a bug in the definition of reg-names in 2396.,The value space for anyURI [1] is defined by RFC 2396 (and RFC 2732). dcp.tcp.pft://192.168.0.1:1002:3002?fec=1&crc=0 is allowed by the grammar since '192.168.0.1:1002:3002' matches reg_name. Registry-based Naming Authority (reg_name) has been supported since Xerces 2.6.0. authority = server | reg_name reg_name = 1*( unreserved | escaped | '$' | ';' | åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊ';' | ':' | '@' | '&' | '=' | '+' ) unreserved = alphanum | mark mark = '-' | '_' | '.' | '!' | '~' | '*' | ''' | åÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊåÊ'(' | ')' If RFC 3986 prohibits this URI then it seems the new RFC is not backwards compatible with RFC 2396. [1] http://www.w3.org/TR/2004/REC-xmlschema-2-20041028/#anyURI,Xerces is correct. This URI is syntactically incorrect according to RFC 3986. The authority component cannot have two colons when used with an IPv4 literal address. In essence; this URI tries to have two ports. I'm not familiar with the spoec you reference; but it does not appear to be conformant to the URI specification.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
41195,x,,,,,,,Thanks to Hazem Saleh for provide us this enhancement fixed at revision 655653,The patch!!!,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
48034,,,,,x,,,Very curious as to where you saw that exception. Because digging through my log files; all I see are series of 'NoClassDefFound' exceptions. Same goes for the sample project I submitted. I get the following stack trace: java.lang.RuntimeException: java.lang.ClassNotFoundException: caught an exception while obtaining a class file for org.apache.tapestry.transformationtest.pages.Start åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.tapestry.internal.services.ComponentInstantiatorSourceImpl.findClass(ComponentInstantiatorSourceImpl.java:240) åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.tapestry.internal.services.ComponentInstantiatorSourceImpl.findInstantiator(ComponentInstantiatorSourceImpl.java:222) åÊåÊåÊåÊåÊåÊåÊåÊat $ComponentInstantiatorSource_1177c5597da.findInstantiator($ComponentInstantiatorSource_1177c5597da.java) åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.tapestry.internal.services.PageElementFactoryImpl.newRootComponentElement(PageElementFactoryImpl.java:297) åÊåÊåÊåÊåÊåÊåÊåÊat $PageElementFactory_1177c5597e8.newRootComponentElement($PageElementFactory_1177c5597e8.java) åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.tapestry.internal.services.PageLoaderProcessor.loadRootComponent(PageLoaderProcessor.java:387) åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.tapestry.internal.services.PageLoaderProcessor.loadPage(PageLoaderProcessor.java:365) åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.tapestry.internal.services.PageLoaderImpl.loadPage(PageLoaderImpl.java:60) åÊåÊåÊåÊåÊåÊåÊåÊat $PageLoader_1177c5597e5.loadPage($PageLoader_1177c5597e5.java) åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.tapestry.internal.services.PagePoolCache.checkout(PagePoolCache.java:188) åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.tapestry.internal.services.PagePoolImpl.checkout(PagePoolImpl.java:108) åÊåÊåÊåÊåÊåÊåÊåÊat $PagePool_1177c5597e4.checkout($PagePool_1177c5597e4.java) åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.tapestry.internal.services.RequestPageCacheImpl.get(RequestPageCacheImpl.java:43) åÊåÊåÊåÊåÊåÊåÊåÊat $RequestPageCache_1177c5597e3.get($RequestPageCache_1177c5597e3.java) åÊåÊåÊåÊåÊåÊåÊåÊat $RequestPageCache_1177c5597d7.get($RequestPageCache_1177c5597d7.java) åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.tapestry.internal.services.PageRenderRequestHandlerImpl.handle(PageRenderRequestHandlerImpl.java:55) åÊåÊåÊåÊåÊåÊåÊåÊat $PageRenderRequestHandler_1177c5597cc.handle($PageRenderRequestHandler_1177c5597cc.java) åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.tapestry.internal.test.PageLinkInvoker.invoke(PageLinkInvoker.java:59) åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.tapestry.test.PageTester.invoke(PageTester.java:167) åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.tapestry.test.PageTester.renderPage(PageTester.java:129) åÊåÊåÊåÊåÊåÊåÊåÊat org.apache.tapestry.transformationtest.pages.TestStart.render_start(TestStart.java:12) Even turning on debugging output; I don't see the exception message you posted.,Exception is pretty clear: 'Service interface org.apache.tapestry.services.DataTypeAnalyzer is matched by 2 services: DataTypeAnalyzer; DefaultDataTypeAnalyzer. Automatic dependency resolution requires that exactly one service implement the interface.' Inside TapestryModule: åÊåÊ@Marker(Primary.class) åÊåÊåÊåÊpublic DataTypeAnalyzer build(List<DataTypeAnalyzer> configuration) åÊåÊåÊåÊ{ åÊåÊåÊåÊåÊåÊåÊåÊreturn _chainBuilder.build(DataTypeAnalyzer.class; configuration); åÊåÊåÊåÊ} Changing Start.java to: public class Start { åÊåÊåÊåÊ@Inject @Primary åÊåÊåÊåÊprivate DataTypeAnalyzer _analyzer; } And all is well.,Uploading a maven project which illustrates the bug. The project uses 5.0.8-SNAPSHOT; but the error is also present in 5.0.7.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
60022,,,,,,,,[branch_4x commit] Shalin Shekhar Mangar http://svn.apache.org/viewvc?view=revision&revision=1444786 SOLR-4426: NRTCachingDirectoryFactory does not initialize maxCachedMB and maxMergeSizeMB if <directoryFactory> is not present in solrconfig.xml,[trunk commit] Shalin Shekhar Mangar http://svn.apache.org/viewvc?view=revision&revision=1444782 SOLR-4426: NRTCachingDirectoryFactory does not initialize maxCachedMB and maxMergeSizeMB if <directoryFactory> is not present in solrconfig.xml,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
70014,x,,,,,,,Marking resolved; feel free to reopen if needed,Thanks for your contribution! I'm not a fan of thread locals at the framework level if we can avoid them; so I implemented a different mechanism in revision 1084217; using optional interfaces. The SlingRemoteExecutionRule class is a RequestCustomizer which does nothing by default; but if you want to use thread locals in your project inheriting your own rule class from that one should work. Please let us know if this works for you; and I'll close this issue if it does.,The patch provides one possible approach based on passing the Request object to a RequestProcessor. The RequestProcessor instance is obtained from a ThreadLocal which can be specified by the TestCase in the Before execution phase depending on the testcase being run,Patch for supporting addition of credentials based on a ThreadLocal request processor,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
44965,,,,,,,,TagSoup 1.2.1 is finally available; so in revision 1160599 I upgraded the dependency and removed the earlier workaround.,I posted again to tagsoup-friends; asking for a release with this fix included. See https://groups.google.com/forum/?pli=1#!topic/tagsoup-friends/Tb7OvGPzKCA,I came up with a fairly simple patch [1] that seems to solve this. I'll see what we can do to push out an official release with this fix. [1] http://github.com/jukka/tagsoup/commit/9cfe7b48745173faafa419f540538a0b6309b699,Here are some related posts to the tagsoup user groups: http://groups.google.com/group/tagsoup-friends/browse_thread/thread/751d271c107a24a9# http://webcache.googleusercontent.com/search?q=cache:M2F_jS2hLVwJ:tech.groups.yahoo.com/group/tagsoup-friends/message/1250+%22Yes;+it+should+be+handled+%28and+returned+as+a+raw+%26;+to+be+escaped%22+on+output+as+%26amp%3B&cd=1&hl=en&ct=clnk&gl=us Evidently the bug occurs when the document contains a sequence of '&' followed by [CR]. When all CRs are transliterated to LFs then TagSoup runs properly. As tagsoup has no official bug tracking or release tracking system there is no way to know when this bug would be fixed. That is why I'm submitting it here as it is causing a bug in apache tika.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33812,,,,,,,,Here is a complete patch removing Composite* from the getImplementation() calls,This patch removes the Composite* from the ComponetnType constructor. I'll apply it when I can confirm it really isn't needed.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
36911,,,,,,,,This is on top of http://svn.apache.org/repos/asf/myfaces/trinidad/branches/2.0.0.1-branch,Reopening this for inclusion in 2.0.0.1-branch,ASF enabled patches,Attaching a patch file created with updated svn.,tri-doc-20110902.patch contains the documentation changes for this patch,Documentation change for patch provided.,The patch (tri-code-24082011.patch) introduces a way to specify css rules specific to touchScreen devices. TouchScreen device agents have capability marked by 'touchScreen' with valid values of none; single and multiple. Syntax implemented allows user to specify rules as follows: @agent (touchScreen:none) { åÊåÊåÊ/* Some styles that should not be rendered on touchScreen devices. */ } @agent (touchScreen:single) { åÊåÊåÊ/* some styles specific for touchScreen with single touch. */ } @agent (touchScreen:multiple) { åÊåÊåÊ/* some styles specific for touchScreen with multiple touch. */ } @agent (touchScreen) { åÊåÊåÊ/* some touchScreen specific styles for all touch devices: both single and multiple touch. */ } @agent webkit and (version: 9) and (touchScreen:single) { åÊåÊåÊ/* some touchScreen specific styles for touch devices with single touch running webkit version 6. */ } @agent gecko and (version: 6); webkit and (touchScreen:single) { åÊåÊåÊ/* styles to be rendered on version 6 of gecko agent and single touch devices running webkit */ },Patched based on @agent (touchScreen) syntax,Will be backing this out. After looking into this more; the separate renderkit for tablets is overkill and causes issues with people that have made custom skins. I am thinking that an extension to @agent in the CSS skin parser would be preferable.,Commit the patch,Patch file implementing this fix on top of http://svn.apache.org/repos/asf/myfaces/trinidad/trunk,,,,,,,,,,,,,,,,,,,,,,,,,,,
64751,x,,,,,,,Thanks for the patch JÌ_rgen. Revision 1028760.,Of course setting this specific import to optional is a good idea - sorry; forgot that!,Thanks for the update JÌ_rgen. Anyway; I prefer to set the import package as optional in Jetty bundle pom. I'm gonna make some tests and keep you posted. Regards JB,Added import for manifest,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33497,x,,,,,x,,Closing because this has been in RESOLVED state for over one year; if it turns out to not be fixed please reopen.,Fixed in revision 512383. You can now obtain helpers that support extensible namespaces by calling SDOUtil.createHelperContext(true).,Sorry - previous was wrong version. Someone with admin rights could remove the older versions,Handles same issue with attributes?,Hi everyone. There are 4 places in the createFeature method where eClass.getEStructuralFeatures().add is called. First is when content kind is mixed and type is EFeatureMapEntry (whatever that means - but name was 'mixed'). Second is alsp content kind mixed and everything else - eg. xMLNSPrefixMap. Third is type instanceof EClass which is where I changed the add to set. Fourth is the attributes. I believe the issue Frank raised with the attributes is handled if there put: åÊåÊåÊåÊåÊåÊint existingIndex = eClass.getEAllStructuralFeatures().indexOf(eClass.getEStructuralFeature(name)); åÊåÊåÊåÊåÊåÊif (existingIndex > -1) { åÊåÊåÊåÊåÊåÊ eClass.getEStructuralFeatures().set(existingIndex; eAttribute); åÊåÊåÊåÊåÊåÊ} else { åÊåÊåÊåÊåÊåÊ eClass.getEStructuralFeatures().add(eAttribute); åÊåÊåÊåÊåÊåÊ} I have tried to modify the test case for this and it seems to handle it. I'll attach the two new versions (still don't know what that Patch thing is). Are we covered now? And have you thought about how to implement these changes the right way? ps. I haven't looked at the simple type issue you mention Frank.,I feared that the hack wasn't good enough and generally I never expected that the changes was of a standard that could get into the SDO baseline. That fact that code is more or replicated directly from EMF is not pretty. Of course I am willing to follow this issue and keep testing etc. I fear that I won't be able to make any relevant changes without your help as I find the EMF part hard to get a thorough understanding of. First I'll try to update the qad test-case to see I can trigger the issue you mention.,Christian; I'm glad to see that you've been able to run your test case; but the hack in createFeature() is not the proper general solution. We can't change the behavior of createFeature() like this; or it will break other things. For example; in the case where there are real duplicates - e.g.; a complexType with an attribute and and element with the same name. This also doesn't handle the case of a global element of simpleType. So; we can't commit this kind of change in Tuscany - we need to come up with a proper way to do it without breaking other things. How soon are you looking to have this implemented and if the answer is soon; are you willing to keep helping with the implementation?,Mail archive: åÊåÊåÊåÊhttp://www.mail-archive.com/tuscany-user@ws.apache.org/msg00644.html,Sorry I don't know that Patch thing :( This version contains the latest changes where the createFeature has been pulled down from XSDECoreBuilder. Since I (at the moment) did not want to change code in EMF I had to pull down the entire createFeature method (since it was already overridden) from XSDECoreBuilder and changed at the spot you pointed out: åÊåÊåÊåÊåÊåÊ// NON-TUSCANY åÊåÊåÊåÊåÊåÊint existingIndex = eClass.getEAllStructuralFeatures().indexOf(eClass.getEStructuralFeature(name)); åÊåÊåÊåÊåÊåÊif (existingIndex > -1) { åÊåÊåÊåÊåÊåÊ eClass.getEStructuralFeatures().set(existingIndex; eReference); åÊåÊåÊåÊåÊåÊ} else { åÊåÊåÊåÊåÊåÊ eClass.getEStructuralFeatures().add(eReference); åÊåÊåÊåÊåÊåÊ} Now the test class succeds even using DocumentRoot!!! I have no idea if all scenarios are handled...,Reading a response from Frank Budinsky; I realized that the issues are probably solved with the 2 fixes. Adding or replacing individual properties in a single type is not necessary when you can redefine an entire type. SO changing TestTypeChangesAndExtensibleNamespaces.generate to just: XSDHelper.INSTANCE.define(new String(xsdFile.getBytes('UTF-8'))); DataObject documentDataObject = DataFactory.INSTANCE.create(namespace; rootElement+'Type'); handleRootDataObject(documentDataObject); Actually makes the program work! Frank's answer: Looking at your test program; I can see that what you're trying to do is more than I thought; so it's going to be harder. Let me explain. In the FIRST part; you define a Type named 'TestElementXType'. Then in SECOND; you add a second Type: 'TestElementYType'; which should work with the 'true' added to XSDHelper.define(); which allows it to proceed. In the THIRD part; you redefine Type 'TestElementXType'; which should work with the addToSortedList() change. That's my theory; anyway :-) What isn't working; since we haven't done anything to support it; is incremental addition/modification of the properties in a Type. Right now; all we have is the ability to add new types or completely replace a type with a new version (like you're doing for TestElementXType in part THREE). You can't add to or replace individual properties in a single type; which is what you're also trying to do with the global elements/properties in the 'DocumentRoot' Type. To test this theory; you could change the global element in the first schema to something like this: åÊåÊåÊåÊåÊåÊåÊåÊ<element name='RootElement' type='xsd:AnyType'/> and then delete the global elements in the second and third schemas. This way; you would define the 'DocumentRoot' Type in the first call to XSDHelper.define() and it would contain the property 'RootElement'. On the second and third calls to TypeHelper.define(); since you have no new global elements; it won't change/replace the 'DocumentRoot'; which is causing the problem. I think you should try to get this much working first; then we can think about how to specially handle the DocumentRoot. Note that if we just change things to allow you to also add new properties or change properties in a Type; then it wouldn't be doing the right thing to 'TestElementXType' in the THIRD part - you would have ended up with a 'TestElementXType' that has 4 properties (2 double and 2 integer) instead of a redefinition. Frank.,Here is the rather ugly version with the methods copied down from XSDECoreBuilder...,Just inserted 'true' to force namespace to be extended. All changes marked by NON-TUSCANY comment,This program demonstrates the issues,,,,,,,,,,,,,,,,,,,,,,,,,
23562,,,,,,,,Rolled back the change to Resource and included a FIXME that notes we don't cover all cases. But that doesn't lead to very serious problems anymore as it least the exception isn't thrown up in ComponentResourceRequestTarget anymore.,that change in ComponentResourceRequestTarget is fine But code that tries to not throw an exception at all should be back in. And improved for other situations/setups. It is pretty easy testing if you can test it in a debugger. Just set a break point in the respond method. And hold the break there. Then press the stop loading button of the browser. Then when you write again. Some kind of abort/reset socket exception should be thrown.,We can put that checking code in back again; and extend it with the cases for unix variants. What we should not put in is re-throwing of exceptions that aren't caught in that algorithm. They were ultimately caught by Wicket and Wicket tried to render an error page for it. Which doesn't make sense/ work for resource requests in the first place.,see http://www.nabble.com/Re%3A-svn-commit%3A-r482863---in--incubator-wicket%3A-branches-wicket-1.2.x-wicket-src-main-java-wicket--branches-wicket-1.2.x-wicket-src-main-java-wicket-request-target-resource--branches-wicket-1.x-wicket-src-main-java-wicket--branches-wicket-1.x-wicket--tf2770886.html,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
49361,,,,,,,,Much cleared exception now .... org.apache.hivemind.ApplicationRuntimeException Component BadInjectComponent/border is not assignable to type org.apache.tapestry.html.Body. location: Annotation @org.apache.tapestry.annotations.InjectComponent(value=border) of public abstract org.apache.tapestry.html.Body pages.BadInjectComponent.getBorder() Stack Trace: åÊåÊåÊåÊ* org.apache.tapestry.TapestryUtils.getComponent(TapestryUtils.java:301) åÊåÊåÊåÊ* $BadInjectComponent_0.finishLoad($BadInjectComponent_0.java) åÊåÊåÊåÊ* org.apache.tapestry.pageload.PageLoader.constructComponent(PageLoader.java:470) åÊåÊåÊåÊ* org.apache.tapestry.pageload.PageLoader.loadPage(PageLoader.java:639) åÊåÊåÊåÊ* $IPageLoader_1066542252f.loadPage($IPageLoader_1066542252f.java) åÊåÊåÊåÊ* $IPageLoader_10665422530.loadPage($IPageLoader_10665422530.java) åÊåÊåÊåÊ* org.apache.tapestry.pageload.PageSource.getPage(PageSource.java:118),Here's the problem; in my HTML template I have: <span jwcid='content@Border'> This is conflicting with: åÊåÊ@InjectComponent('content') åÊåÊpublic abstract Block getContent(); åÊåÊ_$content = (org.apache.tapestry.components.Block) getComponent('content'); It would be nice if Tapestry could help me puzzle this out. I'm picturing a cast check that would report the component id; expected class; actual class and report the location as the location of the @InjectComponent (or should the location be the location of the <span>?),First trick of enhancement problems; enable debugging by updating log4j.properties: log4j.category.tapestry.enhance.ComponentConstructorFactory=debug Now I can see the generated class: ComponentConstructorFactory [DEBUG] Creating class: ClassFab[ public class $ReportInfo_26 extends com.vaisala.ww.ui.pages.report.ReportInfo åÊåÊimplements org.apache.tapestry.event.PageDetachListener private org.apache.tapestry.form.IFormComponent _$tallNoField; private org.apache.tapestry.form.IFormComponent _$otherField; private org.apache.tapestry.form.IFormComponent _$otherDetailField; private com.vaisala.ww.ui.data.UserIdentity _$userIdentity; private org.apache.tapestry.engine.state.ApplicationStateManager _$applicationStateManager; private com.vaisala.ww.ui.data.ReportProposal _$proposal; private com.vaisala.ww.ui.services.ReportProposalMapURLFactory _$mapFactory; private org.apache.tapestry.components.Block _$content; private org.apache.tapestry.services.ComponentMessagesSource _$componentMessagesSource; private org.apache.hivemind.Messages _$messages; private org.apache.tapestry.spec.IComponentSpecification _$specification; private boolean _$tallNo; private boolean _$tallNo$default; private boolean _$tallYes; private boolean _$tallYes$default; private java.lang.String _$message; private java.lang.String _$message$defaultValue; public $ReportInfo_26(org.apache.tapestry.engine.state.ApplicationStateManager $1; com.vaisala.ww.ui.services.ReportProposalMapURLFactory $2; org.apache.tapestry.services.ComponentMessagesSource $3; org.apache.tapestry.spec.IComponentSpecification $4) { åÊåÊ_$applicationStateManager = $1; åÊåÊ_$mapFactory = $2; åÊåÊ_$componentMessagesSource = $3; åÊåÊ_$specification = $4; } public java.lang.String nameAndCompany(java.lang.String $1; java.lang.String $2; java.lang.String $3) { åÊåÊjava.lang.Object[] params = new java.lang.Object[3]; åÊåÊparams[0] = $1; åÊåÊparams[1] = $2; åÊåÊparams[2] = $3; åÊåÊreturn getMessages().format('name-and-company'; params); } public java.lang.String otherIsRequired() { åÊåÊreturn getMessages().getMessage('other-is-required'); } public java.lang.String getNavigationTitle() { åÊåÊreturn getMessages().getMessage('nav-title'); } public void setUserIdentity(com.vaisala.ww.ui.data.UserIdentity $1) { åÊåÊ_$applicationStateManager.store('userIdentity'; $1); åÊåÊ_$userIdentity = $1; } public boolean isTallYes() return _$tallYes; public java.lang.String formWasCancelled() { åÊåÊreturn getMessages().getMessage('form-was-cancelled'); } public com.vaisala.ww.ui.services.ReportProposalMapURLFactory getMapFactory() return _$mapFactory; public org.apache.tapestry.form.IFormComponent getOtherField() return _$otherField; public void setProposal(com.vaisala.ww.ui.data.ReportProposal $1) { åÊåÊ_$applicationStateManager.store('reportProposal'; $1); åÊåÊ_$proposal = $1; } public boolean isTallNo() return _$tallNo; public void setTallYes(boolean $1) { åÊåÊorg.apache.tapestry.Tapestry#fireObservedChange(this; 'tallYes'; ($w) $1); åÊåÊ_$tallYes = $1; } public com.vaisala.ww.ui.data.ReportProposal getProposal() { åÊåÊif (_$proposal == null) åÊåÊåÊåÊ_$proposal = (com.vaisala.ww.ui.data.ReportProposal) _$applicationStateManager.get('reportProposal'); åÊåÊreturn _$proposal; } public org.apache.tapestry.form.IFormComponent getTallNoField() return _$tallNoField; public org.apache.tapestry.valid.IValidationDelegate getDelegate() return (org.apache.tapestry.valid.IValidationDelegate) getBeans().getBean('delegate'); public java.lang.String getMessage() return _$message; public org.apache.tapestry.form.IFormComponent getOtherDetailField() return _$otherDetailField; public com.vaisala.ww.ui.pages.UIMPage getAccountManagement() return (com.vaisala.ww.ui.pages.UIMPage)getPage().getRequestCycle().getPage('account/AccountManagement'); public java.lang.String mustSetTallYesOrNo() { åÊåÊreturn getMessages().getMessage('must-set-tall-yes-or-no'); } public com.vaisala.ww.ui.data.UserIdentity getUserIdentity() { åÊåÊif (_$userIdentity == null) åÊåÊåÊåÊ_$userIdentity = (com.vaisala.ww.ui.data.UserIdentity) _$applicationStateManager.get('userIdentity'); åÊåÊreturn _$userIdentity; } public org.apache.tapestry.spec.IComponentSpecification getSpecification() return _$specification; public void setTallNo(boolean $1) { åÊåÊorg.apache.tapestry.Tapestry#fireObservedChange(this; 'tallNo'; ($w) $1); åÊåÊ_$tallNo = $1; } public java.lang.String yesOrNo() { åÊåÊreturn getMessages().getMessage('yes-or-no'); } public void setMessage(java.lang.String $1) _$message = $1; public void pageDetached(org.apache.tapestry.event.PageEvent $1) { åÊåÊ_$userIdentity = null; åÊåÊ_$proposal = null; åÊåÊ_$tallNo = _$tallNo$default; åÊåÊ_$tallYes = _$tallYes$default; åÊåÊ_$message = _$message$defaultValue; } public org.apache.tapestry.components.Block getContent() return _$content; public org.apache.hivemind.Messages getMessages() { åÊåÊif (_$messages == null) åÊåÊåÊåÊ_$messages = _$componentMessagesSource.getMessages(this); åÊåÊreturn _$messages; } public void finishLoad(org.apache.tapestry.IRequestCycle $1; org.apache.tapestry.engine.IPageLoader $2; org.apache.tapestry.spec.IComponentSpecification $3) { åÊåÊsuper.finishLoad($$); åÊåÊ_$tallNoField = (org.apache.tapestry.form.IFormComponent) getComponent('tallNo'); åÊåÊ_$otherField = (org.apache.tapestry.form.IFormComponent) getComponent('other'); åÊåÊ_$otherDetailField = (org.apache.tapestry.form.IFormComponent) getComponent('otherDetail'); åÊåÊ_$content = (org.apache.tapestry.components.Block) getComponent('content'); åÊåÊ_$tallNo$default = _$tallNo; åÊåÊ_$tallYes$default = _$tallYes; åÊåÊ_$message$defaultValue = _$message; åÊåÊgetPage().addPageDetachListener(this); } ],,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
